{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wSEn1qJXFh9L",
        "nsFX8YxhFJju",
        "eyqVOBLKFyHu",
        "QHQhGkR0tcac",
        "CGnJUB8Im0G6",
        "j9QG1PWoZ89y",
        "-nCPICXRsfPE",
        "4jfTkXF_KWlk",
        "y40rQ53-zzaU",
        "VPI1_xVTs8ZG",
        "NImo9DHfzfhA",
        "Y3xh8pmBzmXq",
        "32MLcGvO0T3S",
        "xtECcua60T3d",
        "0pMn6VzTFC2n",
        "SzHT-MEPEaMN",
        "2wM-KG31Ecok",
        "HAhms8uREcon",
        "lrSZxB1Eixd9",
        "rFmYjhkui0Lz",
        "fqxkUCufi0L1",
        "iaGJZjp7mVLV",
        "G6KgTWD8mbzQ",
        "80ABmQwBmbzc",
        "adgjIoxk50RL",
        "cROXpyNU68xU",
        "Cq_7zfHB55NT",
        "Ic3PxNai55NU",
        "-BlP0-f355NV",
        "m8dWgBDt55NY",
        "oSjrzq4NY1n2",
        "t0EjgtUbY1oE",
        "wNO0TNF355Nk",
        "Fxmz_P4xaOEn",
        "2ZQ3O6GiaOEq",
        "3IWlf0dH55Ny",
        "fQUYqDn3aThs",
        "7yC2_9qgaThu",
        "NBfVfw6I55N4",
        "b01LXgpDaZHE",
        "JNPNRrx_aZHV"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning in Computational Biology\n",
        "## Course Project\n",
        "## 2 class problem classification - Pipeline Notebook\n",
        "#### Papadopoulou Marianna, ID:7115152200032\n",
        "#### Vossos Charalampos, ID:7115152200037\n",
        "#### Fillipidou Thalassini-Marina, ID:7115152200022\n",
        "\n",
        "This notebook presents all the pipeline for the 2class classification problem\n",
        "of cells based on their gene profile. It contains all the optimization steps, hyperparameter tunning and the feature selection techniques that were tested\n",
        "In order to replicate the findings outlined in this academic document, please follow the steps below:\n",
        "\n",
        "1.\tOpen the notebook provided using Google Colab\n",
        "2.\tAccess the data section of the environment by clicking on the folder icon located on the left side.\n",
        "Then, upload the:\n",
        "  - final_data.csv file <br>\n",
        "  or the files\n",
        "  - E-MTAB-6108.aggregated_filtered_normalised_counts.mtx_cols\n",
        "  - E-MTAB-6108.aggregated_filtered_normalised_counts.mtx_rows\n",
        "  - E-MTAB-6108.aggregated_filtered_normalised_counts.mtx<br>\n",
        "  AND\n",
        "  - ground_truth.xlsx\n",
        "\n",
        " These files are provided within the exercise's zip file. To upload them, simply drag and drop the files into the designated area.\n",
        "\n",
        "3. Run the cells in the notebook in the order they appear, making sure to follow the instructions provided in each cell.\n",
        "\n",
        "When executing the notebook in Jupyter, it is essential to ensure that the necessary packages have been installed. Additionally, it is important to specify the path to the dataset (final_data.csv or other three files) as an input parameter for the *pd.read_csv()* functions.\n",
        "\n",
        "** *We have to note that the results of these classifiers are presented in the notebook* \"*Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb*\" *in the corresponding zip file of the exercise.*"
      ],
      "metadata": {
        "id": "vZSGbZaqij7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "wSEn1qJXFh9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute if notebook is opened in Colab\n",
        "!pip install mrmr_selection\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "yoiGHwyxNPpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import make_scorer, matthews_corrcoef, balanced_accuracy_score, f1_score, fbeta_score, recall_score, precision_score, average_precision_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import optuna\n",
        "from optuna.samplers import RandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random\n",
        "from mrmr import mrmr_classif"
      ],
      "metadata": {
        "id": "6WdKoBRaWAf5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets and construct the final dataframe that will be used for classification"
      ],
      "metadata": {
        "id": "nsFX8YxhFJju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, the three files mentioned at the beginning of this notebook are utilised to create our final dataframe, which will be used as the input for our classification pipeline. Our procedure involves the consolidation of three MTX files, which collectively represent the gene profiles of our cells. The subsequent step involves parsing the excel file containing the ground truth labels (gained from the clustering results, which the authors of the chosen paper provided) and appending its contents as additional columns to our gene profile dataframe."
      ],
      "metadata": {
        "id": "Ta8Z1F9EzlVx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8VAFhizFyHp"
      },
      "outputs": [],
      "source": [
        "# open file and read its content\n",
        "with open(\"/content/E-MTAB-6108.aggregated_filtered_normalised_counts.mtx\") as f:\n",
        "    lines = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Psbhr58FyHp"
      },
      "outputs": [],
      "source": [
        "# Create an empty dictionary 'normalized_counts_mtx' with three lists as values: \"gene\", \"cell\", and \"counts\".\n",
        "# These lists will be populated with data from the file 'E-MTAB-6108.aggregated_filtered_normalised_counts.mtx'.\n",
        "normalized_counts_mtx = {\"gene\": [], \"cell\": [], \"counts\": []}\n",
        "\n",
        "# Loop through each line in the 'lines' list starting from the third line (skipping the header).\n",
        "# Each line in the file represents a gene, cell, and its corresponding count.\n",
        "for line in lines[2:]:\n",
        "    normalized_counts_mtx[\"gene\"].append(line.split()[0])\n",
        "    normalized_counts_mtx[\"cell\"].append(line.split()[1])\n",
        "    normalized_counts_mtx[\"counts\"].append(line.split()[2])\n",
        "\n",
        "normalized_counts_mtx = pd.DataFrame(normalized_counts_mtx).astype(float) # Convert the 'normalized_counts_mtx' dictionary into a Pandas DataFrame and convert the 'counts' column to float type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiUaOSkpFyHq"
      },
      "outputs": [],
      "source": [
        "# Find the number of columns (genes) and rows (cells) present in the 'normalized_counts_mtx' DataFrame.\n",
        "# This information will be used to initialize an empty matrix for storing counts.\n",
        "cols= int(normalized_counts_mtx[\"gene\"].max())\n",
        "rows = int(normalized_counts_mtx[\"cell\"].max())\n",
        "matrix = np.zeros((rows, cols)) # Initialize an empty matrix of size (rows, cols)\n",
        "\n",
        "# Loop through each row in the 'normalized_counts_mtx' DataFrame.\n",
        "for i in range(normalized_counts_mtx.shape[0]):\n",
        "    # Retrieve the gene index and cell index (zero-based) for each row in the DataFrame.\n",
        "    gene = int(normalized_counts_mtx.loc[i, \"gene\"]) - 1\n",
        "    cell = int(normalized_counts_mtx.loc[i, \"cell\"]) - 1\n",
        "    counts = normalized_counts_mtx.loc[i, \"counts\"]\n",
        "    # Assign the counts value to the corresponding position in the 'matrix' (cell, gene).\n",
        "    matrix[cell, gene] = counts\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmxnRBh1FyHr"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se-e5ogvFyHs"
      },
      "outputs": [],
      "source": [
        "# Read gene names from the corresponding file\n",
        "genes = []\n",
        "with open(\"/content/E-MTAB-6108.aggregated_filtered_normalised_counts.mtx_rows\") as f:\n",
        "    lines = f.readlines()\n",
        "for line in lines:\n",
        "    genes.append(line.split()[0])\n",
        "df.columns = genes # Assign the gene names as column names in the 'df' DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WclTTVCKFyHs"
      },
      "outputs": [],
      "source": [
        "# Read cell names from the corrsponding file.\n",
        "with open(\"/content/E-MTAB-6108.aggregated_filtered_normalised_counts.mtx_cols\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "df.insert(loc=0, column='cell', value=lines) # Add the cell names as the first column in the 'df' DataFrame\n",
        "df[\"cell\"] = df[\"cell\"].str.rstrip(\"\\n\") # Remove the newline character from the 'cell' column values in the 'df' DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI2Vdl4hFyHt"
      },
      "source": [
        "## Adding ground truth labels from clustering results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty DataFrame named 'final_data' to store the final processed data.\n",
        "final_data = pd.DataFrame({})\n",
        "\n",
        "# Read the ground truth data from the Excel file 'ground_truth.xlsx' and store it in a DataFrame named 'ground_truth'.\n",
        "ground_truth = pd.read_excel(\"/content/ground_truth.xlsx\")\n",
        "\n",
        "temp_df = pd.DataFrame({})\n",
        "\n",
        "# Loop through each column in the 'ground_truth' DataFrame, starting from the third column.\n",
        "# Each column represents a different cell (e.g., 'column' corresponds to the cell name).\n",
        "for number, column in enumerate(ground_truth.columns[2:]):\n",
        "    df_clusters = pd.DataFrame({})\n",
        "\n",
        "    # Extract a subset of the original DataFrame 'df' where the 'cell' column matches the current cell (column).\n",
        "    temp_df = pd.DataFrame(df[df[\"cell\"] == column])\n",
        "\n",
        "    # Iterate through each row in the 'ground_truth' DataFrame.\n",
        "    # 'ground_truth.loc[i, \"K\"]' contains the number of clusters for the current row (index 'i').\n",
        "    # This number represents the number of clusters used in a certain split given by the row index 'i'.\n",
        "    for i in range(ground_truth.shape[0]):\n",
        "\n",
        "        # Get the number of clusters for the current row (index 'i').\n",
        "        number_of_clusters = ground_truth.loc[i, \"K\"]\n",
        "\n",
        "        # Assign the value from the 'ground_truth' DataFrame to a new column in 'temp_df' with a name like \"cluster_2\".\n",
        "        # The name is generated using the format \"cluster_number_of_clusters\".\n",
        "        # This column will contain the cluster label that the cell (column) belongs to for a certain split given by index 'i'.\n",
        "        temp_df[\"cluster_{}\".format(number_of_clusters)] = ground_truth.loc[i, column]\n",
        "\n",
        "    # Concatenate the 'temp_df' DataFrame to the 'final_data' DataFrame, adding data for the current cell (column) and clusters.\n",
        "    final_data = pd.concat([final_data, temp_df])"
      ],
      "metadata": {
        "id": "4kM6arTp-gVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "55s7NYNFFyHu",
        "outputId": "a2762aa0-e272-44fa-e7a6-206666e8ceb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             cell  ENSG00000000003  ENSG00000000005  \\\n",
              "0     ERR2538859-AAACCTGAGACCACGA        122.99367              0.0   \n",
              "1     ERR2538859-AAACCTGTCTGATACG        215.19258              0.0   \n",
              "2     ERR2538859-AAACGGGAGTGTTGAA          0.00000              0.0   \n",
              "3     ERR2538859-AAAGATGTCCGAACGC          0.00000              0.0   \n",
              "4     ERR2538859-AAAGTAGGTTAGTGGG        168.26047              0.0   \n",
              "...                           ...              ...              ...   \n",
              "1422  ERR2538860-TTTGGTTTCGTTACGA          0.00000              0.0   \n",
              "1423  ERR2538860-TTTGTCAAGCCCAACC          0.00000              0.0   \n",
              "1424  ERR2538860-TTTGTCACATTGGGCC        220.29666              0.0   \n",
              "1425  ERR2538860-TTTGTCAGTTGCGTTA          0.00000              0.0   \n",
              "1426  ERR2538860-TTTGTCATCAACACCA        115.33803              0.0   \n",
              "\n",
              "      ENSG00000000419  ENSG00000000457  ENSG00000000460  ENSG00000000938  \\\n",
              "0            0.000000              0.0          0.00000              0.0   \n",
              "1            0.000000              0.0          0.00000              0.0   \n",
              "2            0.000000              0.0          0.00000              0.0   \n",
              "3           65.466450              0.0          0.00000              0.0   \n",
              "4            0.000000              0.0          0.00000              0.0   \n",
              "...               ...              ...              ...              ...   \n",
              "1422         0.000000              0.0          0.00000              0.0   \n",
              "1423       172.205950              0.0          0.00000              0.0   \n",
              "1424         0.000000              0.0          0.00000              0.0   \n",
              "1425        55.496975              0.0          0.00000              0.0   \n",
              "1426        78.721800              0.0         38.44601              0.0   \n",
              "\n",
              "      ENSG00000000971  ENSG00000001036  ENSG00000001084  ...  ENSG00000289716  \\\n",
              "0            0.000000        30.748417         0.000000  ...              0.0   \n",
              "1            0.000000         0.000000         0.000000  ...              0.0   \n",
              "2            0.000000         0.000000         0.000000  ...              0.0   \n",
              "3           32.733227         0.000000        65.466450  ...              0.0   \n",
              "4           56.086823         0.000000        56.086823  ...              0.0   \n",
              "...               ...              ...              ...  ...              ...   \n",
              "1422         0.000000         0.000000         0.000000  ...              0.0   \n",
              "1423         0.000000         0.000000         0.000000  ...              0.0   \n",
              "1424         0.000000         0.000000         0.000000  ...              0.0   \n",
              "1425         0.000000       277.484860         0.000000  ...              0.0   \n",
              "1426        24.028757        19.223005        57.669014  ...              0.0   \n",
              "\n",
              "      cluster_2  cluster_4  cluster_7  cluster_8  cluster_11  cluster_18  \\\n",
              "0             1          3          3          3           2           2   \n",
              "1             2          2          6          7           7           3   \n",
              "2             1          1          1          1           1          14   \n",
              "3             1          4          5          5          10          18   \n",
              "4             1          4          4          6           5           7   \n",
              "...         ...        ...        ...        ...         ...         ...   \n",
              "1422          1          2          5          4           3           9   \n",
              "1423          2          2          6          7           7           3   \n",
              "1424          1          1          2          2           4          13   \n",
              "1425          1          1          2          2           6           8   \n",
              "1426          1          3          3          3           2           2   \n",
              "\n",
              "      cluster_23  cluster_31  cluster_37  \n",
              "0             19          17          12  \n",
              "1              6           6           1  \n",
              "2             14          26          26  \n",
              "3             22          28          33  \n",
              "4             20          11          21  \n",
              "...          ...         ...         ...  \n",
              "1422           3           5           5  \n",
              "1423           6          25           1  \n",
              "1424          13          12           8  \n",
              "1425           7          13          11  \n",
              "1426           1           2          23  \n",
              "\n",
              "[1427 rows x 19605 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ede1091a-9efd-401f-aff0-a8f6e483aa15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell</th>\n",
              "      <th>ENSG00000000003</th>\n",
              "      <th>ENSG00000000005</th>\n",
              "      <th>ENSG00000000419</th>\n",
              "      <th>ENSG00000000457</th>\n",
              "      <th>ENSG00000000460</th>\n",
              "      <th>ENSG00000000938</th>\n",
              "      <th>ENSG00000000971</th>\n",
              "      <th>ENSG00000001036</th>\n",
              "      <th>ENSG00000001084</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000289716</th>\n",
              "      <th>cluster_2</th>\n",
              "      <th>cluster_4</th>\n",
              "      <th>cluster_7</th>\n",
              "      <th>cluster_8</th>\n",
              "      <th>cluster_11</th>\n",
              "      <th>cluster_18</th>\n",
              "      <th>cluster_23</th>\n",
              "      <th>cluster_31</th>\n",
              "      <th>cluster_37</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ERR2538859-AAACCTGAGACCACGA</td>\n",
              "      <td>122.99367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.748417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ERR2538859-AAACCTGTCTGATACG</td>\n",
              "      <td>215.19258</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ERR2538859-AAACGGGAGTGTTGAA</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ERR2538859-AAAGATGTCCGAACGC</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.466450</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.733227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65.466450</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>28</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ERR2538859-AAAGTAGGTTAGTGGG</td>\n",
              "      <td>168.26047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.086823</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.086823</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>ERR2538860-TTTGGTTTCGTTACGA</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>ERR2538860-TTTGTCAAGCCCAACC</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>172.205950</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>ERR2538860-TTTGTCACATTGGGCC</td>\n",
              "      <td>220.29666</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>ERR2538860-TTTGTCAGTTGCGTTA</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.496975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>277.484860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1426</th>\n",
              "      <td>ERR2538860-TTTGTCATCAACACCA</td>\n",
              "      <td>115.33803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.721800</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.44601</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.028757</td>\n",
              "      <td>19.223005</td>\n",
              "      <td>57.669014</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1427 rows × 19605 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ede1091a-9efd-401f-aff0-a8f6e483aa15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ede1091a-9efd-401f-aff0-a8f6e483aa15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ede1091a-9efd-401f-aff0-a8f6e483aa15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "final_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyqVOBLKFyHu"
      },
      "source": [
        "# Get the 1500 genes with most variance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We keep only the 1500 most variant genes, as proposed in the paper."
      ],
      "metadata": {
        "id": "9M-mzG6d-_ds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao4UEJxuFyHv"
      },
      "outputs": [],
      "source": [
        "# Calculate the variance across cells for each gene\n",
        "variances = final_data.iloc[:, 1:-9].var(axis=0)\n",
        "\n",
        "# Sort the genes based on variance in descending order and select the top 1,500 genes\n",
        "top_genes = variances.sort_values(ascending=False).index[:1500]\n",
        "\n",
        "# Get the last columns from the original DataFrame\n",
        "last_columns = final_data.iloc[:, -9:]\n",
        "\n",
        "# Filter the DataFrame to keep only the top 1,500 genes and the last columns\n",
        "df_filtered = pd.concat([final_data[['cell'] + list(top_genes)], last_columns], axis=1)\n",
        "\n",
        "# Optionally, you can reset the index of the filtered DataFrame\n",
        "df_filtered.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "0r0nuJSWFyHw",
        "outputId": "f2b6d1bd-2c59-4122-f7e3-b39951578fb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             cell  ENSG00000205542  ENSG00000198804  \\\n",
              "0     ERR2538859-AAACCTGAGACCACGA        32962.305       9065.20200   \n",
              "1     ERR2538859-AAACCTGTCTGATACG        34861.200          0.00000   \n",
              "2     ERR2538859-AAACGGGAGTGTTGAA        17791.770       9193.14500   \n",
              "3     ERR2538859-AAAGATGTCCGAACGC        26513.914      10016.36700   \n",
              "4     ERR2538859-AAAGTAGGTTAGTGGG        30791.666      18116.04300   \n",
              "...                           ...              ...              ...   \n",
              "1422  ERR2538860-TTTGGTTTCGTTACGA        20833.332      11986.30100   \n",
              "1423  ERR2538860-TTTGTCAAGCCCAACC        73876.350        172.20595   \n",
              "1424  ERR2538860-TTTGTCACATTGGGCC        22690.557      14539.58000   \n",
              "1425  ERR2538860-TTTGTCAGTTGCGTTA        54775.516       5771.68550   \n",
              "1426  ERR2538860-TTTGTCATCAACACCA        15493.742       8285.11500   \n",
              "\n",
              "      ENSG00000167996  ENSG00000198712  ENSG00000156508  ENSG00000087086  \\\n",
              "0           8240.5760        5350.2246        4735.2563        5042.7400   \n",
              "1           5579.0670           0.0000       16139.4430        4519.0444   \n",
              "2           4845.0840        3431.0170       13334.9840        4739.7560   \n",
              "3           7070.3770        5564.6484       10540.0990        4058.9202   \n",
              "4           7291.2870        7347.3735        5664.7690        5384.3350   \n",
              "...               ...              ...              ...              ...   \n",
              "1422        5707.7627        6849.3150        6563.9270        5707.7627   \n",
              "1423       13776.4760           0.0000        5510.5903        9126.9150   \n",
              "1424        3524.7466        4038.7722       10060.2140        2570.1277   \n",
              "1425       11874.2080        2830.3457        6992.6187       11654.3640   \n",
              "1426        4150.8433        3748.4860        9015.5320        5151.7656   \n",
              "\n",
              "      ENSG00000075624  ENSG00000229117  ENSG00000026025  ...  ENSG00000185565  \\\n",
              "0           4950.4950        9255.0700        3659.0615  ...          0.00000   \n",
              "1           3873.4666       12696.3620        3443.0813  ...          0.00000   \n",
              "2           1061.1393       14643.7230        2193.0212  ...         70.74262   \n",
              "3           3404.2556        7725.0415        8837.9720  ...         65.46645   \n",
              "4           2636.0806        8469.1100        3140.8620  ...          0.00000   \n",
              "...               ...              ...              ...  ...              ...   \n",
              "1422        3139.2693       14554.7940        1141.5525  ...          0.00000   \n",
              "1423       18598.2420       10160.1510        7577.0615  ...          0.00000   \n",
              "1424        3671.6110        8003.4385        6094.8745  ...          0.00000   \n",
              "1425        8047.0615        8713.0250        6160.1640  ...          0.00000   \n",
              "1426        2383.6526        7515.4080        4632.7440  ...         96.11503   \n",
              "\n",
              "      cluster_2  cluster_4  cluster_7  cluster_8  cluster_11  cluster_18  \\\n",
              "0             1          3          3          3           2           2   \n",
              "1             2          2          6          7           7           3   \n",
              "2             1          1          1          1           1          14   \n",
              "3             1          4          5          5          10          18   \n",
              "4             1          4          4          6           5           7   \n",
              "...         ...        ...        ...        ...         ...         ...   \n",
              "1422          1          2          5          4           3           9   \n",
              "1423          2          2          6          7           7           3   \n",
              "1424          1          1          2          2           4          13   \n",
              "1425          1          1          2          2           6           8   \n",
              "1426          1          3          3          3           2           2   \n",
              "\n",
              "      cluster_23  cluster_31  cluster_37  \n",
              "0             19          17          12  \n",
              "1              6           6           1  \n",
              "2             14          26          26  \n",
              "3             22          28          33  \n",
              "4             20          11          21  \n",
              "...          ...         ...         ...  \n",
              "1422           3           5           5  \n",
              "1423           6          25           1  \n",
              "1424          13          12           8  \n",
              "1425           7          13          11  \n",
              "1426           1           2          23  \n",
              "\n",
              "[1427 rows x 1510 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7848c6f5-de65-42ff-a3ab-b6f737d9c240\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell</th>\n",
              "      <th>ENSG00000205542</th>\n",
              "      <th>ENSG00000198804</th>\n",
              "      <th>ENSG00000167996</th>\n",
              "      <th>ENSG00000198712</th>\n",
              "      <th>ENSG00000156508</th>\n",
              "      <th>ENSG00000087086</th>\n",
              "      <th>ENSG00000075624</th>\n",
              "      <th>ENSG00000229117</th>\n",
              "      <th>ENSG00000026025</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000185565</th>\n",
              "      <th>cluster_2</th>\n",
              "      <th>cluster_4</th>\n",
              "      <th>cluster_7</th>\n",
              "      <th>cluster_8</th>\n",
              "      <th>cluster_11</th>\n",
              "      <th>cluster_18</th>\n",
              "      <th>cluster_23</th>\n",
              "      <th>cluster_31</th>\n",
              "      <th>cluster_37</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ERR2538859-AAACCTGAGACCACGA</td>\n",
              "      <td>32962.305</td>\n",
              "      <td>9065.20200</td>\n",
              "      <td>8240.5760</td>\n",
              "      <td>5350.2246</td>\n",
              "      <td>4735.2563</td>\n",
              "      <td>5042.7400</td>\n",
              "      <td>4950.4950</td>\n",
              "      <td>9255.0700</td>\n",
              "      <td>3659.0615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ERR2538859-AAACCTGTCTGATACG</td>\n",
              "      <td>34861.200</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>5579.0670</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>16139.4430</td>\n",
              "      <td>4519.0444</td>\n",
              "      <td>3873.4666</td>\n",
              "      <td>12696.3620</td>\n",
              "      <td>3443.0813</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ERR2538859-AAACGGGAGTGTTGAA</td>\n",
              "      <td>17791.770</td>\n",
              "      <td>9193.14500</td>\n",
              "      <td>4845.0840</td>\n",
              "      <td>3431.0170</td>\n",
              "      <td>13334.9840</td>\n",
              "      <td>4739.7560</td>\n",
              "      <td>1061.1393</td>\n",
              "      <td>14643.7230</td>\n",
              "      <td>2193.0212</td>\n",
              "      <td>...</td>\n",
              "      <td>70.74262</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ERR2538859-AAAGATGTCCGAACGC</td>\n",
              "      <td>26513.914</td>\n",
              "      <td>10016.36700</td>\n",
              "      <td>7070.3770</td>\n",
              "      <td>5564.6484</td>\n",
              "      <td>10540.0990</td>\n",
              "      <td>4058.9202</td>\n",
              "      <td>3404.2556</td>\n",
              "      <td>7725.0415</td>\n",
              "      <td>8837.9720</td>\n",
              "      <td>...</td>\n",
              "      <td>65.46645</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>28</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ERR2538859-AAAGTAGGTTAGTGGG</td>\n",
              "      <td>30791.666</td>\n",
              "      <td>18116.04300</td>\n",
              "      <td>7291.2870</td>\n",
              "      <td>7347.3735</td>\n",
              "      <td>5664.7690</td>\n",
              "      <td>5384.3350</td>\n",
              "      <td>2636.0806</td>\n",
              "      <td>8469.1100</td>\n",
              "      <td>3140.8620</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>ERR2538860-TTTGGTTTCGTTACGA</td>\n",
              "      <td>20833.332</td>\n",
              "      <td>11986.30100</td>\n",
              "      <td>5707.7627</td>\n",
              "      <td>6849.3150</td>\n",
              "      <td>6563.9270</td>\n",
              "      <td>5707.7627</td>\n",
              "      <td>3139.2693</td>\n",
              "      <td>14554.7940</td>\n",
              "      <td>1141.5525</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>ERR2538860-TTTGTCAAGCCCAACC</td>\n",
              "      <td>73876.350</td>\n",
              "      <td>172.20595</td>\n",
              "      <td>13776.4760</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5510.5903</td>\n",
              "      <td>9126.9150</td>\n",
              "      <td>18598.2420</td>\n",
              "      <td>10160.1510</td>\n",
              "      <td>7577.0615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>ERR2538860-TTTGTCACATTGGGCC</td>\n",
              "      <td>22690.557</td>\n",
              "      <td>14539.58000</td>\n",
              "      <td>3524.7466</td>\n",
              "      <td>4038.7722</td>\n",
              "      <td>10060.2140</td>\n",
              "      <td>2570.1277</td>\n",
              "      <td>3671.6110</td>\n",
              "      <td>8003.4385</td>\n",
              "      <td>6094.8745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>ERR2538860-TTTGTCAGTTGCGTTA</td>\n",
              "      <td>54775.516</td>\n",
              "      <td>5771.68550</td>\n",
              "      <td>11874.2080</td>\n",
              "      <td>2830.3457</td>\n",
              "      <td>6992.6187</td>\n",
              "      <td>11654.3640</td>\n",
              "      <td>8047.0615</td>\n",
              "      <td>8713.0250</td>\n",
              "      <td>6160.1640</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1426</th>\n",
              "      <td>ERR2538860-TTTGTCATCAACACCA</td>\n",
              "      <td>15493.742</td>\n",
              "      <td>8285.11500</td>\n",
              "      <td>4150.8433</td>\n",
              "      <td>3748.4860</td>\n",
              "      <td>9015.5320</td>\n",
              "      <td>5151.7656</td>\n",
              "      <td>2383.6526</td>\n",
              "      <td>7515.4080</td>\n",
              "      <td>4632.7440</td>\n",
              "      <td>...</td>\n",
              "      <td>96.11503</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1427 rows × 1510 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7848c6f5-de65-42ff-a3ab-b6f737d9c240')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7848c6f5-de65-42ff-a3ab-b6f737d9c240 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7848c6f5-de65-42ff-a3ab-b6f737d9c240');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_filtered"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_filtered.to_csv('final_df.csv',index=False) # save the filtered file for future use"
      ],
      "metadata": {
        "id": "PBkYhn3WrU0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset (csv ready, already filtered)"
      ],
      "metadata": {
        "id": "QHQhGkR0tcac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This stage skips all of the preceding steps because the csv that we load is the result of all of the preceding."
      ],
      "metadata": {
        "id": "mEinMD2B_ppi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = pd.read_csv('final_df.csv')"
      ],
      "metadata": {
        "id": "xAdiToTCKB5w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "hAaKldMcu1iE",
        "outputId": "3b22630c-1876-46f6-aa94-53a1bb502cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             cell  ENSG00000205542  ENSG00000198804  \\\n",
              "0     ERR2538859-AAACCTGAGACCACGA        32962.305       9065.20200   \n",
              "1     ERR2538859-AAACCTGTCTGATACG        34861.200          0.00000   \n",
              "2     ERR2538859-AAACGGGAGTGTTGAA        17791.770       9193.14500   \n",
              "3     ERR2538859-AAAGATGTCCGAACGC        26513.914      10016.36700   \n",
              "4     ERR2538859-AAAGTAGGTTAGTGGG        30791.666      18116.04300   \n",
              "...                           ...              ...              ...   \n",
              "1422  ERR2538860-TTTGGTTTCGTTACGA        20833.332      11986.30100   \n",
              "1423  ERR2538860-TTTGTCAAGCCCAACC        73876.350        172.20595   \n",
              "1424  ERR2538860-TTTGTCACATTGGGCC        22690.557      14539.58000   \n",
              "1425  ERR2538860-TTTGTCAGTTGCGTTA        54775.516       5771.68550   \n",
              "1426  ERR2538860-TTTGTCATCAACACCA        15493.742       8285.11500   \n",
              "\n",
              "      ENSG00000167996  ENSG00000198712  ENSG00000156508  ENSG00000087086  \\\n",
              "0           8240.5760        5350.2246        4735.2563        5042.7400   \n",
              "1           5579.0670           0.0000       16139.4430        4519.0444   \n",
              "2           4845.0840        3431.0170       13334.9840        4739.7560   \n",
              "3           7070.3770        5564.6484       10540.0990        4058.9202   \n",
              "4           7291.2870        7347.3735        5664.7690        5384.3350   \n",
              "...               ...              ...              ...              ...   \n",
              "1422        5707.7627        6849.3150        6563.9270        5707.7627   \n",
              "1423       13776.4760           0.0000        5510.5903        9126.9150   \n",
              "1424        3524.7466        4038.7722       10060.2140        2570.1277   \n",
              "1425       11874.2080        2830.3457        6992.6187       11654.3640   \n",
              "1426        4150.8433        3748.4860        9015.5320        5151.7656   \n",
              "\n",
              "      ENSG00000075624  ENSG00000229117  ENSG00000026025  ...  ENSG00000185565  \\\n",
              "0           4950.4950        9255.0700        3659.0615  ...          0.00000   \n",
              "1           3873.4666       12696.3620        3443.0813  ...          0.00000   \n",
              "2           1061.1393       14643.7230        2193.0212  ...         70.74262   \n",
              "3           3404.2556        7725.0415        8837.9720  ...         65.46645   \n",
              "4           2636.0806        8469.1100        3140.8620  ...          0.00000   \n",
              "...               ...              ...              ...  ...              ...   \n",
              "1422        3139.2693       14554.7940        1141.5525  ...          0.00000   \n",
              "1423       18598.2420       10160.1510        7577.0615  ...          0.00000   \n",
              "1424        3671.6110        8003.4385        6094.8745  ...          0.00000   \n",
              "1425        8047.0615        8713.0250        6160.1640  ...          0.00000   \n",
              "1426        2383.6526        7515.4080        4632.7440  ...         96.11503   \n",
              "\n",
              "      cluster_2  cluster_4  cluster_7  cluster_8  cluster_11  cluster_18  \\\n",
              "0             1          3          3          3           2           2   \n",
              "1             2          2          6          7           7           3   \n",
              "2             1          1          1          1           1          14   \n",
              "3             1          4          5          5          10          18   \n",
              "4             1          4          4          6           5           7   \n",
              "...         ...        ...        ...        ...         ...         ...   \n",
              "1422          1          2          5          4           3           9   \n",
              "1423          2          2          6          7           7           3   \n",
              "1424          1          1          2          2           4          13   \n",
              "1425          1          1          2          2           6           8   \n",
              "1426          1          3          3          3           2           2   \n",
              "\n",
              "      cluster_23  cluster_31  cluster_37  \n",
              "0             19          17          12  \n",
              "1              6           6           1  \n",
              "2             14          26          26  \n",
              "3             22          28          33  \n",
              "4             20          11          21  \n",
              "...          ...         ...         ...  \n",
              "1422           3           5           5  \n",
              "1423           6          25           1  \n",
              "1424          13          12           8  \n",
              "1425           7          13          11  \n",
              "1426           1           2          23  \n",
              "\n",
              "[1427 rows x 1510 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-789b0ea8-cc5c-41ef-a9c2-1b43331d5010\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell</th>\n",
              "      <th>ENSG00000205542</th>\n",
              "      <th>ENSG00000198804</th>\n",
              "      <th>ENSG00000167996</th>\n",
              "      <th>ENSG00000198712</th>\n",
              "      <th>ENSG00000156508</th>\n",
              "      <th>ENSG00000087086</th>\n",
              "      <th>ENSG00000075624</th>\n",
              "      <th>ENSG00000229117</th>\n",
              "      <th>ENSG00000026025</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000185565</th>\n",
              "      <th>cluster_2</th>\n",
              "      <th>cluster_4</th>\n",
              "      <th>cluster_7</th>\n",
              "      <th>cluster_8</th>\n",
              "      <th>cluster_11</th>\n",
              "      <th>cluster_18</th>\n",
              "      <th>cluster_23</th>\n",
              "      <th>cluster_31</th>\n",
              "      <th>cluster_37</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ERR2538859-AAACCTGAGACCACGA</td>\n",
              "      <td>32962.305</td>\n",
              "      <td>9065.20200</td>\n",
              "      <td>8240.5760</td>\n",
              "      <td>5350.2246</td>\n",
              "      <td>4735.2563</td>\n",
              "      <td>5042.7400</td>\n",
              "      <td>4950.4950</td>\n",
              "      <td>9255.0700</td>\n",
              "      <td>3659.0615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ERR2538859-AAACCTGTCTGATACG</td>\n",
              "      <td>34861.200</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>5579.0670</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>16139.4430</td>\n",
              "      <td>4519.0444</td>\n",
              "      <td>3873.4666</td>\n",
              "      <td>12696.3620</td>\n",
              "      <td>3443.0813</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ERR2538859-AAACGGGAGTGTTGAA</td>\n",
              "      <td>17791.770</td>\n",
              "      <td>9193.14500</td>\n",
              "      <td>4845.0840</td>\n",
              "      <td>3431.0170</td>\n",
              "      <td>13334.9840</td>\n",
              "      <td>4739.7560</td>\n",
              "      <td>1061.1393</td>\n",
              "      <td>14643.7230</td>\n",
              "      <td>2193.0212</td>\n",
              "      <td>...</td>\n",
              "      <td>70.74262</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ERR2538859-AAAGATGTCCGAACGC</td>\n",
              "      <td>26513.914</td>\n",
              "      <td>10016.36700</td>\n",
              "      <td>7070.3770</td>\n",
              "      <td>5564.6484</td>\n",
              "      <td>10540.0990</td>\n",
              "      <td>4058.9202</td>\n",
              "      <td>3404.2556</td>\n",
              "      <td>7725.0415</td>\n",
              "      <td>8837.9720</td>\n",
              "      <td>...</td>\n",
              "      <td>65.46645</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>28</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ERR2538859-AAAGTAGGTTAGTGGG</td>\n",
              "      <td>30791.666</td>\n",
              "      <td>18116.04300</td>\n",
              "      <td>7291.2870</td>\n",
              "      <td>7347.3735</td>\n",
              "      <td>5664.7690</td>\n",
              "      <td>5384.3350</td>\n",
              "      <td>2636.0806</td>\n",
              "      <td>8469.1100</td>\n",
              "      <td>3140.8620</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>ERR2538860-TTTGGTTTCGTTACGA</td>\n",
              "      <td>20833.332</td>\n",
              "      <td>11986.30100</td>\n",
              "      <td>5707.7627</td>\n",
              "      <td>6849.3150</td>\n",
              "      <td>6563.9270</td>\n",
              "      <td>5707.7627</td>\n",
              "      <td>3139.2693</td>\n",
              "      <td>14554.7940</td>\n",
              "      <td>1141.5525</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>ERR2538860-TTTGTCAAGCCCAACC</td>\n",
              "      <td>73876.350</td>\n",
              "      <td>172.20595</td>\n",
              "      <td>13776.4760</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5510.5903</td>\n",
              "      <td>9126.9150</td>\n",
              "      <td>18598.2420</td>\n",
              "      <td>10160.1510</td>\n",
              "      <td>7577.0615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>ERR2538860-TTTGTCACATTGGGCC</td>\n",
              "      <td>22690.557</td>\n",
              "      <td>14539.58000</td>\n",
              "      <td>3524.7466</td>\n",
              "      <td>4038.7722</td>\n",
              "      <td>10060.2140</td>\n",
              "      <td>2570.1277</td>\n",
              "      <td>3671.6110</td>\n",
              "      <td>8003.4385</td>\n",
              "      <td>6094.8745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>ERR2538860-TTTGTCAGTTGCGTTA</td>\n",
              "      <td>54775.516</td>\n",
              "      <td>5771.68550</td>\n",
              "      <td>11874.2080</td>\n",
              "      <td>2830.3457</td>\n",
              "      <td>6992.6187</td>\n",
              "      <td>11654.3640</td>\n",
              "      <td>8047.0615</td>\n",
              "      <td>8713.0250</td>\n",
              "      <td>6160.1640</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1426</th>\n",
              "      <td>ERR2538860-TTTGTCATCAACACCA</td>\n",
              "      <td>15493.742</td>\n",
              "      <td>8285.11500</td>\n",
              "      <td>4150.8433</td>\n",
              "      <td>3748.4860</td>\n",
              "      <td>9015.5320</td>\n",
              "      <td>5151.7656</td>\n",
              "      <td>2383.6526</td>\n",
              "      <td>7515.4080</td>\n",
              "      <td>4632.7440</td>\n",
              "      <td>...</td>\n",
              "      <td>96.11503</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1427 rows × 1510 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-789b0ea8-cc5c-41ef-a9c2-1b43331d5010')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-789b0ea8-cc5c-41ef-a9c2-1b43331d5010 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-789b0ea8-cc5c-41ef-a9c2-1b43331d5010');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset to features and labels"
      ],
      "metadata": {
        "id": "CGnJUB8Im0G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target variable\n",
        "# If used the final_df.csv, use the second batch of lines\n",
        "# If the whole process was executed from the beggining use the tfirst batch of lines\n",
        "\n",
        "#X = df_filtered.iloc[:,1:-9]\n",
        "#y_labels = df_filtered.iloc[:,-9:]\n",
        "\n",
        "X = final_data.iloc[:,1:-9]\n",
        "y_labels = final_data.iloc[:,-9:]"
      ],
      "metadata": {
        "id": "VmZgBC9hrul4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_features"
      ],
      "metadata": {
        "id": "d2cFBspyr_cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_labels"
      ],
      "metadata": {
        "id": "orIPGXXtsHGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2class classification approach"
      ],
      "metadata": {
        "id": "Aq1mRYK_z9iK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset to two sets(training and test)"
      ],
      "metadata": {
        "id": "j9QG1PWoZ89y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** * The test set will remain hidden in all the procedures below. We will only use it for our final evaluations*"
      ],
      "metadata": {
        "id": "6gvA7TZVBWV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the column named 'cluster_2' from the 'y_labels' DataFrame and store it in the variable 'y'.\n",
        "y = y_labels['cluster_2']\n",
        "\n",
        "y = np.where(y == 1, 0, 1)"
      ],
      "metadata": {
        "id": "EXLi5DGe951P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_std = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "jd3gPGNT97Tu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y to a 1-dimensional array\n",
        "y = np.ravel(y)"
      ],
      "metadata": {
        "id": "cOhtoJi_9-Y9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training/validation set and test set\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X_std, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0xCxgtgS-AaU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANOVA for feature selection"
      ],
      "metadata": {
        "id": "-nCPICXRsfPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of features to keep"
      ],
      "metadata": {
        "id": "4jfTkXF_KWlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main goal of this code is to perform hyperparameter optimization for feature selection (how many features should we keep) using the ANOVA F-test and evaluate the performance of different classifiers on the selected features based on the Matthews correlation coefficient. The Optuna library is used to search for the optimal number of features to select, and the results are stored in the study object, which contains information about the best number of features to keep found during the optimization process.\n",
        "\n",
        "We split the dataset using the *perform_dataset_split()* function in order not to have any leakage of data and evaluate our results in the most appropriate way"
      ],
      "metadata": {
        "id": "EDNvDiBXOS-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_dataset_split(X_train_val, y_train_val):\n",
        "    X_train_features, X_evaluation, y_train_features, y_evaluation = train_test_split(X_train_val, y_train_val, test_size=0.30, random_state=30)\n",
        "    # Perform feature selection on X_train_features only\n",
        "    X_train_features_df = pd.DataFrame(X_train_features)\n",
        "    y_train_features_df = pd.DataFrame(y_train_features)\n",
        "    X_evaluation_df = pd.DataFrame(X_evaluation)\n",
        "    y_evaluation_df = pd.DataFrame(y_evaluation)\n",
        "    return X_train_features_df, y_train_features_df, X_evaluation_df,y_evaluation_df"
      ],
      "metadata": {
        "id": "I_j9Qw6PKVAP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_feature_selection_ANOVA(trial,X_train_features_df,y_train_features_df,X_evaluation_df,y_evaluation_df,scores):\n",
        "  # Define the search space for the number of features\n",
        "  num_features = trial.suggest_int(\"num_features\", 1, X_train_features_df.shape[1])\n",
        "\n",
        "  # Perform feature selection on the training set\n",
        "  feature_selector = SelectKBest(score_func=f_classif, k=num_features)\n",
        "  X_train_features_selected_df = feature_selector.fit_transform(X_train_features_df, y_train_features_df)\n",
        "  selected_features = feature_selector.get_support()\n",
        "\n",
        "  # Apply the same feature selection on the validation set\n",
        "  X_evaluation_selected = X_evaluation_df.iloc[:, selected_features]\n",
        "\n",
        "  SVC_cl = SVC()\n",
        "  GNB_cl = GaussianNB()\n",
        "  LR_cl = LogisticRegression()\n",
        "  RF_cl = RandomForestClassifier()\n",
        "  XG_cl = XGBClassifier()\n",
        "\n",
        "  # Train the classifier on the selected features\n",
        "  SVC_cl.fit(X_train_features_selected_df ,y_train_features_df)\n",
        "  GNB_cl.fit(X_train_features_selected_df ,y_train_features_df)\n",
        "  LR_cl.fit(X_train_features_selected_df,y_train_features_df)\n",
        "  RF_cl.fit(X_train_features_selected_df,y_train_features_df)\n",
        "  XG_cl.fit(X_train_features_selected_df,y_train_features_df)\n",
        "\n",
        "  # Make predictions on the validation set\n",
        "  y_pred_SVC = SVC_cl.predict(X_evaluation_selected)\n",
        "  y_pred_GNB = GNB_cl.predict(X_evaluation_selected)\n",
        "  y_pred_LR = LR_cl.predict(X_evaluation_selected)\n",
        "  y_pred_RF = RF_cl.predict(X_evaluation_selected)\n",
        "  y_pred_XG = XG_cl.predict(X_evaluation_selected)\n",
        "\n",
        "  # Calculate the accuracy score\n",
        "  mcc_features_evaluation_GNB = matthews_corrcoef(y_evaluation_df, y_pred_GNB)\n",
        "  scores.append(mcc_features_evaluation_GNB)\n",
        "  mcc_features_evaluation_LR = matthews_corrcoef(y_evaluation_df, y_pred_LR)\n",
        "  scores.append(mcc_features_evaluation_LR)\n",
        "  mcc_features_evaluation_RF = matthews_corrcoef(y_evaluation_df, y_pred_RF)\n",
        "  scores.append(mcc_features_evaluation_RF)\n",
        "  mcc_features_evaluation_XG = matthews_corrcoef(y_evaluation_df, y_pred_XG)\n",
        "  scores.append(mcc_features_evaluation_XG)\n",
        "\n",
        "  avg_mcc = np.mean(scores) # we get the average in order to find the optimal number of features to keep according to all classifiers\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "WW_QWy3fKVAQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature selection\n",
        "X_train_features_df,y_train_features_df,X_evaluation_df,y_evaluation_df = perform_dataset_split(X_train_val, y_train_val)"
      ],
      "metadata": {
        "id": "Y00jLjJAKVAQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores=[]"
      ],
      "metadata": {
        "id": "WnvDJxD9KVAQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function with selected features\n",
        "def objective(trial):\n",
        "    return objective_feature_selection_ANOVA(trial,X_train_features_df,y_train_features_df,X_evaluation_df,y_evaluation_df,scores)"
      ],
      "metadata": {
        "id": "t44olM1-KVAQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "YBHqtXxwNifp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC\n",
        "\n"
      ],
      "metadata": {
        "id": "y40rQ53-zzaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "VPI1_xVTs8ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main goal of the provided code is to perform hyperparameter tuning for a Support Vector Machine (SVM) classifier (specifically, the SVC implementation) using the Optuna library.\n",
        "The code also stores the best set of features selected during the hyperparameter tuning in the best_features variable. If the hyperparameter tuning process is pruned (terminated early), the best_features variable will be set to the selected features of the last trial that was not pruned."
      ],
      "metadata": {
        "id": "Cp8OxYPwO4ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "RR_f70eU-J45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Optuna hyperparameter tuning\n",
        "def objective_SVC(trial):\n",
        "  global best_features\n",
        "  # Define the hyperparameters to be optimized\n",
        "  C = trial.suggest_float('C', 0.1, 10)\n",
        "  gamma = trial.suggest_float('gamma', 0.01, 1)\n",
        "  kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "  degree = trial.suggest_int('degree', 2, 10)\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  classifier = SVC(C=C, gamma=gamma,kernel=kernel,degree=degree)\n",
        "\n",
        "  # Perform cross-validation with feature selection\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "  feature_selector = SelectKBest(score_func=f_classif, k=300)  # Adjust the number of features as desired or found through optimization\n",
        "  best_features = None\n",
        "\n",
        "  for train_index, val_index in kf.split(X_train_val, y_train_val):\n",
        "      X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "      y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "\n",
        "      # Perform feature selection on the training set\n",
        "      X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
        "      selected_features = feature_selector.get_support()\n",
        "\n",
        "      # Apply the same feature selection on the validation set\n",
        "      X_val_selected = X_val[:, selected_features]\n",
        "\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train_selected, y_train)\n",
        "      y_pred = classifier.predict(X_val_selected)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  if trial.should_prune()==False:\n",
        "    best_features = selected_features.copy()\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "62QAjmsI8m8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Optuna study\n",
        "study = optuna.create_study(direction='maximize',sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective_SVC, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWD4at4c9v6A",
        "outputId": "680fc219-b6f4-4210-847b-6f1096a26792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 09:00:11,830] A new study created in memory with name: no-name-b79a7270-e773-457e-8073-8bc20ea9fad6\n",
            "[I 2023-06-23 09:00:12,047] Trial 0 finished with value: 0.8791884824338855 and parameters: {'C': 3.807947176588889, 'gamma': 0.951207163345817, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:13,547] Trial 1 finished with value: 0.0 and parameters: {'C': 8.675143843171858, 'gamma': 0.6051038616257767, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:14,050] Trial 2 finished with value: 0.3347510634344725 and parameters: {'C': 1.9000671753502962, 'gamma': 0.1915704647548995, 'kernel': 'poly', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:15,093] Trial 3 finished with value: 0.0 and parameters: {'C': 1.4809892204552142, 'gamma': 0.29922320204986597, 'kernel': 'rbf', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:15,342] Trial 4 finished with value: -0.05011836656935418 and parameters: {'C': 5.96490423173422, 'gamma': 0.05598590859279775, 'kernel': 'sigmoid', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:15,676] Trial 5 finished with value: 0.36047227221619355 and parameters: {'C': 8.103133746352965, 'gamma': 0.31156763148163696, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:16,013] Trial 6 finished with value: 0.36047227221619355 and parameters: {'C': 0.4404463590406621, 'gamma': 0.9102271980579942, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:16,700] Trial 7 finished with value: 0.037270108055840766 and parameters: {'C': 1.9300591097027178, 'gamma': 0.9698887814869129, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:17,805] Trial 8 finished with value: 0.0 and parameters: {'C': 0.976075770314003, 'gamma': 0.20402303379495376, 'kernel': 'rbf', 'degree': 9}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:18,894] Trial 9 finished with value: 0.0 and parameters: {'C': 3.631857934266534, 'gamma': 0.28812516459050697, 'kernel': 'rbf', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:19,375] Trial 10 finished with value: 0.11017281489195199 and parameters: {'C': 7.7452232160369086, 'gamma': 0.2067285247188307, 'kernel': 'poly', 'degree': 8}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:19,587] Trial 11 finished with value: 0.7877843217243251 and parameters: {'C': 0.8330420521674946, 'gamma': 0.3648810712588299, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:20,694] Trial 12 finished with value: 0.0 and parameters: {'C': 3.178724984985056, 'gamma': 0.3319314888064796, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:20,993] Trial 13 finished with value: 0.6577425511325593 and parameters: {'C': 7.16112339350765, 'gamma': 0.7631771981307285, 'kernel': 'poly', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:21,696] Trial 14 finished with value: 0.037270108055840766 and parameters: {'C': 0.35164935476654235, 'gamma': 0.1168125127233714, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:21,859] Trial 15 finished with value: 0.8791884824338855 and parameters: {'C': 2.567993068573862, 'gamma': 0.41627909380527345, 'kernel': 'linear', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:22,552] Trial 16 finished with value: 0.037270108055840766 and parameters: {'C': 9.304006758191473, 'gamma': 0.8100391757687728, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:22,712] Trial 17 finished with value: 0.8791884824338855 and parameters: {'C': 5.439488194964942, 'gamma': 0.8093657536124219, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:22,907] Trial 18 finished with value: 0.8208275804769783 and parameters: {'C': 8.198346182632681, 'gamma': 0.86212327742378, 'kernel': 'poly', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:24,353] Trial 19 finished with value: 0.0 and parameters: {'C': 3.442390196895917, 'gamma': 0.943480606873394, 'kernel': 'rbf', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:24,561] Trial 20 finished with value: 0.8791884824338855 and parameters: {'C': 9.628228219926902, 'gamma': 0.2592644728671105, 'kernel': 'linear', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:25,017] Trial 21 finished with value: 0.36047227221619355 and parameters: {'C': 5.076522329965728, 'gamma': 0.06096396373748946, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:25,404] Trial 22 finished with value: 0.6577425511325593 and parameters: {'C': 9.857939495694946, 'gamma': 0.2496347187963854, 'kernel': 'poly', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:26,842] Trial 23 finished with value: 0.0 and parameters: {'C': 6.359827722876437, 'gamma': 0.6371944136532858, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:27,002] Trial 24 finished with value: 0.8791884824338855 and parameters: {'C': 0.5036739013921628, 'gamma': 0.5949840137563595, 'kernel': 'linear', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:27,193] Trial 25 finished with value: 0.8208275804769783 and parameters: {'C': 1.8262276471494154, 'gamma': 0.6940283607214413, 'kernel': 'poly', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:28,332] Trial 26 finished with value: 0.0 and parameters: {'C': 9.254466820957772, 'gamma': 0.8785659598471712, 'kernel': 'rbf', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:28,623] Trial 27 finished with value: 0.6577425511325593 and parameters: {'C': 2.4943376799144716, 'gamma': 0.10217174012784021, 'kernel': 'poly', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:28,787] Trial 28 finished with value: 0.8791884824338855 and parameters: {'C': 7.286961220815369, 'gamma': 0.8981391573530513, 'kernel': 'linear', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:29,895] Trial 29 finished with value: 0.0 and parameters: {'C': 8.995686466418084, 'gamma': 0.6103647690629941, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:31,018] Trial 30 finished with value: 0.0 and parameters: {'C': 5.532464514729202, 'gamma': 0.6949762457157663, 'kernel': 'rbf', 'degree': 4}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:31,178] Trial 31 finished with value: 0.8791884824338855 and parameters: {'C': 7.490264910668439, 'gamma': 0.6531365700567425, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:31,339] Trial 32 finished with value: 0.8791884824338855 and parameters: {'C': 2.7255034400490823, 'gamma': 0.25154974694529275, 'kernel': 'linear', 'degree': 9}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:32,476] Trial 33 finished with value: 0.0 and parameters: {'C': 5.076107221741402, 'gamma': 0.5811348457800956, 'kernel': 'rbf', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:32,685] Trial 34 finished with value: 0.7877843217243251 and parameters: {'C': 6.490175729480962, 'gamma': 0.18533957261297845, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:32,858] Trial 35 finished with value: 0.8791884824338855 and parameters: {'C': 9.29035376961848, 'gamma': 0.4339023068341412, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:33,974] Trial 36 finished with value: 0.0 and parameters: {'C': 8.526253048016883, 'gamma': 0.3237527851047149, 'kernel': 'rbf', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:34,134] Trial 37 finished with value: 0.8791884824338855 and parameters: {'C': 1.0620472883306085, 'gamma': 0.618857154432178, 'kernel': 'linear', 'degree': 8}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:34,392] Trial 38 finished with value: -0.039450770839979235 and parameters: {'C': 7.000455835853153, 'gamma': 0.7054592431472382, 'kernel': 'sigmoid', 'degree': 9}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:34,967] Trial 39 finished with value: 0.2296437775002586 and parameters: {'C': 9.141081470309066, 'gamma': 0.5162289748723284, 'kernel': 'poly', 'degree': 9}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:36,075] Trial 40 finished with value: 0.0 and parameters: {'C': 8.911052883993907, 'gamma': 0.3446152052830205, 'kernel': 'rbf', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:36,325] Trial 41 finished with value: -0.051912503827278834 and parameters: {'C': 5.472181883605009, 'gamma': 0.29367583960700155, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:36,527] Trial 42 finished with value: 0.8791884824338855 and parameters: {'C': 1.3578990752536595, 'gamma': 0.5270208274542564, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:38,161] Trial 43 finished with value: 0.0 and parameters: {'C': 5.360410852524665, 'gamma': 0.5452287703940054, 'kernel': 'rbf', 'degree': 4}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:38,475] Trial 44 finished with value: -0.05077003341362964 and parameters: {'C': 7.972343328210166, 'gamma': 0.27812392874945346, 'kernel': 'sigmoid', 'degree': 9}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:38,801] Trial 45 finished with value: -0.037542280185228226 and parameters: {'C': 6.9901446403276095, 'gamma': 0.4148634149701272, 'kernel': 'sigmoid', 'degree': 8}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:39,016] Trial 46 finished with value: 0.8791884824338855 and parameters: {'C': 6.635954029505539, 'gamma': 0.2871345579764834, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:39,230] Trial 47 finished with value: 0.8791884824338855 and parameters: {'C': 2.552536796061459, 'gamma': 0.362412951864749, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:40,425] Trial 48 finished with value: 0.0 and parameters: {'C': 8.56905978170897, 'gamma': 0.7066212807862234, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:40,935] Trial 49 finished with value: 0.3347510634344725 and parameters: {'C': 4.395131327455933, 'gamma': 0.4045196870533997, 'kernel': 'poly', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:41,098] Trial 50 finished with value: 0.8791884824338855 and parameters: {'C': 5.081048959942868, 'gamma': 0.857924942776439, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:42,267] Trial 51 finished with value: 0.0 and parameters: {'C': 5.899178254607286, 'gamma': 0.940827939010708, 'kernel': 'rbf', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:42,427] Trial 52 finished with value: 0.8791884824338855 and parameters: {'C': 9.4205016068876, 'gamma': 0.39224161142276653, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:42,694] Trial 53 finished with value: -0.024913536121772734 and parameters: {'C': 0.28039607395034233, 'gamma': 0.1034985311483691, 'kernel': 'sigmoid', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:42,944] Trial 54 finished with value: -0.049634696224709215 and parameters: {'C': 8.163237977630464, 'gamma': 0.28903622702566595, 'kernel': 'sigmoid', 'degree': 8}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:43,197] Trial 55 finished with value: -0.049634696224709215 and parameters: {'C': 8.05446121081, 'gamma': 0.28921422684559345, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:43,691] Trial 56 finished with value: 0.11017281489195199 and parameters: {'C': 3.782979049348554, 'gamma': 0.7786488311345768, 'kernel': 'poly', 'degree': 8}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:43,854] Trial 57 finished with value: 0.8791884824338855 and parameters: {'C': 7.5699744534383555, 'gamma': 0.11209263014757327, 'kernel': 'linear', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:44,103] Trial 58 finished with value: 0.006969612779377804 and parameters: {'C': 3.953096619468215, 'gamma': 0.020729274965495377, 'kernel': 'sigmoid', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:44,353] Trial 59 finished with value: -0.036834263649123206 and parameters: {'C': 5.777035092420532, 'gamma': 0.6355188400481013, 'kernel': 'sigmoid', 'degree': 8}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:44,605] Trial 60 finished with value: -0.03572832155785104 and parameters: {'C': 7.9366325328859, 'gamma': 0.7917219613666083, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:45,682] Trial 61 finished with value: 0.0 and parameters: {'C': 8.888271409307167, 'gamma': 0.3574058624265579, 'kernel': 'rbf', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:45,898] Trial 62 finished with value: 0.7877843217243251 and parameters: {'C': 0.9326573805384746, 'gamma': 0.7039594401445288, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:46,163] Trial 63 finished with value: -0.037542280185228226 and parameters: {'C': 9.867731827161636, 'gamma': 0.3805280877985591, 'kernel': 'sigmoid', 'degree': 8}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:46,426] Trial 64 finished with value: -0.04383452473848366 and parameters: {'C': 3.824969896756066, 'gamma': 0.09266570953168207, 'kernel': 'sigmoid', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:46,590] Trial 65 finished with value: 0.8791884824338855 and parameters: {'C': 4.976988532479505, 'gamma': 0.021240108319744877, 'kernel': 'linear', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:46,751] Trial 66 finished with value: 0.8791884824338855 and parameters: {'C': 7.48584430472769, 'gamma': 0.587535077446188, 'kernel': 'linear', 'degree': 4}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:46,922] Trial 67 finished with value: 0.8791884824338855 and parameters: {'C': 9.635903140462052, 'gamma': 0.022032929942918177, 'kernel': 'linear', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:47,085] Trial 68 finished with value: 0.8791884824338855 and parameters: {'C': 0.8305859908804487, 'gamma': 0.5583157415573076, 'kernel': 'linear', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:47,340] Trial 69 finished with value: -0.03917089909903507 and parameters: {'C': 6.312824992832228, 'gamma': 0.5884711688038693, 'kernel': 'sigmoid', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:48,491] Trial 70 finished with value: 0.0 and parameters: {'C': 4.611001852578558, 'gamma': 0.6239312718235214, 'kernel': 'rbf', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:48,653] Trial 71 finished with value: 0.8791884824338855 and parameters: {'C': 0.8695729059533499, 'gamma': 0.9746508595895048, 'kernel': 'linear', 'degree': 9}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:49,862] Trial 72 finished with value: 0.0 and parameters: {'C': 6.878838608283405, 'gamma': 0.17099076995144238, 'kernel': 'rbf', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:50,069] Trial 73 finished with value: 0.8791884824338855 and parameters: {'C': 4.240606059277127, 'gamma': 0.9334011985204731, 'kernel': 'linear', 'degree': 9}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:51,675] Trial 74 finished with value: 0.0 and parameters: {'C': 9.87403368021795, 'gamma': 0.15891272219249292, 'kernel': 'rbf', 'degree': 9}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:53,019] Trial 75 finished with value: 0.0 and parameters: {'C': 4.740062281970205, 'gamma': 0.42067130731428853, 'kernel': 'rbf', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:53,361] Trial 76 finished with value: 0.36047227221619355 and parameters: {'C': 9.966704687031664, 'gamma': 0.5598773885466012, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:54,510] Trial 77 finished with value: 0.0 and parameters: {'C': 1.3786782099998005, 'gamma': 0.9545105169861352, 'kernel': 'rbf', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:54,748] Trial 78 finished with value: -0.035181912026595354 and parameters: {'C': 1.2242201627763274, 'gamma': 0.6748574636368716, 'kernel': 'sigmoid', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:55,000] Trial 79 finished with value: -0.039269913788501386 and parameters: {'C': 5.653285918200324, 'gamma': 0.8778870666317615, 'kernel': 'sigmoid', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:55,248] Trial 80 finished with value: -0.038687180395377926 and parameters: {'C': 7.070389704182313, 'gamma': 0.22083451989382163, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:56,432] Trial 81 finished with value: 0.0 and parameters: {'C': 4.431001728034918, 'gamma': 0.9051171075488109, 'kernel': 'rbf', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:56,773] Trial 82 finished with value: 0.36047227221619355 and parameters: {'C': 8.637400716592778, 'gamma': 0.9500254174210657, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:56,966] Trial 83 finished with value: 0.8208275804769783 and parameters: {'C': 9.802322495326223, 'gamma': 0.4976919130529409, 'kernel': 'poly', 'degree': 3}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:57,639] Trial 84 finished with value: 0.037270108055840766 and parameters: {'C': 1.3676538056819474, 'gamma': 0.1603836665771714, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:57,895] Trial 85 finished with value: 0.6313245135338412 and parameters: {'C': 4.792220238602436, 'gamma': 0.6708821611358169, 'kernel': 'poly', 'degree': 4}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:58,220] Trial 86 finished with value: 0.36047227221619355 and parameters: {'C': 1.8524037943397935, 'gamma': 0.09781550841948505, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:58,472] Trial 87 finished with value: -0.04607300231962285 and parameters: {'C': 6.934908803430717, 'gamma': 0.04891901844268795, 'kernel': 'sigmoid', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:58,626] Trial 88 finished with value: 0.8791884824338855 and parameters: {'C': 0.7046718025631511, 'gamma': 0.2841088716657317, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:00:59,762] Trial 89 finished with value: 0.0 and parameters: {'C': 4.896777553391111, 'gamma': 0.622072223814993, 'kernel': 'rbf', 'degree': 4}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:00,104] Trial 90 finished with value: 0.36047227221619355 and parameters: {'C': 7.162160900257069, 'gamma': 0.8962547693103273, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:00,266] Trial 91 finished with value: 0.8791884824338855 and parameters: {'C': 2.500457985983824, 'gamma': 0.2765507986398872, 'kernel': 'linear', 'degree': 4}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:01,727] Trial 92 finished with value: 0.0 and parameters: {'C': 1.2856451050105873, 'gamma': 0.891622007932496, 'kernel': 'rbf', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:01,888] Trial 93 finished with value: 0.8791884824338855 and parameters: {'C': 5.417354764003623, 'gamma': 0.5909727068406704, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:02,095] Trial 94 finished with value: 0.7877843217243251 and parameters: {'C': 6.494580689182852, 'gamma': 0.5750705216222227, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:03,500] Trial 95 finished with value: 0.0 and parameters: {'C': 1.6133054779248872, 'gamma': 0.25349815110066304, 'kernel': 'rbf', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:04,467] Trial 96 finished with value: 0.037270108055840766 and parameters: {'C': 0.8943140820502579, 'gamma': 0.5292662756745521, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:04,789] Trial 97 finished with value: -0.039302762872612196 and parameters: {'C': 8.668520546350404, 'gamma': 0.8189013502397872, 'kernel': 'sigmoid', 'degree': 7}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:05,001] Trial 98 finished with value: 0.8791884824338855 and parameters: {'C': 5.758965625752008, 'gamma': 0.28717930272368136, 'kernel': 'linear', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n",
            "[I 2023-06-23 09:01:05,210] Trial 99 finished with value: 0.8791884824338855 and parameters: {'C': 2.4998563509092944, 'gamma': 0.1236884564918115, 'kernel': 'linear', 'degree': 6}. Best is trial 0 with value: 0.8791884824338855.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "4DZOp2qV8m27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv7CFYFPdvcz",
        "outputId": "7513d6a6-57a3-4ae0-8c3c-57583009ad86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 3.807947176588889,\n",
              " 'gamma': 0.951207163345817,\n",
              " 'kernel': 'linear',\n",
              " 'degree': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xeMlNlpFidq",
        "outputId": "c643fd8a-758b-46fe-d343-21641ac02ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, ..., False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "##### We suggest executing the notebook \"*Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb*\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "NImo9DHfzfhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "PmRKsJK4wewQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "8M6oV_oAxZ7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLDTmPejwetd",
        "outputId": "931f946b-e2aa-4db8-d5bc-faf52bceaba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best_classifier_SVC = SVC('C': 3.807947176588889,gamma=0.951207163345817,kernel= 'linear',degree= 2) # in case something is wrong with the parameter **best_params\n",
        "best_classifier_SVC = SVC(**best_params)"
      ],
      "metadata": {
        "id": "B4Vy_aQpweqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_SVC.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "6sKY-YjPwene",
        "outputId": "17096830-2467-4f31-e783-129607a2fd82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=3.807947176588889, degree=2, gamma=0.951207163345817, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=3.807947176588889, degree=2, gamma=0.951207163345817, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=3.807947176588889, degree=2, gamma=0.951207163345817, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_SVC.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "Gy4YZNL9wekn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "dEWHhqiJwehs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "Y3xh8pmBzmXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "32MLcGvO0T3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main goal of the provided code is to perform hyperparameter tuning for a RandomForest classifier using the Optuna library.\n",
        "The code also stores the best set of features selected during the hyperparameter tuning in the best_features variable. If the hyperparameter tuning process is pruned (terminated early), the best_features variable will be set to the selected features of the last trial that was not pruned."
      ],
      "metadata": {
        "id": "dUFFgoHZPf8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "_TlPeD810T3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Optuna hyperparameter tuning\n",
        "def objective_RF(trial):\n",
        "  global best_features\n",
        "  # Define the hyperparameters to be optimized\n",
        "  n_estimators= trial.suggest_int('n_estimators', 100,1000)\n",
        "  max_depth= trial.suggest_int('max_depth', 5, 31)\n",
        "  min_samples_split= trial.suggest_int('min_samples_split', 2, 100)\n",
        "  min_samples_leaf= trial.suggest_int('min_samples_leaf', 1, 4)\n",
        "  bootstrap=trial.suggest_categorical('bootstrap', [True, False])\n",
        "\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,min_samples_split=min_samples_split,min_samples_leaf=min_samples_leaf,bootstrap=bootstrap)\n",
        "\n",
        "  # Perform cross-validation with feature selection\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "  feature_selector = SelectKBest(score_func=f_classif, k=300)  # Adjust the number of features as desired\n",
        "  best_features = None\n",
        "\n",
        "  for train_index, val_index in kf.split(X_train_val, y_train_val):\n",
        "      X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "      y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "\n",
        "      # Perform feature selection on the training set\n",
        "      X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
        "      selected_features = feature_selector.get_support()\n",
        "\n",
        "      # Apply the same feature selection on the validation set\n",
        "      X_val_selected = X_val[:, selected_features]\n",
        "\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train_selected, y_train)\n",
        "      y_pred = classifier.predict(X_val_selected)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  if trial.should_prune()==False:\n",
        "    best_features = selected_features.copy()\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "kbPc-XgT0T3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Optuna study\n",
        "study = optuna.create_study(direction='maximize',sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective_RF, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e995e11c-d6eb-46a0-dafe-07d0cf13a9c2",
        "id": "dAxE-6390T3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 09:59:24,345] A new study created in memory with name: no-name-8965de21-3a04-4fa3-9955-d4ede5192c4c\n",
            "[I 2023-06-23 09:59:34,718] Trial 0 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 437, 'max_depth': 30, 'min_samples_split': 74, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 0 with value: 0.9586952887473211.\n",
            "[I 2023-06-23 09:59:42,288] Trial 1 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 152, 'max_depth': 28, 'min_samples_split': 61, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 0.9586952887473211.\n",
            "[I 2023-06-23 10:00:14,844] Trial 2 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 850, 'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:00:29,887] Trial 3 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 489, 'max_depth': 12, 'min_samples_split': 62, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:00:41,167] Trial 4 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 510, 'max_depth': 26, 'min_samples_split': 21, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:00:55,069] Trial 5 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 647, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:01:06,277] Trial 6 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 374, 'max_depth': 7, 'min_samples_split': 69, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:01:09,918] Trial 7 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 130, 'max_depth': 29, 'min_samples_split': 27, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:01:22,342] Trial 8 finished with value: 0.9367912032292331 and parameters: {'n_estimators': 592, 'max_depth': 9, 'min_samples_split': 97, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:01:42,518] Trial 9 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 638, 'max_depth': 29, 'min_samples_split': 10, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:01:55,866] Trial 10 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 450, 'max_depth': 12, 'min_samples_split': 84, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:02:00,874] Trial 11 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 226, 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:02:03,000] Trial 12 finished with value: 0.9440248199963859 and parameters: {'n_estimators': 104, 'max_depth': 27, 'min_samples_split': 71, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:02:12,222] Trial 13 finished with value: 0.9440248199963859 and parameters: {'n_estimators': 422, 'max_depth': 8, 'min_samples_split': 87, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:02:19,697] Trial 14 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 380, 'max_depth': 13, 'min_samples_split': 74, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:02:24,575] Trial 15 finished with value: 0.9437786620795539 and parameters: {'n_estimators': 207, 'max_depth': 24, 'min_samples_split': 77, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:02:42,026] Trial 16 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 570, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:02:53,541] Trial 17 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 383, 'max_depth': 18, 'min_samples_split': 91, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:03:00,437] Trial 18 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 306, 'max_depth': 7, 'min_samples_split': 30, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:03:15,300] Trial 19 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 670, 'max_depth': 28, 'min_samples_split': 81, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:03:40,704] Trial 20 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 827, 'max_depth': 29, 'min_samples_split': 33, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:03:58,451] Trial 21 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 837, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:04:04,253] Trial 22 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 207, 'max_depth': 14, 'min_samples_split': 95, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:04:13,478] Trial 23 finished with value: 0.9437786620795539 and parameters: {'n_estimators': 427, 'max_depth': 31, 'min_samples_split': 97, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:04:23,710] Trial 24 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 356, 'max_depth': 5, 'min_samples_split': 62, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:04:43,791] Trial 25 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 918, 'max_depth': 11, 'min_samples_split': 16, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:05:04,696] Trial 26 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 705, 'max_depth': 25, 'min_samples_split': 25, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:05:18,898] Trial 27 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 670, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:05:21,939] Trial 28 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 136, 'max_depth': 20, 'min_samples_split': 69, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:05:37,023] Trial 29 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 681, 'max_depth': 9, 'min_samples_split': 70, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:05:47,682] Trial 30 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 407, 'max_depth': 8, 'min_samples_split': 93, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:06:13,384] Trial 31 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 836, 'max_depth': 19, 'min_samples_split': 54, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:06:41,050] Trial 32 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 911, 'max_depth': 22, 'min_samples_split': 35, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:07:08,430] Trial 33 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 899, 'max_depth': 26, 'min_samples_split': 65, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:07:26,831] Trial 34 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 646, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:07:39,857] Trial 35 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 594, 'max_depth': 23, 'min_samples_split': 66, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:07:48,441] Trial 36 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 393, 'max_depth': 25, 'min_samples_split': 66, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:07:52,513] Trial 37 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 184, 'max_depth': 14, 'min_samples_split': 28, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:08:11,670] Trial 38 finished with value: 0.9510122788467067 and parameters: {'n_estimators': 903, 'max_depth': 22, 'min_samples_split': 80, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:08:17,882] Trial 39 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 275, 'max_depth': 24, 'min_samples_split': 29, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:08:46,020] Trial 40 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 947, 'max_depth': 30, 'min_samples_split': 92, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:08:59,256] Trial 41 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 485, 'max_depth': 31, 'min_samples_split': 97, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:09:17,859] Trial 42 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 866, 'max_depth': 13, 'min_samples_split': 18, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:09:35,121] Trial 43 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 613, 'max_depth': 7, 'min_samples_split': 62, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:09:53,526] Trial 44 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 890, 'max_depth': 25, 'min_samples_split': 71, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:10:10,832] Trial 45 finished with value: 0.9367912032292331 and parameters: {'n_estimators': 829, 'max_depth': 26, 'min_samples_split': 87, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:10:27,629] Trial 46 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 819, 'max_depth': 22, 'min_samples_split': 71, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:10:40,937] Trial 47 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 438, 'max_depth': 7, 'min_samples_split': 59, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:10:49,260] Trial 48 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 358, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:10:54,068] Trial 49 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 214, 'max_depth': 19, 'min_samples_split': 78, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:10:58,055] Trial 50 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 146, 'max_depth': 19, 'min_samples_split': 55, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:11:10,145] Trial 51 finished with value: 0.9510122788467067 and parameters: {'n_estimators': 565, 'max_depth': 13, 'min_samples_split': 80, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:11:12,571] Trial 52 finished with value: 0.9440248199963859 and parameters: {'n_estimators': 122, 'max_depth': 30, 'min_samples_split': 84, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:11:18,335] Trial 53 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 240, 'max_depth': 11, 'min_samples_split': 56, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:11:37,830] Trial 54 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 960, 'max_depth': 24, 'min_samples_split': 56, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:11:47,648] Trial 55 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 420, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:12:06,653] Trial 56 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 870, 'max_depth': 23, 'min_samples_split': 48, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:12:12,278] Trial 57 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 256, 'max_depth': 16, 'min_samples_split': 41, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:12:21,462] Trial 58 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 437, 'max_depth': 21, 'min_samples_split': 51, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:12:25,441] Trial 59 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 163, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:12:35,318] Trial 60 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 449, 'max_depth': 22, 'min_samples_split': 47, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:12:56,245] Trial 61 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 966, 'max_depth': 29, 'min_samples_split': 21, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:13:00,907] Trial 62 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 185, 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:13:24,754] Trial 63 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 833, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:13:47,677] Trial 64 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 762, 'max_depth': 26, 'min_samples_split': 29, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:14:15,615] Trial 65 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 992, 'max_depth': 16, 'min_samples_split': 38, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:14:39,463] Trial 66 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 873, 'max_depth': 16, 'min_samples_split': 76, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:14:51,248] Trial 67 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 555, 'max_depth': 27, 'min_samples_split': 33, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:15:10,784] Trial 68 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 915, 'max_depth': 7, 'min_samples_split': 33, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:15:29,986] Trial 69 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 669, 'max_depth': 17, 'min_samples_split': 31, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:15:54,323] Trial 70 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 813, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:16:09,410] Trial 71 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 497, 'max_depth': 28, 'min_samples_split': 36, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:16:29,845] Trial 72 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 657, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:16:45,118] Trial 73 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 736, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:17:02,046] Trial 74 finished with value: 0.9367912032292331 and parameters: {'n_estimators': 832, 'max_depth': 30, 'min_samples_split': 99, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:17:24,826] Trial 75 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 800, 'max_depth': 20, 'min_samples_split': 43, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:17:28,063] Trial 76 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 110, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:17:50,384] Trial 77 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 772, 'max_depth': 20, 'min_samples_split': 97, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:17:59,033] Trial 78 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 301, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:18:11,332] Trial 79 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 575, 'max_depth': 31, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:18:30,579] Trial 80 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 667, 'max_depth': 23, 'min_samples_split': 46, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:18:34,247] Trial 81 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 140, 'max_depth': 12, 'min_samples_split': 96, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:18:42,148] Trial 82 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 349, 'max_depth': 10, 'min_samples_split': 47, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:19:09,497] Trial 83 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 977, 'max_depth': 31, 'min_samples_split': 71, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:19:24,021] Trial 84 finished with value: 0.9440248199963859 and parameters: {'n_estimators': 716, 'max_depth': 9, 'min_samples_split': 92, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:19:37,242] Trial 85 finished with value: 0.9440248199963859 and parameters: {'n_estimators': 652, 'max_depth': 16, 'min_samples_split': 94, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:19:47,271] Trial 86 finished with value: 0.9367912032292331 and parameters: {'n_estimators': 439, 'max_depth': 26, 'min_samples_split': 99, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:20:08,718] Trial 87 finished with value: 0.9440248199963859 and parameters: {'n_estimators': 973, 'max_depth': 27, 'min_samples_split': 84, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:20:12,237] Trial 88 finished with value: 0.9510122788467067 and parameters: {'n_estimators': 150, 'max_depth': 28, 'min_samples_split': 82, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:20:28,944] Trial 89 finished with value: 0.9440248199963859 and parameters: {'n_estimators': 792, 'max_depth': 30, 'min_samples_split': 86, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:20:49,121] Trial 90 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 959, 'max_depth': 21, 'min_samples_split': 24, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:20:54,573] Trial 91 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 202, 'max_depth': 23, 'min_samples_split': 53, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:21:07,136] Trial 92 finished with value: 0.9510122788467067 and parameters: {'n_estimators': 597, 'max_depth': 20, 'min_samples_split': 88, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:21:23,639] Trial 93 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 780, 'max_depth': 21, 'min_samples_split': 71, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:21:32,834] Trial 94 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 415, 'max_depth': 20, 'min_samples_split': 40, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:21:48,641] Trial 95 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 563, 'max_depth': 26, 'min_samples_split': 41, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:21:55,767] Trial 96 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 232, 'max_depth': 30, 'min_samples_split': 50, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:22:11,801] Trial 97 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 543, 'max_depth': 13, 'min_samples_split': 64, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:22:17,620] Trial 98 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 215, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 2 with value: 0.9661398274865641.\n",
            "[I 2023-06-23 10:22:37,405] Trial 99 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 908, 'max_depth': 17, 'min_samples_split': 68, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9661398274865641.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "TLK12IKc0T3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZN5XMgrsecR",
        "outputId": "771d5b69-b04c-4878-8176-57510854a816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 850,\n",
              " 'max_depth': 10,\n",
              " 'min_samples_split': 20,\n",
              " 'min_samples_leaf': 1,\n",
              " 'bootstrap': False}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c34c843-5264-4761-9356-46e52dba4327",
        "id": "NeTPmuVV0T3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 854,\n",
              " 'max_depth': 24,\n",
              " 'min_samples_split': 28,\n",
              " 'min_samples_leaf': 3,\n",
              " 'bootstrap': True}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ca7a93-2fa1-40e1-dc77-c882c439d056",
        "id": "Qvoon7Jr0T3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, ..., False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "xtECcua60T3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "lm-QW5NE0T3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "6Mhmg8kg0T3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708ed135-f505-4061-ef04-f3f6cd33daf8",
        "id": "SNgGo5FI0T3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_RF = RandomForestClassifier(**best_params)"
      ],
      "metadata": {
        "id": "lqJO8rFnOzIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_RF.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "2cf0d47f-4c4e-4d27-9335-26b3b89f8f45",
        "id": "6NcEzrRR0T3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, max_depth=10, min_samples_split=20,\n",
              "                       n_estimators=850)"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, max_depth=10, min_samples_split=20,\n",
              "                       n_estimators=850)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=10, min_samples_split=20,\n",
              "                       n_estimators=850)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_RF.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "LVQgUnAF0T3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "-4Phrdmy0T3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature importance"
      ],
      "metadata": {
        "id": "0pMn6VzTFC2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame using the boolean array\n",
        "data_filtered_features = df_filtered.iloc[:,:-10].loc[:, best_features]\n",
        "\n",
        "# Print the filtered DataFrame\n",
        "data_filtered_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "4cN-1K7TyqeJ",
        "outputId": "692113ce-6e0f-4ccb-9ca2-e46e464d66c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             cell  ENSG00000205542  ENSG00000167996  \\\n",
              "0     ERR2538859-AAACCTGAGACCACGA        32962.305        8240.5760   \n",
              "1     ERR2538859-AAACCTGTCTGATACG        34861.200        5579.0670   \n",
              "2     ERR2538859-AAACGGGAGTGTTGAA        17791.770        4845.0840   \n",
              "3     ERR2538859-AAAGATGTCCGAACGC        26513.914        7070.3770   \n",
              "4     ERR2538859-AAAGTAGGTTAGTGGG        30791.666        7291.2870   \n",
              "...                           ...              ...              ...   \n",
              "1422  ERR2538860-TTTGGTTTCGTTACGA        20833.332        5707.7627   \n",
              "1423  ERR2538860-TTTGTCAAGCCCAACC        73876.350       13776.4760   \n",
              "1424  ERR2538860-TTTGTCACATTGGGCC        22690.557        3524.7466   \n",
              "1425  ERR2538860-TTTGTCAGTTGCGTTA        54775.516       11874.2080   \n",
              "1426  ERR2538860-TTTGTCATCAACACCA        15493.742        4150.8433   \n",
              "\n",
              "      ENSG00000087086  ENSG00000075624  ENSG00000198918  ENSG00000111640  \\\n",
              "0           5042.7400        4950.4950        3874.3005        6949.1420   \n",
              "1           4519.0444        3873.4666       10329.2440        9038.0890   \n",
              "2           4739.7560        1061.1393       11424.9340        6402.2075   \n",
              "3           4058.9202        3404.2556        5695.5815        3076.9233   \n",
              "4           5384.3350        2636.0806        4823.4670        4655.2060   \n",
              "...               ...              ...              ...              ...   \n",
              "1422        5707.7627        3139.2693        6563.9270        3995.4336   \n",
              "1423        9126.9150       18598.2420        6027.2080        7921.4736   \n",
              "1424        2570.1277        3671.6110        9105.5960        8150.9766   \n",
              "1425       11654.3640        8047.0615        4384.2610        9101.5040   \n",
              "1426        5151.7656        2383.6526        6036.0234        6631.9370   \n",
              "\n",
              "      ENSG00000198938  ENSG00000145425  ENSG00000112306  ...  ENSG00000115866  \\\n",
              "0           2982.5964        3351.5774        3474.5710  ...       153.742080   \n",
              "1              0.0000        8607.7030       10114.0520  ...       215.192580   \n",
              "2           3218.7893        8878.1990        8489.1140  ...        70.742620   \n",
              "3           2029.4601        4517.1850        5302.7827  ...        65.466450   \n",
              "4           6449.9844        3533.4697        4822.8145  ...       112.173645   \n",
              "...               ...              ...              ...  ...              ...   \n",
              "1422        7420.0913        7420.0913        7705.4795  ...       285.388120   \n",
              "1423           0.0000        5855.0024        5855.0024  ...       172.205950   \n",
              "1424        5140.2554        6976.0610        4993.3910  ...       367.161100   \n",
              "1425        2830.3457        3995.7822        3884.7883  ...       166.490920   \n",
              "1426        3287.1338        4997.8330        5074.8735  ...       153.784040   \n",
              "\n",
              "      ENSG00000165775  ENSG00000126261  ENSG00000159352  ENSG00000167123  \\\n",
              "0          153.742080        61.496834        61.496834       297.796360   \n",
              "1            0.000000         0.000000       215.192580         0.000000   \n",
              "2          141.485240         0.000000        70.742620       156.347350   \n",
              "3            0.000000         0.000000         0.000000        65.466450   \n",
              "4           56.086823       112.173645        56.086823       112.173645   \n",
              "...               ...              ...              ...              ...   \n",
              "1422         0.000000       570.776250         0.000000         0.000000   \n",
              "1423       172.205950       516.617860       172.205950       172.205950   \n",
              "1424       146.864440        73.432220        73.432220         0.000000   \n",
              "1425        55.496975         0.000000       166.490920        83.245460   \n",
              "1426       173.007050       134.561040       153.784040        21.625881   \n",
              "\n",
              "      ENSG00000172785  ENSG00000104419  ENSG00000151835  ENSG00000077942  \\\n",
              "0          107.619460         0.000000        61.496834       245.987340   \n",
              "1            0.000000         0.000000         0.000000         0.000000   \n",
              "2           78.863240        35.371310        35.371310         0.000000   \n",
              "3          120.912285       196.399350        65.466450       130.932900   \n",
              "4            0.000000         0.000000        56.086823        56.086823   \n",
              "...               ...              ...              ...              ...   \n",
              "1422         0.000000         0.000000         0.000000         0.000000   \n",
              "1423         0.000000         0.000000       172.205950         0.000000   \n",
              "1424       220.296660         0.000000        73.432220       367.161100   \n",
              "1425       221.987900       110.993950         0.000000         0.000000   \n",
              "1426       124.949530        57.669014        24.028757        96.115030   \n",
              "\n",
              "      ENSG00000241553  \n",
              "0           30.748417  \n",
              "1          215.192580  \n",
              "2           35.371310  \n",
              "3            0.000000  \n",
              "4          224.347290  \n",
              "...               ...  \n",
              "1422         0.000000  \n",
              "1423         0.000000  \n",
              "1424         0.000000  \n",
              "1425        55.496975  \n",
              "1426        96.115030  \n",
              "\n",
              "[1427 rows x 300 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58118f6a-6fd1-493f-a0e5-70eee128138e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell</th>\n",
              "      <th>ENSG00000205542</th>\n",
              "      <th>ENSG00000167996</th>\n",
              "      <th>ENSG00000087086</th>\n",
              "      <th>ENSG00000075624</th>\n",
              "      <th>ENSG00000198918</th>\n",
              "      <th>ENSG00000111640</th>\n",
              "      <th>ENSG00000198938</th>\n",
              "      <th>ENSG00000145425</th>\n",
              "      <th>ENSG00000112306</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000115866</th>\n",
              "      <th>ENSG00000165775</th>\n",
              "      <th>ENSG00000126261</th>\n",
              "      <th>ENSG00000159352</th>\n",
              "      <th>ENSG00000167123</th>\n",
              "      <th>ENSG00000172785</th>\n",
              "      <th>ENSG00000104419</th>\n",
              "      <th>ENSG00000151835</th>\n",
              "      <th>ENSG00000077942</th>\n",
              "      <th>ENSG00000241553</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ERR2538859-AAACCTGAGACCACGA</td>\n",
              "      <td>32962.305</td>\n",
              "      <td>8240.5760</td>\n",
              "      <td>5042.7400</td>\n",
              "      <td>4950.4950</td>\n",
              "      <td>3874.3005</td>\n",
              "      <td>6949.1420</td>\n",
              "      <td>2982.5964</td>\n",
              "      <td>3351.5774</td>\n",
              "      <td>3474.5710</td>\n",
              "      <td>...</td>\n",
              "      <td>153.742080</td>\n",
              "      <td>153.742080</td>\n",
              "      <td>61.496834</td>\n",
              "      <td>61.496834</td>\n",
              "      <td>297.796360</td>\n",
              "      <td>107.619460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.496834</td>\n",
              "      <td>245.987340</td>\n",
              "      <td>30.748417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ERR2538859-AAACCTGTCTGATACG</td>\n",
              "      <td>34861.200</td>\n",
              "      <td>5579.0670</td>\n",
              "      <td>4519.0444</td>\n",
              "      <td>3873.4666</td>\n",
              "      <td>10329.2440</td>\n",
              "      <td>9038.0890</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8607.7030</td>\n",
              "      <td>10114.0520</td>\n",
              "      <td>...</td>\n",
              "      <td>215.192580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>215.192580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>215.192580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ERR2538859-AAACGGGAGTGTTGAA</td>\n",
              "      <td>17791.770</td>\n",
              "      <td>4845.0840</td>\n",
              "      <td>4739.7560</td>\n",
              "      <td>1061.1393</td>\n",
              "      <td>11424.9340</td>\n",
              "      <td>6402.2075</td>\n",
              "      <td>3218.7893</td>\n",
              "      <td>8878.1990</td>\n",
              "      <td>8489.1140</td>\n",
              "      <td>...</td>\n",
              "      <td>70.742620</td>\n",
              "      <td>141.485240</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.742620</td>\n",
              "      <td>156.347350</td>\n",
              "      <td>78.863240</td>\n",
              "      <td>35.371310</td>\n",
              "      <td>35.371310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.371310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ERR2538859-AAAGATGTCCGAACGC</td>\n",
              "      <td>26513.914</td>\n",
              "      <td>7070.3770</td>\n",
              "      <td>4058.9202</td>\n",
              "      <td>3404.2556</td>\n",
              "      <td>5695.5815</td>\n",
              "      <td>3076.9233</td>\n",
              "      <td>2029.4601</td>\n",
              "      <td>4517.1850</td>\n",
              "      <td>5302.7827</td>\n",
              "      <td>...</td>\n",
              "      <td>65.466450</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65.466450</td>\n",
              "      <td>120.912285</td>\n",
              "      <td>196.399350</td>\n",
              "      <td>65.466450</td>\n",
              "      <td>130.932900</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ERR2538859-AAAGTAGGTTAGTGGG</td>\n",
              "      <td>30791.666</td>\n",
              "      <td>7291.2870</td>\n",
              "      <td>5384.3350</td>\n",
              "      <td>2636.0806</td>\n",
              "      <td>4823.4670</td>\n",
              "      <td>4655.2060</td>\n",
              "      <td>6449.9844</td>\n",
              "      <td>3533.4697</td>\n",
              "      <td>4822.8145</td>\n",
              "      <td>...</td>\n",
              "      <td>112.173645</td>\n",
              "      <td>56.086823</td>\n",
              "      <td>112.173645</td>\n",
              "      <td>56.086823</td>\n",
              "      <td>112.173645</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.086823</td>\n",
              "      <td>56.086823</td>\n",
              "      <td>224.347290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>ERR2538860-TTTGGTTTCGTTACGA</td>\n",
              "      <td>20833.332</td>\n",
              "      <td>5707.7627</td>\n",
              "      <td>5707.7627</td>\n",
              "      <td>3139.2693</td>\n",
              "      <td>6563.9270</td>\n",
              "      <td>3995.4336</td>\n",
              "      <td>7420.0913</td>\n",
              "      <td>7420.0913</td>\n",
              "      <td>7705.4795</td>\n",
              "      <td>...</td>\n",
              "      <td>285.388120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>570.776250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>ERR2538860-TTTGTCAAGCCCAACC</td>\n",
              "      <td>73876.350</td>\n",
              "      <td>13776.4760</td>\n",
              "      <td>9126.9150</td>\n",
              "      <td>18598.2420</td>\n",
              "      <td>6027.2080</td>\n",
              "      <td>7921.4736</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5855.0024</td>\n",
              "      <td>5855.0024</td>\n",
              "      <td>...</td>\n",
              "      <td>172.205950</td>\n",
              "      <td>172.205950</td>\n",
              "      <td>516.617860</td>\n",
              "      <td>172.205950</td>\n",
              "      <td>172.205950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>172.205950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>ERR2538860-TTTGTCACATTGGGCC</td>\n",
              "      <td>22690.557</td>\n",
              "      <td>3524.7466</td>\n",
              "      <td>2570.1277</td>\n",
              "      <td>3671.6110</td>\n",
              "      <td>9105.5960</td>\n",
              "      <td>8150.9766</td>\n",
              "      <td>5140.2554</td>\n",
              "      <td>6976.0610</td>\n",
              "      <td>4993.3910</td>\n",
              "      <td>...</td>\n",
              "      <td>367.161100</td>\n",
              "      <td>146.864440</td>\n",
              "      <td>73.432220</td>\n",
              "      <td>73.432220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>220.296660</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.432220</td>\n",
              "      <td>367.161100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>ERR2538860-TTTGTCAGTTGCGTTA</td>\n",
              "      <td>54775.516</td>\n",
              "      <td>11874.2080</td>\n",
              "      <td>11654.3640</td>\n",
              "      <td>8047.0615</td>\n",
              "      <td>4384.2610</td>\n",
              "      <td>9101.5040</td>\n",
              "      <td>2830.3457</td>\n",
              "      <td>3995.7822</td>\n",
              "      <td>3884.7883</td>\n",
              "      <td>...</td>\n",
              "      <td>166.490920</td>\n",
              "      <td>55.496975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>166.490920</td>\n",
              "      <td>83.245460</td>\n",
              "      <td>221.987900</td>\n",
              "      <td>110.993950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>55.496975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1426</th>\n",
              "      <td>ERR2538860-TTTGTCATCAACACCA</td>\n",
              "      <td>15493.742</td>\n",
              "      <td>4150.8433</td>\n",
              "      <td>5151.7656</td>\n",
              "      <td>2383.6526</td>\n",
              "      <td>6036.0234</td>\n",
              "      <td>6631.9370</td>\n",
              "      <td>3287.1338</td>\n",
              "      <td>4997.8330</td>\n",
              "      <td>5074.8735</td>\n",
              "      <td>...</td>\n",
              "      <td>153.784040</td>\n",
              "      <td>173.007050</td>\n",
              "      <td>134.561040</td>\n",
              "      <td>153.784040</td>\n",
              "      <td>21.625881</td>\n",
              "      <td>124.949530</td>\n",
              "      <td>57.669014</td>\n",
              "      <td>24.028757</td>\n",
              "      <td>96.115030</td>\n",
              "      <td>96.115030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1427 rows × 300 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58118f6a-6fd1-493f-a0e5-70eee128138e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58118f6a-6fd1-493f-a0e5-70eee128138e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58118f6a-6fd1-493f-a0e5-70eee128138e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view the feature scores\n",
        "#X_df = pd.DataFrame(X_train_val,columns=X.columns)\n",
        "feature_scores = pd.Series(best_classifier_RF.feature_importances_).sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "IVX9SzrtFBkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EABZ-TDdLACp",
        "outputId": "74c1214c-d6b4-425d-b216-014e66af1fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6      0.087005\n",
              "1      0.081445\n",
              "8      0.072879\n",
              "2      0.061646\n",
              "26     0.052522\n",
              "         ...   \n",
              "293    0.000016\n",
              "239    0.000008\n",
              "256    0.000000\n",
              "261    0.000000\n",
              "284    0.000000\n",
              "Length: 300, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the column names corresponding to the series indices\n",
        "column_names = data_filtered_features.columns[feature_scores.index]\n",
        "\n",
        "# Print the column names\n",
        "print(column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY7GhQpq2oQu",
        "outputId": "5c944b7f-d6ea-45da-84cb-377729eb2995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ENSG00000111640', 'ENSG00000205542', 'ENSG00000145425',\n",
            "       'ENSG00000167996', 'ENSG00000168209', 'ENSG00000177600',\n",
            "       'ENSG00000105193', 'ENSG00000096384', 'ENSG00000096150',\n",
            "       'ENSG00000163041',\n",
            "       ...\n",
            "       'ENSG00000115866', 'ENSG00000178980', 'ENSG00000101966',\n",
            "       'ENSG00000159210', 'ENSG00000169871', 'ENSG00000159352',\n",
            "       'ENSG00000063046', 'ENSG00000149357', 'ENSG00000079482',\n",
            "       'ENSG00000136003'],\n",
            "      dtype='object', length=300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the column names corresponding to the series indices above the threshold\n",
        "filtered_column_names = data_filtered_features.columns[feature_scores[feature_scores > 0.05].index]\n",
        "\n",
        "# Print the filtered column names\n",
        "print(filtered_column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeV8LPaV2_kq",
        "outputId": "167dba76-2288-497d-f84e-71a79b4cb255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ENSG00000111640', 'ENSG00000205542', 'ENSG00000145425',\n",
            "       'ENSG00000167996', 'ENSG00000168209', 'ENSG00000177600'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "SzHT-MEPEaMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "2wM-KG31Ecok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main goal of the provided code is to perform hyperparameter tuning for an XGBoost classifier using the Optuna library.\n",
        "The code also stores the best set of features selected during the hyperparameter tuning in the best_features variable. If the hyperparameter tuning process is pruned (terminated early), the best_features variable will be set to the selected features of the last trial that was not pruned."
      ],
      "metadata": {
        "id": "I2ITNAL4Pp94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "2blTK7FmEcol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Optuna hyperparameter tuning\n",
        "def objective_XG(trial):\n",
        "  global best_features\n",
        "\n",
        "  params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "            'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
        "            'random_state': 42,\n",
        "            'tree_method': 'hist',  # Optional: Use 'hist' method for faster training\n",
        "            'objective': 'multi:softmax',\n",
        "            'num_class': 2  # Replace with the actual number of classes\n",
        "        }\n",
        "\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  #classifier = XGBClassifier(eta=eta,gamma=gamma ,min_child_weight=min_child_weight,max_delta_step=max_delta_step,subsample=subsample)\n",
        "  classifier = XGBClassifier(**params)\n",
        "\n",
        "  # Perform cross-validation with feature selection\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "  feature_selector = SelectKBest(score_func=f_classif, k=300)  # Adjust the number of features as desired\n",
        "  best_features = None\n",
        "\n",
        "  for train_index, val_index in kf.split(X_train_val, y_train_val):\n",
        "      X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "      y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "\n",
        "      # Perform feature selection on the training set\n",
        "      X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
        "      selected_features = feature_selector.get_support()\n",
        "\n",
        "      # Apply the same feature selection on the validation set\n",
        "      X_val_selected = X_val[:, selected_features]\n",
        "\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train_selected, y_train)\n",
        "      y_pred = classifier.predict(X_val_selected)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  if trial.should_prune()==False:\n",
        "    best_features = selected_features.copy()\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "_oOLPOa1Ecol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Optuna study\n",
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective_XG, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e915b5-bfa7-4bd0-df58-0f7462ff6f5b",
        "id": "aaF6hq6FEcom"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 09:02:18,874] A new study created in memory with name: no-name-f4a9e6e3-4e36-4df5-923e-d44af625dff6\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:02:24,592] Trial 0 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 106, 'max_depth': 20, 'learning_rate': 0.05395030966670229, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'gamma': 0.7799726016810132, 'min_child_weight': 1}. Best is trial 0 with value: 0.9659070867794387.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:02:33,689] Trial 1 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 180, 'max_depth': 14, 'learning_rate': 0.051059032093947576, 'subsample': 0.5102922471479012, 'colsample_bytree': 0.9849549260809971, 'gamma': 4.162213204002109, 'min_child_weight': 2}. Best is trial 0 with value: 0.9659070867794387.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:02:37,791] Trial 2 finished with value: 0.9582070932929401 and parameters: {'n_estimators': 77, 'max_depth': 7, 'learning_rate': 0.02014847788415866, 'subsample': 0.762378215816119, 'colsample_bytree': 0.7159725093210578, 'gamma': 1.4561457009902097, 'min_child_weight': 4}. Best is trial 0 with value: 0.9659070867794387.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:02:44,615] Trial 3 finished with value: 0.9729457704817694 and parameters: {'n_estimators': 71, 'max_depth': 9, 'learning_rate': 0.023246728489504348, 'subsample': 0.728034992108518, 'colsample_bytree': 0.8925879806965068, 'gamma': 0.9983689107917987, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:02:48,744] Trial 4 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 139, 'max_depth': 5, 'learning_rate': 0.04050837781329675, 'subsample': 0.5852620618436457, 'colsample_bytree': 0.5325257964926398, 'gamma': 4.7444276862666666, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:00,936] Trial 5 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.012521954287060391, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007, 'gamma': 0.6101911742238941, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:03,913] Trial 6 finished with value: 0.9729457704817694 and parameters: {'n_estimators': 55, 'max_depth': 19, 'learning_rate': 0.01814596135349025, 'subsample': 0.831261142176991, 'colsample_bytree': 0.6558555380447055, 'gamma': 2.600340105889054, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:09,790] Trial 7 finished with value: 0.9591011437842333 and parameters: {'n_estimators': 77, 'max_depth': 20, 'learning_rate': 0.05958443469672518, 'subsample': 0.9697494707820946, 'colsample_bytree': 0.9474136752138245, 'gamma': 2.9894998940554256, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:13,022] Trial 8 finished with value: 0.9582070932929401 and parameters: {'n_estimators': 63, 'max_depth': 8, 'learning_rate': 0.011097554561103107, 'subsample': 0.6626651653816322, 'colsample_bytree': 0.6943386448447411, 'gamma': 1.3567451588694794, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:20,593] Trial 9 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 103, 'max_depth': 9, 'learning_rate': 0.03488960745139221, 'subsample': 0.5704621124873813, 'colsample_bytree': 0.9010984903770198, 'gamma': 0.3727532183988541, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:29,666] Trial 10 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 166, 'max_depth': 8, 'learning_rate': 0.010127963257331486, 'subsample': 0.9077307142274171, 'colsample_bytree': 0.8534286719238086, 'gamma': 3.6450358402049368, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:36,650] Trial 11 finished with value: 0.9594774315055374 and parameters: {'n_estimators': 61, 'max_depth': 10, 'learning_rate': 0.013057771348997228, 'subsample': 0.9315517129377968, 'colsample_bytree': 0.811649063413779, 'gamma': 1.654490124263246, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:46,069] Trial 12 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 96, 'max_depth': 10, 'learning_rate': 0.053654503243520245, 'subsample': 0.8187787356776066, 'colsample_bytree': 0.9436063712881633, 'gamma': 2.3610746258097466, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:52,628] Trial 13 finished with value: 0.9521136849339126 and parameters: {'n_estimators': 157, 'max_depth': 17, 'learning_rate': 0.036414738668149954, 'subsample': 0.8854835899772805, 'colsample_bytree': 0.7468977981821954, 'gamma': 2.6136641469099704, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:03:57,452] Trial 14 finished with value: 0.9515719399751259 and parameters: {'n_estimators': 53, 'max_depth': 6, 'learning_rate': 0.010750512925563078, 'subsample': 0.8182052056318903, 'colsample_bytree': 0.6571779905381634, 'gamma': 2.542853455823514, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:04:01,602] Trial 15 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 87, 'max_depth': 11, 'learning_rate': 0.05695752881519842, 'subsample': 0.6143990827458112, 'colsample_bytree': 0.5384899549143964, 'gamma': 1.4487572645688402, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:04:10,418] Trial 16 finished with value: 0.9591011437842333 and parameters: {'n_estimators': 190, 'max_depth': 17, 'learning_rate': 0.0429935945473144, 'subsample': 0.9357302950938589, 'colsample_bytree': 0.9018360384495572, 'gamma': 0.9328502944301792, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:04:13,856] Trial 17 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 131, 'max_depth': 17, 'learning_rate': 0.07872112644525067, 'subsample': 0.6590017374859319, 'colsample_bytree': 0.5550259622638384, 'gamma': 1.1396758127097084, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:04:27,149] Trial 18 finished with value: 0.9729457704817694 and parameters: {'n_estimators': 173, 'max_depth': 18, 'learning_rate': 0.010161366845302874, 'subsample': 0.7553736512887829, 'colsample_bytree': 0.7087055015743895, 'gamma': 1.1105390523536514, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:04:34,782] Trial 19 finished with value: 0.9454785316160983 and parameters: {'n_estimators': 100, 'max_depth': 20, 'learning_rate': 0.021047616983326124, 'subsample': 0.7593953108716831, 'colsample_bytree': 0.8515094794475889, 'gamma': 1.81814801189647, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:04:48,607] Trial 20 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 195, 'max_depth': 9, 'learning_rate': 0.031423062259089654, 'subsample': 0.6504391549083848, 'colsample_bytree': 0.6424202471887338, 'gamma': 0.18443473677266398, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:04:58,240] Trial 21 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.018995313441382815, 'subsample': 0.9541329429833268, 'colsample_bytree': 0.6197809453334862, 'gamma': 0.7244743604561155, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:05:04,785] Trial 22 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.04700407898796262, 'subsample': 0.8808098076643588, 'colsample_bytree': 0.6188187719961998, 'gamma': 3.641081743059298, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:05:15,350] Trial 23 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 145, 'max_depth': 15, 'learning_rate': 0.03433797531418577, 'subsample': 0.5451448850272042, 'colsample_bytree': 0.917651247794619, 'gamma': 1.6039003248586792, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:05:20,093] Trial 24 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 56, 'max_depth': 14, 'learning_rate': 0.04759533213871805, 'subsample': 0.508293914463928, 'colsample_bytree': 0.7560465291496405, 'gamma': 1.1324788759896898, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:05:26,430] Trial 25 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 76, 'max_depth': 16, 'learning_rate': 0.024363256990834973, 'subsample': 0.9683649943683672, 'colsample_bytree': 0.5687604720729966, 'gamma': 1.7053317552512925, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:05:38,413] Trial 26 finished with value: 0.9521136849339126 and parameters: {'n_estimators': 189, 'max_depth': 19, 'learning_rate': 0.018110966519152245, 'subsample': 0.8299920230170895, 'colsample_bytree': 0.9086111001006079, 'gamma': 2.7760040579973118, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:05:42,565] Trial 27 finished with value: 0.9591011437842333 and parameters: {'n_estimators': 86, 'max_depth': 6, 'learning_rate': 0.07892521215168546, 'subsample': 0.9502090285816652, 'colsample_bytree': 0.816550728636634, 'gamma': 1.6951489552435035, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:05:51,509] Trial 28 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 159, 'max_depth': 19, 'learning_rate': 0.07710568935221308, 'subsample': 0.8899377729288119, 'colsample_bytree': 0.8210158230771438, 'gamma': 0.42069982497524416, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:06:11,111] Trial 29 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 185, 'max_depth': 14, 'learning_rate': 0.010214028177610482, 'subsample': 0.5507357714330161, 'colsample_bytree': 0.8317508845540279, 'gamma': 0.025307919231093434, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:06:17,565] Trial 30 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 132, 'max_depth': 16, 'learning_rate': 0.04487053621524984, 'subsample': 0.61213465473028, 'colsample_bytree': 0.8560896106737679, 'gamma': 1.1862454374840004, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:06:25,693] Trial 31 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 162, 'max_depth': 15, 'learning_rate': 0.0706680992793571, 'subsample': 0.8288064461501716, 'colsample_bytree': 0.7841543016677358, 'gamma': 0.4683738391404624, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:06:29,328] Trial 32 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.09397461491404223, 'subsample': 0.6965488623333802, 'colsample_bytree': 0.9460232775885566, 'gamma': 3.1556931299863145, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:06:38,739] Trial 33 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 125, 'max_depth': 14, 'learning_rate': 0.03108262535511156, 'subsample': 0.5976214938990223, 'colsample_bytree': 0.8612260576307527, 'gamma': 1.403861812204279, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:06:47,428] Trial 34 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 147, 'max_depth': 7, 'learning_rate': 0.08718837518272327, 'subsample': 0.9769642885012937, 'colsample_bytree': 0.9574321951102243, 'gamma': 1.8507935012772219, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:06:55,421] Trial 35 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 190, 'max_depth': 11, 'learning_rate': 0.09260934638062272, 'subsample': 0.9818099885446264, 'colsample_bytree': 0.92650472773368, 'gamma': 1.4722444603479286, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:07:16,117] Trial 36 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.014773818070797135, 'subsample': 0.7784006312291751, 'colsample_bytree': 0.9680773870803905, 'gamma': 3.480148983374865, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:07:20,468] Trial 37 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 64, 'max_depth': 14, 'learning_rate': 0.09773584004575739, 'subsample': 0.570042007618262, 'colsample_bytree': 0.7591648261818684, 'gamma': 4.386865359639777, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:07:32,477] Trial 38 finished with value: 0.9444136914474139 and parameters: {'n_estimators': 155, 'max_depth': 16, 'learning_rate': 0.02288185089169864, 'subsample': 0.6467959221322467, 'colsample_bytree': 0.9046805777392568, 'gamma': 4.050566973395904, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:07:43,462] Trial 39 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 187, 'max_depth': 13, 'learning_rate': 0.03173337724928844, 'subsample': 0.8991475894833876, 'colsample_bytree': 0.8249819653888826, 'gamma': 3.509834386288517, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:07:54,594] Trial 40 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.023745589332672786, 'subsample': 0.5469909699204345, 'colsample_bytree': 0.789140070498087, 'gamma': 0.17971136898371043, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:07:59,046] Trial 41 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.03897923043114404, 'subsample': 0.5152501249695247, 'colsample_bytree': 0.5186740943746072, 'gamma': 4.113002803298292, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:05,875] Trial 42 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 69, 'max_depth': 13, 'learning_rate': 0.05888349143078406, 'subsample': 0.6079105137484215, 'colsample_bytree': 0.8114452379095001, 'gamma': 0.42673732496884, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:14,492] Trial 43 finished with value: 0.9521136849339126 and parameters: {'n_estimators': 130, 'max_depth': 13, 'learning_rate': 0.04339402166711993, 'subsample': 0.8630456668613308, 'colsample_bytree': 0.9879260397312672, 'gamma': 2.5815017415059764, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:19,587] Trial 44 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.027477133304227786, 'subsample': 0.5392281906711329, 'colsample_bytree': 0.5126753717077288, 'gamma': 4.813242073389626, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:28,049] Trial 45 finished with value: 0.9444136914474139 and parameters: {'n_estimators': 155, 'max_depth': 11, 'learning_rate': 0.014903707553457764, 'subsample': 0.5782185213355431, 'colsample_bytree': 0.6251214490822976, 'gamma': 2.7461333235306022, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:32,841] Trial 46 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 149, 'max_depth': 9, 'learning_rate': 0.09012915111444605, 'subsample': 0.8689484583478843, 'colsample_bytree': 0.7771770262557003, 'gamma': 3.058603731171761, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:39,280] Trial 47 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 87, 'max_depth': 10, 'learning_rate': 0.05725931002475599, 'subsample': 0.5071967443148779, 'colsample_bytree': 0.5580363202534582, 'gamma': 0.23001321010876374, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:47,827] Trial 48 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 179, 'max_depth': 16, 'learning_rate': 0.02979708837909646, 'subsample': 0.5489170803255008, 'colsample_bytree': 0.7458079375584161, 'gamma': 2.3673588539028283, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:53,720] Trial 49 finished with value: 0.9729457704817694 and parameters: {'n_estimators': 115, 'max_depth': 11, 'learning_rate': 0.04129049582940024, 'subsample': 0.8175468254338218, 'colsample_bytree': 0.5226520048860223, 'gamma': 1.873063073132356, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:08:58,070] Trial 50 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 125, 'max_depth': 18, 'learning_rate': 0.045571532304896696, 'subsample': 0.5814672135407148, 'colsample_bytree': 0.5352843737002149, 'gamma': 3.212096391031578, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:09:06,177] Trial 51 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 138, 'max_depth': 20, 'learning_rate': 0.03762479807864279, 'subsample': 0.694084963103261, 'colsample_bytree': 0.8216441092211766, 'gamma': 2.2912644524575834, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:09:29,321] Trial 52 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 192, 'max_depth': 11, 'learning_rate': 0.09145144327022775, 'subsample': 0.9526753209780319, 'colsample_bytree': 0.5978955673946482, 'gamma': 0.3468065043758273, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:09:32,070] Trial 53 finished with value: 0.9444136914474139 and parameters: {'n_estimators': 52, 'max_depth': 6, 'learning_rate': 0.04819553143187268, 'subsample': 0.5355943242301144, 'colsample_bytree': 0.6594878151468806, 'gamma': 4.2243765548472725, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:09:42,326] Trial 54 finished with value: 0.9454785316160983 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.013126980122725883, 'subsample': 0.8483685826820753, 'colsample_bytree': 0.8144714233899419, 'gamma': 4.387360067635265, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:09:54,004] Trial 55 finished with value: 0.952465990466419 and parameters: {'n_estimators': 171, 'max_depth': 9, 'learning_rate': 0.01504664046574254, 'subsample': 0.8753073758204292, 'colsample_bytree': 0.9034173696336321, 'gamma': 4.952525710003367, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:10:00,484] Trial 56 finished with value: 0.9591011437842333 and parameters: {'n_estimators': 106, 'max_depth': 17, 'learning_rate': 0.02191813210849195, 'subsample': 0.9653786628017824, 'colsample_bytree': 0.9292063759215059, 'gamma': 2.1449701368750915, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:10:06,800] Trial 57 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 163, 'max_depth': 6, 'learning_rate': 0.07990112729952498, 'subsample': 0.7526261862239285, 'colsample_bytree': 0.9132287330538709, 'gamma': 1.6002480051530588, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:10:09,845] Trial 58 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.08042331609807464, 'subsample': 0.5456433383930668, 'colsample_bytree': 0.6596568187952074, 'gamma': 4.750309835254025, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:10:15,790] Trial 59 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 136, 'max_depth': 15, 'learning_rate': 0.02808313075092021, 'subsample': 0.6466053858490323, 'colsample_bytree': 0.664332272684958, 'gamma': 3.362592280385192, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:10:24,145] Trial 60 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 169, 'max_depth': 17, 'learning_rate': 0.012336901664320325, 'subsample': 0.7472101523512907, 'colsample_bytree': 0.5287793800083221, 'gamma': 2.7476444116186776, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:10:36,158] Trial 61 finished with value: 0.9514011502977346 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.013093839597945776, 'subsample': 0.5714958410264179, 'colsample_bytree': 0.8807553158587361, 'gamma': 3.0910903165813055, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:10:44,870] Trial 62 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 62, 'max_depth': 16, 'learning_rate': 0.011823961484137372, 'subsample': 0.9109300296451781, 'colsample_bytree': 0.8531211135782482, 'gamma': 0.4067439032094988, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:10:55,805] Trial 63 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.023476975517779386, 'subsample': 0.9063997836287513, 'colsample_bytree': 0.9736242886919293, 'gamma': 4.930005319114354, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:00,310] Trial 64 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.059861406382344204, 'subsample': 0.7792021248679025, 'colsample_bytree': 0.7121110046234882, 'gamma': 4.53177192547368, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:07,717] Trial 65 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.029421217593944136, 'subsample': 0.5281516378409187, 'colsample_bytree': 0.559408958134036, 'gamma': 0.5876312338855244, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:11,900] Trial 66 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 162, 'max_depth': 14, 'learning_rate': 0.09165845837596683, 'subsample': 0.6874352897618521, 'colsample_bytree': 0.6428560431409304, 'gamma': 4.342995640947302, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:16,212] Trial 67 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.09329939481415435, 'subsample': 0.5215799559752881, 'colsample_bytree': 0.9455715568490355, 'gamma': 2.6385055454314994, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:20,599] Trial 68 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 61, 'max_depth': 13, 'learning_rate': 0.09317567242278998, 'subsample': 0.7615489220850744, 'colsample_bytree': 0.8146993190676313, 'gamma': 3.4787434449230856, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:23,917] Trial 69 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 144, 'max_depth': 14, 'learning_rate': 0.07964490718465164, 'subsample': 0.522723190170729, 'colsample_bytree': 0.6404815947961151, 'gamma': 4.752057420382794, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:31,950] Trial 70 finished with value: 0.9444136914474139 and parameters: {'n_estimators': 118, 'max_depth': 14, 'learning_rate': 0.018940052695803525, 'subsample': 0.5940605798618807, 'colsample_bytree': 0.7318492024699911, 'gamma': 1.766761140130264, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:34,492] Trial 71 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 61, 'max_depth': 20, 'learning_rate': 0.09687478339838175, 'subsample': 0.8490808570098726, 'colsample_bytree': 0.7680481831720603, 'gamma': 1.5476380814316388, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:39,491] Trial 72 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 153, 'max_depth': 7, 'learning_rate': 0.08145676989745455, 'subsample': 0.9112686214615845, 'colsample_bytree': 0.974899956645962, 'gamma': 3.6285975419418, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:44,137] Trial 73 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 113, 'max_depth': 19, 'learning_rate': 0.07346219311834645, 'subsample': 0.5226093350530947, 'colsample_bytree': 0.5131834872486261, 'gamma': 1.8823168343902479, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:51,725] Trial 74 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 199, 'max_depth': 7, 'learning_rate': 0.03927631327238783, 'subsample': 0.6904454283155108, 'colsample_bytree': 0.9849571989073016, 'gamma': 4.210594615678543, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:11:59,860] Trial 75 finished with value: 0.9377785381295997 and parameters: {'n_estimators': 120, 'max_depth': 11, 'learning_rate': 0.018767527976279317, 'subsample': 0.5281877483254636, 'colsample_bytree': 0.9323611881275267, 'gamma': 4.064505045650388, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:12:09,125] Trial 76 finished with value: 0.9591011437842333 and parameters: {'n_estimators': 200, 'max_depth': 13, 'learning_rate': 0.05874723287345401, 'subsample': 0.9723828649412141, 'colsample_bytree': 0.9248236953387057, 'gamma': 1.2367405087159882, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:12:12,815] Trial 77 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 69, 'max_depth': 20, 'learning_rate': 0.04038077357300822, 'subsample': 0.6143214027517314, 'colsample_bytree': 0.8358503422029284, 'gamma': 3.090641202289479, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:12:16,336] Trial 78 finished with value: 0.9591011437842333 and parameters: {'n_estimators': 67, 'max_depth': 15, 'learning_rate': 0.03313658135010507, 'subsample': 0.8861591958678197, 'colsample_bytree': 0.7600817505559967, 'gamma': 4.2609075015927, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:12:22,721] Trial 79 finished with value: 0.9444136914474139 and parameters: {'n_estimators': 134, 'max_depth': 19, 'learning_rate': 0.02532111736428085, 'subsample': 0.5670076142253204, 'colsample_bytree': 0.5143913381566695, 'gamma': 3.775686278368095, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:12:29,609] Trial 80 finished with value: 0.9514011502977346 and parameters: {'n_estimators': 156, 'max_depth': 8, 'learning_rate': 0.013688992185997532, 'subsample': 0.507272332833941, 'colsample_bytree': 0.6752937794032985, 'gamma': 2.9495884342731653, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:12:38,309] Trial 81 finished with value: 0.9525172153184289 and parameters: {'n_estimators': 116, 'max_depth': 19, 'learning_rate': 0.022297463774559975, 'subsample': 0.7569947445799055, 'colsample_bytree': 0.8918265063705715, 'gamma': 1.9827139116063508, 'min_child_weight': 4}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:12:50,886] Trial 82 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 180, 'max_depth': 20, 'learning_rate': 0.014030510752388549, 'subsample': 0.9632938125807472, 'colsample_bytree': 0.7460581465397691, 'gamma': 1.2912219414947916, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:05,760] Trial 83 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 197, 'max_depth': 12, 'learning_rate': 0.021318252915542873, 'subsample': 0.8167004271583629, 'colsample_bytree': 0.6200728093890966, 'gamma': 0.3793166405433196, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:12,797] Trial 84 finished with value: 0.9582070932929401 and parameters: {'n_estimators': 69, 'max_depth': 7, 'learning_rate': 0.013766615178606525, 'subsample': 0.8204373724016073, 'colsample_bytree': 0.5909400421995724, 'gamma': 1.728336416619316, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:18,614] Trial 85 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 121, 'max_depth': 15, 'learning_rate': 0.014870304825893887, 'subsample': 0.5961445094043354, 'colsample_bytree': 0.5204343081332394, 'gamma': 0.8446753153608227, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:24,246] Trial 86 finished with value: 0.9655012317425266 and parameters: {'n_estimators': 76, 'max_depth': 6, 'learning_rate': 0.013201882743050744, 'subsample': 0.7303893840163629, 'colsample_bytree': 0.6031668592028963, 'gamma': 1.8213493052403773, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:28,054] Trial 87 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.0630101333767141, 'subsample': 0.8139501947454539, 'colsample_bytree': 0.540879515974436, 'gamma': 4.3678931205338865, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:31,438] Trial 88 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 59, 'max_depth': 9, 'learning_rate': 0.06400313981708697, 'subsample': 0.8741298451918291, 'colsample_bytree': 0.5922605096781887, 'gamma': 1.0467466166835515, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:42,633] Trial 89 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 123, 'max_depth': 14, 'learning_rate': 0.023383722018755035, 'subsample': 0.731267358066574, 'colsample_bytree': 0.8737354690668783, 'gamma': 0.1834160144529895, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:50,165] Trial 90 finished with value: 0.9661398274865641 and parameters: {'n_estimators': 157, 'max_depth': 19, 'learning_rate': 0.03248459391724695, 'subsample': 0.7660567426326579, 'colsample_bytree': 0.553586005669888, 'gamma': 2.237061834117273, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:13:54,638] Trial 91 finished with value: 0.9586952887473211 and parameters: {'n_estimators': 86, 'max_depth': 9, 'learning_rate': 0.023838787542363262, 'subsample': 0.5100355988888632, 'colsample_bytree': 0.6610395827915891, 'gamma': 1.0572400349827231, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:14:01,167] Trial 92 finished with value: 0.9595217948835618 and parameters: {'n_estimators': 68, 'max_depth': 19, 'learning_rate': 0.03922766461502937, 'subsample': 0.8395511595722448, 'colsample_bytree': 0.8945856193036692, 'gamma': 2.492210994645286, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:14:06,109] Trial 93 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 131, 'max_depth': 14, 'learning_rate': 0.05564670763518914, 'subsample': 0.7158297731148398, 'colsample_bytree': 0.5637901513977819, 'gamma': 1.4188795289936222, 'min_child_weight': 2}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:14:18,405] Trial 94 finished with value: 0.9659070867794387 and parameters: {'n_estimators': 147, 'max_depth': 14, 'learning_rate': 0.02270370451600889, 'subsample': 0.9932576243964899, 'colsample_bytree': 0.8028874096784435, 'gamma': 1.1861339586799724, 'min_child_weight': 1}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:14:23,734] Trial 95 finished with value: 0.9514011502977346 and parameters: {'n_estimators': 73, 'max_depth': 8, 'learning_rate': 0.014477093298939937, 'subsample': 0.5932835120256529, 'colsample_bytree': 0.6425475843469235, 'gamma': 0.8668679764737741, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:14:26,680] Trial 96 finished with value: 0.9528422781877233 and parameters: {'n_estimators': 62, 'max_depth': 13, 'learning_rate': 0.025727454984745508, 'subsample': 0.9911893084543032, 'colsample_bytree': 0.5560194510840262, 'gamma': 1.9892779952287083, 'min_child_weight': 5}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:14:36,591] Trial 97 finished with value: 0.9444136914474139 and parameters: {'n_estimators': 180, 'max_depth': 18, 'learning_rate': 0.018109348524270045, 'subsample': 0.585443793695033, 'colsample_bytree': 0.8343216099622155, 'gamma': 4.646879945637929, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:14:41,391] Trial 98 finished with value: 0.9517078298970004 and parameters: {'n_estimators': 136, 'max_depth': 9, 'learning_rate': 0.058815654362488916, 'subsample': 0.5935218742787617, 'colsample_bytree': 0.6618396182021218, 'gamma': 2.127182193082084, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n",
            "<ipython-input-76-211a78915f70>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
            "[I 2023-06-23 09:14:48,205] Trial 99 finished with value: 0.9591523686362432 and parameters: {'n_estimators': 86, 'max_depth': 6, 'learning_rate': 0.040796231020865825, 'subsample': 0.6443152766201279, 'colsample_bytree': 0.7906191107113061, 'gamma': 0.7718135763710116, 'min_child_weight': 3}. Best is trial 3 with value: 0.9729457704817694.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "OTNjgxycEcom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV-BZzDRgbh6",
        "outputId": "454b83d4-fc46-4532-ad4e-b68c84d5b5a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 71,\n",
              " 'max_depth': 9,\n",
              " 'learning_rate': 0.023246728489504348,\n",
              " 'subsample': 0.728034992108518,\n",
              " 'colsample_bytree': 0.8925879806965068,\n",
              " 'gamma': 0.9983689107917987,\n",
              " 'min_child_weight': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d91997f-70b9-4b83-8d0f-d670fc59b111",
        "id": "MsXpEp5CEcon"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eta': 0.9998923071077181,\n",
              " 'gamma': 0.48062735928448386,\n",
              " 'min_child_weight ': 0.9165527129072861,\n",
              " 'max_delta_step': 9,\n",
              " 'subsample': 0.9036565255711814}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc38ac7-f00d-492a-a3fa-cf20fe459bca",
        "id": "Pu9VDZG7Econ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, ..., False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "HAhms8uREcon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "t54B-N7BEcoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "7Wf6auGpEcoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774899b5-6106-4e73-bdcc-0e0e4532bc49",
        "id": "6-IRamTREcoo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_XG = XGBClassifier(**best_params)"
      ],
      "metadata": {
        "id": "RXSKzaPHEcoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_XG.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "aeeBy4miczxh",
        "outputId": "b6976270-d461-4b8b-f585-e14ec6f5b508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8925879806965068, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.9983689107917987, gpu_id=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.023246728489504348, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=71, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8925879806965068, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.9983689107917987, gpu_id=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.023246728489504348, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=71, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8925879806965068, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.9983689107917987, gpu_id=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.023246728489504348, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=71, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_XG.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "vgLQd1HNEcop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "9IaHkEmzEcop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irYnuVUiE6GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "lrSZxB1Eixd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "rFmYjhkui0Lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main goal of the provided code is to perform hyperparameter tuning for a LogisticRegression classifier using the Optuna library.\n",
        "The code also stores the best set of features selected during the hyperparameter tuning in the best_features variable. If the hyperparameter tuning process is pruned (terminated early), the best_features variable will be set to the selected features of the last trial that was not pruned."
      ],
      "metadata": {
        "id": "EmlWgbB-Px5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "v9BA4QJEi0Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Optuna hyperparameter tuning\n",
        "def objective_LG(trial):\n",
        "  global best_features\n",
        "  params = {\n",
        "              'tol' : trial.suggest_float('tol' , 1e-6 , 1e-3),\n",
        "              'C' : trial.suggest_float(\"C\", 1e-5, 100),\n",
        "              \"n_jobs\" : -1,\n",
        "              'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
        "          }\n",
        "\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  #classifier = XGBClassifier(eta=eta,gamma=gamma ,min_child_weight=min_child_weight,max_delta_step=max_delta_step,subsample=subsample)\n",
        "  classifier = LogisticRegression(**params)\n",
        "\n",
        "  # Perform cross-validation with feature selection\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "  feature_selector = SelectKBest(score_func=f_classif, k=300)  # Adjust the number of features as desired\n",
        "  best_features = None\n",
        "\n",
        "  for train_index, val_index in kf.split(X_train_val, y_train_val):\n",
        "      X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "      y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "\n",
        "      # Perform feature selection on the training set\n",
        "      X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
        "      selected_features = feature_selector.get_support()\n",
        "\n",
        "      # Apply the same feature selection on the validation set\n",
        "      X_val_selected = X_val[:, selected_features]\n",
        "\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train_selected, y_train)\n",
        "      y_pred = classifier.predict(X_val_selected)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  if trial.should_prune()==False:\n",
        "    best_features = selected_features.copy()\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "KuUXGkAQi0Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Optuna study\n",
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective_LG, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14f6cbe-9907-4124-aca7-1d55b319db47",
        "id": "Zyhjoitei0L0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 09:27:21,257] A new study created in memory with name: no-name-67271ba0-9880-4066-bfe2-b80b7cda5d9c\n",
            "[I 2023-06-23 09:27:23,483] Trial 0 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0003751655787285152, 'C': 95.07143113384855, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:27:24,024] Trial 1 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0008663099696291604, 'C': 60.11150516317076, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:27:26,087] Trial 2 finished with value: 0.8375464915589985 and parameters: {'tol': 0.00018264314223989352, 'C': 18.340459151298283, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:27:26,633] Trial 3 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0001403543667913898, 'C': 29.21447193207533, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:27:28,746] Trial 4 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0005928221542931806, 'C': 4.645050807495645, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:27:34,254] Trial 5 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0008085889507683448, 'C': 30.461383871199377, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:27:39,625] Trial 6 finished with value: 0.9010134081634122 and parameters: {'tol': 3.535413259410318e-05, 'C': 90.93204111467419, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:27:45,041] Trial 7 finished with value: 0.9010134081634122 and parameters: {'tol': 0.00018566960107000154, 'C': 96.95846308060958, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:27:47,319] Trial 8 finished with value: 0.8375464915589985 and parameters: {'tol': 8.940400954986758e-05, 'C': 19.598294282085895, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:27:49,389] Trial 9 finished with value: 0.8375464915589985 and parameters: {'tol': 0.00035739657336689574, 'C': 28.093458159392977, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:27:54,723] Trial 10 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0007724725245273608, 'C': 19.871576166260425, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:00,116] Trial 11 finished with value: 0.9082276043023576 and parameters: {'tol': 7.497060708235628e-05, 'C': 35.846579269769975, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:00,702] Trial 12 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0003116713393939466, 'C': 32.51833895084149, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:06,042] Trial 13 finished with value: 0.8933726147307934 and parameters: {'tol': 0.0007135315424357721, 'C': 76.07850725383926, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:08,314] Trial 14 finished with value: 0.8375464915589985 and parameters: {'tol': 2.6393707617351097e-05, 'C': 10.789151620416174, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:09,623] Trial 15 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0002500429369197261, 'C': 41.038298199733745, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:12,230] Trial 16 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0009297679546902306, 'C': 80.8120398752379, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:13,330] Trial 17 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0005398028996737352, 'C': 80.7440174420047, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:18,643] Trial 18 finished with value: 0.8933726147307934 and parameters: {'tol': 0.0008181967511565707, 'C': 86.07305971832851, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:20,753] Trial 19 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0003382775562322244, 'C': 94.29097096215487, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:24,040] Trial 20 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0009624848476471692, 'C': 25.178237064713457, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:29,378] Trial 21 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0005031763442056327, 'C': 5.147884610211422, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:34,839] Trial 22 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0009856648036564901, 'C': 24.205534730597325, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:35,669] Trial 23 finished with value: 0.8290908451538833 and parameters: {'tol': 0.000632673524762986, 'C': 63.35297474079236, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:36,934] Trial 24 finished with value: 0.9082276043023576 and parameters: {'tol': 4.173436641320915e-05, 'C': 59.08929840989475, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:42,269] Trial 25 finished with value: 0.9082276043023576 and parameters: {'tol': 0.00017519206257598648, 'C': 69.09377690086922, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:42,788] Trial 26 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0009247689246602843, 'C': 87.73393656470456, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:48,176] Trial 27 finished with value: 0.9082276043023576 and parameters: {'tol': 0.00024261043860955125, 'C': 9.310285849562243, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:49,318] Trial 28 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0007262297231913692, 'C': 89.71102702415511, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:49,893] Trial 29 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0008986556343385523, 'C': 60.642909901668396, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:50,467] Trial 30 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0005491850555772196, 'C': 69.18952285031735, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:51,418] Trial 31 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0007467449137129063, 'C': 64.96329340839247, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:52,501] Trial 32 finished with value: 0.9082276043023576 and parameters: {'tol': 0.00026593716531404376, 'C': 24.398971898011922, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:28:53,042] Trial 33 finished with value: 0.8290908451538833 and parameters: {'tol': 0.000503134456012087, 'C': 57.69039269359707, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:58,377] Trial 34 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0006458268236112607, 'C': 17.711076169598098, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:28:59,608] Trial 35 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0009283902440251377, 'C': 42.81842054988995, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:00,336] Trial 36 finished with value: 0.8344417744060536 and parameters: {'tol': 0.0008512855348453401, 'C': 31.692207346407713, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:01,712] Trial 37 finished with value: 0.9082276043023576 and parameters: {'tol': 9.807931727699777e-05, 'C': 61.50072651984471, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:04,534] Trial 38 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0006973187252542728, 'C': 70.24841137387008, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:10,046] Trial 39 finished with value: 0.9008076409516755 and parameters: {'tol': 0.0009133273120039149, 'C': 51.134244772669796, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:10,569] Trial 40 finished with value: 0.8344417744060536 and parameters: {'tol': 0.0008901153364757489, 'C': 33.79952230520201, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:13,150] Trial 41 finished with value: 0.8424301189794337 and parameters: {'tol': 0.0005431019900728691, 'C': 28.654132347415917, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:14,423] Trial 42 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0001279334521392329, 'C': 52.22433078304784, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:15,046] Trial 43 finished with value: 0.8290908451538833 and parameters: {'tol': 0.00053182327693658, 'C': 54.06351675465944, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:17,045] Trial 44 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0007953910085739351, 'C': 27.083232417884908, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:19,179] Trial 45 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0006962782318876043, 'C': 40.895300351897546, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:20,246] Trial 46 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0006605371793410136, 'C': 27.993396895255312, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:21,420] Trial 47 finished with value: 0.9082276043023576 and parameters: {'tol': 0.00024848325851165634, 'C': 35.597274305399374, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:22,120] Trial 48 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0008556051234269963, 'C': 70.36578890142377, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:27,920] Trial 49 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0004344177975887351, 'C': 39.85047945469, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:29,171] Trial 50 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0005036331223215077, 'C': 85.64898555393381, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:29,800] Trial 51 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0005861898056921899, 'C': 94.02302474019335, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:31,165] Trial 52 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0009415233439677488, 'C': 38.61026991905105, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:34,060] Trial 53 finished with value: 0.8375464915589985 and parameters: {'tol': 1.920360382589818e-05, 'C': 9.444305131163231, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:36,337] Trial 54 finished with value: 0.8478774359512791 and parameters: {'tol': 0.000814654014106347, 'C': 28.185484658792245, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:41,918] Trial 55 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0008036774494544638, 'C': 28.203464436784923, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:47,566] Trial 56 finished with value: 0.9082276043023576 and parameters: {'tol': 0.00037264606770699043, 'C': 77.64129831007008, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:29:48,558] Trial 57 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0007547883312105977, 'C': 10.312395852354571, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:50,624] Trial 58 finished with value: 0.8375464915589985 and parameters: {'tol': 0.00038981247705542903, 'C': 1.0837750396533212, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:53,216] Trial 59 finished with value: 0.8375464915589985 and parameters: {'tol': 0.000573864450235163, 'C': 63.18372489860781, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:55,914] Trial 60 finished with value: 0.8478774359512791 and parameters: {'tol': 0.0007917874646821228, 'C': 78.96181638327396, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:29:56,435] Trial 61 finished with value: 0.8344417744060536 and parameters: {'tol': 0.0008878164785755415, 'C': 35.091507746057744, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:30:01,801] Trial 62 finished with value: 0.9082276043023576 and parameters: {'tol': 8.502269930888245e-05, 'C': 70.09691613622068, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:04,121] Trial 63 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0009866529389226744, 'C': 37.427085832904076, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:08,192] Trial 64 finished with value: 0.8478774359512791 and parameters: {'tol': 0.0003768833259453849, 'C': 8.350080834859709, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:11,350] Trial 65 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0004931324791865683, 'C': 1.1353743632054591, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:30:12,303] Trial 66 finished with value: 0.9082276043023576 and parameters: {'tol': 0.000746298834386158, 'C': 58.336880676028315, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:14,373] Trial 67 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0009632593169011708, 'C': 1.2154573474368873, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:30:15,508] Trial 68 finished with value: 0.9082276043023576 and parameters: {'tol': 7.472276817066347e-05, 'C': 55.38543290158923, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:17,482] Trial 69 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0006279305220039795, 'C': 58.431435349166904, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:19,847] Trial 70 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0004562010960329273, 'C': 62.0132635788277, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:30:21,219] Trial 71 finished with value: 0.9010134081634122 and parameters: {'tol': 7.865690232801985e-05, 'C': 97.43948102266857, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:22,019] Trial 72 finished with value: 0.8344417744060536 and parameters: {'tol': 0.0006850464413813255, 'C': 16.261702308319734, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:30:23,158] Trial 73 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0004188247932543283, 'C': 93.2728490081165, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:23,660] Trial 74 finished with value: 0.8344417744060536 and parameters: {'tol': 0.0009872888531856296, 'C': 15.041697606183906, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:25,754] Trial 75 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0004692244666351754, 'C': 41.4819560855715, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:30:31,072] Trial 76 finished with value: 0.9005868108697388 and parameters: {'tol': 0.0009966402002368315, 'C': 55.54317500594569, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:31,679] Trial 77 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0001300302557363435, 'C': 95.40510318536197, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:34,506] Trial 78 finished with value: 0.8478774359512791 and parameters: {'tol': 0.00011444403460742941, 'C': 67.157322843548, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:36,838] Trial 79 finished with value: 0.8375464915589985 and parameters: {'tol': 0.000561377033563851, 'C': 87.66536149929847, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:38,786] Trial 80 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0007043756883311244, 'C': 21.296424021249457, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:39,306] Trial 81 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0004380374471017054, 'C': 90.41587040778789, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:30:44,621] Trial 82 finished with value: 0.9010134081634122 and parameters: {'tol': 0.0008625013450379985, 'C': 94.95206287055798, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:30:50,065] Trial 83 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0009800525427101916, 'C': 49.26181447310602, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:52,192] Trial 84 finished with value: 0.8375464915589985 and parameters: {'tol': 0.00012891779311881467, 'C': 15.190277832202499, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:54,287] Trial 85 finished with value: 0.8375464915589985 and parameters: {'tol': 0.00047448767862260955, 'C': 66.75577717652533, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:56,387] Trial 86 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0001778334737924701, 'C': 8.870262488680224, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:30:59,072] Trial 87 finished with value: 0.8375464915589985 and parameters: {'tol': 0.000690704433800736, 'C': 3.931223590988495, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:31:00,432] Trial 88 finished with value: 0.9082276043023576 and parameters: {'tol': 6.20168818950089e-05, 'C': 27.68777204594389, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:31:01,073] Trial 89 finished with value: 0.8290908451538833 and parameters: {'tol': 0.0004850384622058304, 'C': 61.825480970481884, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:31:03,172] Trial 90 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0007136362362986679, 'C': 89.52068481665155, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:31:04,284] Trial 91 finished with value: 0.9082276043023576 and parameters: {'tol': 0.00024322803313109496, 'C': 26.924330402505785, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:31:04,907] Trial 92 finished with value: 0.8290908451538833 and parameters: {'tol': 0.00012064236968743198, 'C': 89.0527291687167, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:31:05,980] Trial 93 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0005375694352767293, 'C': 58.684115933676736, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:31:11,301] Trial 94 finished with value: 0.9082276043023576 and parameters: {'tol': 0.0006462713240902697, 'C': 57.07783475910814, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:31:15,143] Trial 95 finished with value: 0.8375464915589985 and parameters: {'tol': 0.0001537062800451477, 'C': 24.595780378873528, 'solver': 'saga'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:31:20,503] Trial 96 finished with value: 0.9082276043023576 and parameters: {'tol': 8.115351191598057e-05, 'C': 52.45114371191157, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2023-06-23 09:31:22,443] Trial 97 finished with value: 0.8478774359512791 and parameters: {'tol': 0.0008656416187680864, 'C': 81.70720892420728, 'solver': 'sag'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:31:23,478] Trial 98 finished with value: 0.9082276043023576 and parameters: {'tol': 0.00057204107678043, 'C': 27.99791656623748, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n",
            "[I 2023-06-23 09:31:24,725] Trial 99 finished with value: 0.9082276043023576 and parameters: {'tol': 0.00024316732268266517, 'C': 11.483691325552105, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.9082276043023576.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "vLcmvFM2i0L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df25ef0-38ba-49b6-ff3f-733f4e801474",
        "id": "5eaXmjiOi0L0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tol': 0.0003751655787285152, 'C': 95.07143113384855, 'solver': 'newton-cg'}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d63101-2757-4cf9-902e-d4b55504e7ed",
        "id": "TgR4muAli0L1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, ..., False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "fqxkUCufi0L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "SKOuQFpGi0L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "bcIAhFHdi0L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774899b5-6106-4e73-bdcc-0e0e4532bc49",
        "id": "bmGwpCmNi0L1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_LG = LogisticRegression(**best_params)"
      ],
      "metadata": {
        "id": "QCJfhL-9i0L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_LG.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "e2e484f8-d792-44c7-fd7f-6d1909b73918",
        "id": "8vo7Jsbgi0L2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=95.07143113384855, solver='newton-cg',\n",
              "                   tol=0.0003751655787285152)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=95.07143113384855, solver=&#x27;newton-cg&#x27;,\n",
              "                   tol=0.0003751655787285152)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=95.07143113384855, solver=&#x27;newton-cg&#x27;,\n",
              "                   tol=0.0003751655787285152)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_LG.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "BZlK7DNti0L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "ql--kEL5i0L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GaussianNB"
      ],
      "metadata": {
        "id": "iaGJZjp7mVLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "G6KgTWD8mbzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main goal of the provided code is to perform hyperparameter tuning for a GaussianNB classifier using the Optuna library.\n",
        "The code also stores the best set of features selected during the hyperparameter tuning in the best_features variable. If the hyperparameter tuning process is pruned (terminated early), the best_features variable will be set to the selected features of the last trial that was not pruned."
      ],
      "metadata": {
        "id": "CQtqj_6cP4vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "cD_yCs3_mbza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Optuna hyperparameter tuning\n",
        "def objective_GNB(trial):\n",
        "  global best_features\n",
        "  params = {\n",
        "            'var_smoothing': trial.suggest_float('var_smoothing', 1e-10, 1e-3, log=True)\n",
        "          }\n",
        "\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  #classifier = XGBClassifier(eta=eta,gamma=gamma ,min_child_weight=min_child_weight,max_delta_step=max_delta_step,subsample=subsample)\n",
        "  classifier = GaussianNB(**params)\n",
        "\n",
        "  # Perform cross-validation with feature selection\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "  feature_selector = SelectKBest(score_func=f_classif, k=300)  # Adjust the number of features as desired\n",
        "  best_features = None\n",
        "\n",
        "  for train_index, val_index in kf.split(X_train_val, y_train_val):\n",
        "      X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "      y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "\n",
        "      # Perform feature selection on the training set\n",
        "      X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
        "      selected_features = feature_selector.get_support()\n",
        "\n",
        "      # Apply the same feature selection on the validation set\n",
        "      X_val_selected = X_val[:, selected_features]\n",
        "\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train_selected, y_train)\n",
        "      y_pred = classifier.predict(X_val_selected)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  if trial.should_prune()==False:\n",
        "    best_features = selected_features.copy()\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "QO4ayWJ0mbzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Optuna study\n",
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective_GNB, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787e8dde-b19e-488c-bfc6-4b2f2f3fa961",
        "id": "l0rBE8xJmbzb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 09:42:52,640] A new study created in memory with name: no-name-97694674-8357-409a-ab60-fb09004a7e1e\n",
            "[I 2023-06-23 09:42:52,840] Trial 0 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 4.185822729546966e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:53,028] Trial 1 finished with value: 0.775315618686399 and parameters: {'var_smoothing': 0.0004518560951024107}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:53,213] Trial 2 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 1.3303245101522907e-05}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:53,421] Trial 3 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.5509913987594307e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:53,715] Trial 4 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.2363188277052218e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:53,874] Trial 5 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.2358382772306896e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:54,027] Trial 6 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.5502648504032847e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:54,197] Trial 7 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 0.00011567327199145979}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:54,350] Trial 8 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.6136341713591319e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:54,508] Trial 9 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 9.047071957568391e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:54,659] Trial 10 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.3934502251337584e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:54,783] Trial 11 finished with value: 0.776811530588348 and parameters: {'var_smoothing': 0.00061569973282352}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:54,955] Trial 12 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 6.715811311069945e-05}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:55,120] Trial 13 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 3.064599841241147e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:55,289] Trial 14 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.874022368883631e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:55,461] Trial 15 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.922346047064363e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:55,623] Trial 16 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.3480180290890788e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:55,782] Trial 17 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 4.7129737561107815e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:55,956] Trial 18 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.0558813779064848e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:56,170] Trial 19 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.0929592787219375e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:56,357] Trial 20 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.9185373703841914e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:56,535] Trial 21 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 9.472334467618544e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:56,832] Trial 22 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.1092068418536174e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:57,177] Trial 23 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 3.6688748954991754e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:57,483] Trial 24 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.5577217702693015e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:57,647] Trial 25 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 3.134958021096909e-05}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:57,791] Trial 26 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.4987135684669447e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:57,931] Trial 27 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 3.97778283081119e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:58,066] Trial 28 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.402497132660036e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:58,203] Trial 29 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.1142332035497139e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:58,337] Trial 30 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.7898389848671593e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:58,483] Trial 31 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.5619562520792733e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:58,620] Trial 32 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.853390105240223e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:58,756] Trial 33 finished with value: 0.775315618686399 and parameters: {'var_smoothing': 0.0004387314432435404}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:58,898] Trial 34 finished with value: 0.776811530588348 and parameters: {'var_smoothing': 0.0005746775499181862}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:59,032] Trial 35 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 4.55807468402733e-05}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:59,170] Trial 36 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.3561145768453489e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:59,310] Trial 37 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 4.827305651975699e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:59,452] Trial 38 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 6.1607159527745434e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:59,597] Trial 39 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.20522312541456e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:59,736] Trial 40 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 7.149367864959178e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:59,858] Trial 41 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.9257577949824413e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:42:59,974] Trial 42 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.740682839312808e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,084] Trial 43 finished with value: 0.775315618686399 and parameters: {'var_smoothing': 0.0002318690670290197}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,197] Trial 44 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 6.478282331897327e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,312] Trial 45 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 4.341661800361736e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,425] Trial 46 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.520468869219889e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,542] Trial 47 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 4.369946783595579e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,656] Trial 48 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 6.713854967599219e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,763] Trial 49 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.9678010532114953e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,881] Trial 50 finished with value: 0.776811530588348 and parameters: {'var_smoothing': 0.0006124806805925976}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:00,988] Trial 51 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 2.666427400467686e-05}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:01,098] Trial 52 finished with value: 0.775315618686399 and parameters: {'var_smoothing': 0.00037713131110779903}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:01,213] Trial 53 finished with value: 0.775315618686399 and parameters: {'var_smoothing': 0.0001835656654435508}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:01,324] Trial 54 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.5321449415450716e-06}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:01,442] Trial 55 finished with value: 0.775315618686399 and parameters: {'var_smoothing': 0.0002838700963443627}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:01,572] Trial 56 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 4.163394022669372e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:01,685] Trial 57 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.3543988498504872e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:01,798] Trial 58 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.0729604791291157e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:01,911] Trial 59 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.893704954163126e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,025] Trial 60 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 5.2570369292136696e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,140] Trial 61 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 7.933105363733031e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,251] Trial 62 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 6.326486185661583e-05}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,366] Trial 63 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 3.142485531883158e-08}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,486] Trial 64 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 9.258519973443778e-09}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,603] Trial 65 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 6.293215187893864e-07}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,721] Trial 66 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 9.693253593230319e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,832] Trial 67 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 4.1245717727594184e-05}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:02,948] Trial 68 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 3.325481267274218e-10}. Best is trial 0 with value: 0.7774806049494355.\n",
            "[I 2023-06-23 09:43:03,060] Trial 69 finished with value: 0.7851500822037473 and parameters: {'var_smoothing': 0.0008094845352286139}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:03,174] Trial 70 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 2.545150013091292e-05}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:03,290] Trial 71 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.460422958018417e-09}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:03,401] Trial 72 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.0930872279404526e-10}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:03,510] Trial 73 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 5.107754312955834e-05}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:03,628] Trial 74 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 8.871588860587616e-06}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:03,744] Trial 75 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 1.267798332692875e-05}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:03,862] Trial 76 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 2.5054885755573557e-05}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:03,974] Trial 77 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 3.298470179752563e-10}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,080] Trial 78 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 3.2304282522409615e-08}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,194] Trial 79 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 6.472669269538624e-10}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,308] Trial 80 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 0.0001100839441018131}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,420] Trial 81 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.3072087378099e-06}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,533] Trial 82 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.0715058970816234e-08}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,647] Trial 83 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.785533924389101e-10}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,765] Trial 84 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.5027137214154533e-08}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,878] Trial 85 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.889223130553437e-08}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:04,986] Trial 86 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 1.2800980864220754e-05}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,097] Trial 87 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.9033694281285623e-06}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,207] Trial 88 finished with value: 0.775315618686399 and parameters: {'var_smoothing': 0.00016236379661338317}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,321] Trial 89 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.0207122587167362e-07}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,431] Trial 90 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 6.873211713642716e-10}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,543] Trial 91 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 9.833622008382918e-06}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,649] Trial 92 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 2.1159009829538346e-05}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,772] Trial 93 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 8.490639132761158e-07}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,883] Trial 94 finished with value: 0.7678940594228604 and parameters: {'var_smoothing': 2.4932754437140142e-05}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:05,995] Trial 95 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 2.861338079089885e-07}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:06,103] Trial 96 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 4.5617324056306345e-07}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:06,215] Trial 97 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 9.835289062589968e-08}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:06,330] Trial 98 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 1.5063777323554432e-10}. Best is trial 69 with value: 0.7851500822037473.\n",
            "[I 2023-06-23 09:43:06,443] Trial 99 finished with value: 0.7774806049494355 and parameters: {'var_smoothing': 5.691673629899875e-10}. Best is trial 69 with value: 0.7851500822037473.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "kcR7mOoOmbzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e37cf83-6050-4b41-d21c-d40de0275798",
        "id": "I7hiNJG0mbzb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'var_smoothing': 0.0008094845352286139}"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af859bf1-36c2-43d3-eb73-8b46b190eb43",
        "id": "uMZJVa6Vmbzc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, ..., False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "80ABmQwBmbzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "lBHvjRTKmbzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features_indices]"
      ],
      "metadata": {
        "id": "wtdjcUAhmbzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774899b5-6106-4e73-bdcc-0e0e4532bc49",
        "id": "vQOSW3Dambzc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_GNB = GaussianNB(**best_params)"
      ],
      "metadata": {
        "id": "Rtr42gDambzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_GNB.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "660b96a8-ff6c-4e12-d89f-f0c4657d21c5",
        "id": "VXdvn1G5mbzd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(var_smoothing=0.0008094845352286139)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=0.0008094845352286139)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=0.0008094845352286139)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_GNB.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "G9FDx7lZmbzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "vdIWRE5Hmbzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MRMR for feature selection"
      ],
      "metadata": {
        "id": "adgjIoxk50RL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, the optimisation procedures employed were similar to those utilised in the preceding section. However, a notable distinction lies in the fact that feature selection was not conducted concurrently with hyperparameter optimisation (with different datasets employed). Instead, feature selection was performed on a separate dataset prior to hyperparameter optimisation. This approach was adopted due to the time-intensive nature of the mRMR procedure."
      ],
      "metadata": {
        "id": "1lywmJjdP_gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of features to keep"
      ],
      "metadata": {
        "id": "cROXpyNU68xU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_dataset_split(X_train_val, y_train_val):\n",
        "    X_train_features, X_evaluation, y_train_features, y_evaluation = train_test_split(X_train_val, y_train_val, test_size=0.30, random_state=30)\n",
        "    # Perform feature selection on X_train_features only\n",
        "    X_train_features_df = pd.DataFrame(X_train_features)\n",
        "    y_train_features_df = pd.DataFrame(y_train_features)\n",
        "    X_evaluation_df = pd.DataFrame(X_evaluation)\n",
        "    y_evaluation_df = pd.DataFrame(y_evaluation)\n",
        "    return X_train_features_df, y_train_features_df, X_evaluation_df,y_evaluation_df"
      ],
      "metadata": {
        "id": "M-jsiW2J7A9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_feature_selection(trial,X_train_features_df,y_train_features_df,X_evaluation_df,y_evaluation_df,scores):\n",
        "  # Define the search space for the number of features\n",
        "  num_features = trial.suggest_int(\"num_features\", 1, X_train_features_df.shape[1])\n",
        "\n",
        "  selected_features = mrmr_classif(X_train_features_df, y_train_features_df, K=num_features)\n",
        "  X_train_features_selected_df = X_train_features_df.loc[:,selected_features]\n",
        "  X_evaluation_selected = X_evaluation_df.loc[:, selected_features]\n",
        "\n",
        "  SVC_cl = SVC()\n",
        "  GNB_cl = GaussianNB()\n",
        "  LR_cl = LogisticRegression()\n",
        "  RF_cl = RandomForestClassifier()\n",
        "  XG_cl = XGBClassifier()\n",
        "\n",
        "  # Train the classifier on the selected features\n",
        "  SVC_cl.fit(X_train_features_selected_df ,y_train_features_df)\n",
        "  GNB_cl.fit(X_train_features_selected_df ,y_train_features_df)\n",
        "  LR_cl.fit(X_train_features_selected_df,y_train_features_df)\n",
        "  RF_cl.fit(X_train_features_selected_df,y_train_features_df)\n",
        "  XG_cl.fit(X_train_features_selected_df,y_train_features_df)\n",
        "\n",
        "  # Make predictions on the validation set\n",
        "  y_pred_SVC = SVC_cl.predict(X_evaluation_selected)\n",
        "  y_pred_GNB = GNB_cl.predict(X_evaluation_selected)\n",
        "  y_pred_LR = LR_cl.predict(X_evaluation_selected)\n",
        "  y_pred_RF = RF_cl.predict(X_evaluation_selected)\n",
        "  y_pred_XG = XG_cl.predict(X_evaluation_selected)\n",
        "\n",
        "  # Calculate the accuracy score\n",
        "  mcc_features_evaluation_GNB = matthews_corrcoef(y_evaluation_df, y_pred_GNB)\n",
        "  scores.append(mcc_features_evaluation_GNB)\n",
        "  mcc_features_evaluation_LR = matthews_corrcoef(y_evaluation_df, y_pred_LR)\n",
        "  scores.append(mcc_features_evaluation_LR)\n",
        "  mcc_features_evaluation_RF = matthews_corrcoef(y_evaluation_df, y_pred_RF)\n",
        "  scores.append(mcc_features_evaluation_RF)\n",
        "  mcc_features_evaluation_XG = matthews_corrcoef(y_evaluation_df, y_pred_XG)\n",
        "  scores.append(mcc_features_evaluation_XG)\n",
        "\n",
        "  avg_mcc = np.mean(scores) # we get the average in order to find the optimal number of features to keep according to all classifiers\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "1fGjmGTL8Y1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature selection\n",
        "X_train_features_df,y_train_features_df,X_evaluation_df,y_evaluation_df = perform_dataset_split(X_train_val, y_train_val)"
      ],
      "metadata": {
        "id": "BZmMIl8bEzOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores=[]"
      ],
      "metadata": {
        "id": "0vxUZWUXIjWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function with selected features\n",
        "def objective(trial):\n",
        "    return objective_feature_selection(trial,X_train_features_df,y_train_features_df,X_evaluation_df,y_evaluation_df,scores)"
      ],
      "metadata": {
        "id": "_-r-PHVl9ke9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "AvIxmkh29ke_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC\n",
        "\n"
      ],
      "metadata": {
        "id": "Cq_7zfHB55NT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "Ic3PxNai55NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "vquuRCCW55NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_feature_selection(X_train_val, y_train_val):\n",
        "    X_train_features, X_hyperparam_opt, y_train_features, y_hyperparam_opt = train_test_split(X_train_val, y_train_val, train_size=0.30, random_state=42)\n",
        "    # Perform feature selection on X_train_val\n",
        "    X_train_val_df = pd.DataFrame(X_train_features)\n",
        "    y_train_val_df = pd.DataFrame(y_train_features)\n",
        "    X_hyperparam_opt = pd.DataFrame(X_hyperparam_opt)\n",
        "    y_hyperparam_opt = pd.DataFrame(y_hyperparam_opt)\n",
        "    selected_features = mrmr_classif(X_train_val_df, y_train_val_df, K=300)\n",
        "    X_train_val_selected = X_hyperparam_opt.loc[:, selected_features] # filter the dataset for hyperparameters tunning according to the selected features\n",
        "\n",
        "    return X_train_val_selected, y_hyperparam_opt,selected_features"
      ],
      "metadata": {
        "id": "AwpamdziSol5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_SVC(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features):\n",
        "    # Define the hyperparameters to be optimized\n",
        "    C = trial.suggest_float('C', 0.1, 10)\n",
        "    gamma = trial.suggest_float('gamma', 0.01, 1)\n",
        "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "    degree = trial.suggest_int('degree', 2, 10)\n",
        "\n",
        "    # Instantiate the classifier with the current hyperparameters\n",
        "    classifier = SVC(C=C, gamma=gamma, kernel=kernel, degree=degree)\n",
        "\n",
        "    # Perform cross-validation on the selected features\n",
        "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "    cv_scores = []\n",
        "\n",
        "    for train_index, val_index in kf.split(X_hyperparam_opt, y_hyperparam_opt):\n",
        "        X_train, X_val = X_hyperparam_opt.iloc[train_index], X_hyperparam_opt.iloc[val_index]\n",
        "        y_train, y_val = y_hyperparam_opt.iloc[train_index], y_hyperparam_opt.iloc[val_index]\n",
        "\n",
        "        # Fit the classifier on the selected features and evaluate on the validation set\n",
        "        classifier.fit(X_train, y_train)\n",
        "        y_pred = classifier.predict(X_val)\n",
        "        mcc = matthews_corrcoef(y_val, y_pred)\n",
        "        cv_scores.append(mcc)\n",
        "\n",
        "    # Calculate the average MCC\n",
        "    avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "    return avg_mcc"
      ],
      "metadata": {
        "id": "sK4zjdyFWlnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature selection\n",
        "X_hyperparam_opt, y_hyperparam_opt,selected_features = perform_feature_selection(X_train_val, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMHwr1xXS4w6",
        "outputId": "bc8e6e31-4cae-4378-a214-3a4ffe7529ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [02:54<00:00,  1.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function with selected features\n",
        "def objective(trial):\n",
        "    return objective_SVC(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features)"
      ],
      "metadata": {
        "id": "wkemfnaAS8lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeaUX7t5S9j3",
        "outputId": "64238fe6-ce39-4feb-91f5-cadee4d01718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 13:05:54,447] A new study created in memory with name: no-name-a5ae983e-a302-4932-aeb4-224d2f54f8b6\n",
            "[I 2023-06-23 13:05:55,247] Trial 0 finished with value: 0.8668486306868823 and parameters: {'C': 3.807947176588889, 'gamma': 0.951207163345817, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:05:57,939] Trial 1 finished with value: 0.0 and parameters: {'C': 8.675143843171858, 'gamma': 0.6051038616257767, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:05:59,366] Trial 2 finished with value: 0.0 and parameters: {'C': 1.9000671753502962, 'gamma': 0.1915704647548995, 'kernel': 'poly', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:01,140] Trial 3 finished with value: 0.0 and parameters: {'C': 1.4809892204552142, 'gamma': 0.29922320204986597, 'kernel': 'rbf', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:01,479] Trial 4 finished with value: 0.08880087844372722 and parameters: {'C': 5.96490423173422, 'gamma': 0.05598590859279775, 'kernel': 'sigmoid', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:02,966] Trial 5 finished with value: 0.0 and parameters: {'C': 8.103133746352965, 'gamma': 0.31156763148163696, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:04,454] Trial 6 finished with value: 0.0 and parameters: {'C': 0.4404463590406621, 'gamma': 0.9102271980579942, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:06,071] Trial 7 finished with value: 0.0 and parameters: {'C': 1.9300591097027178, 'gamma': 0.9698887814869129, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:08,289] Trial 8 finished with value: 0.0 and parameters: {'C': 0.976075770314003, 'gamma': 0.20402303379495376, 'kernel': 'rbf', 'degree': 9}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:10,080] Trial 9 finished with value: 0.0 and parameters: {'C': 3.631857934266534, 'gamma': 0.28812516459050697, 'kernel': 'rbf', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:11,565] Trial 10 finished with value: 0.0 and parameters: {'C': 7.7452232160369086, 'gamma': 0.2067285247188307, 'kernel': 'poly', 'degree': 8}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:12,162] Trial 11 finished with value: 0.26188115883060437 and parameters: {'C': 0.8330420521674946, 'gamma': 0.3648810712588299, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:13,981] Trial 12 finished with value: 0.0 and parameters: {'C': 3.178724984985056, 'gamma': 0.3319314888064796, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:15,291] Trial 13 finished with value: 0.0 and parameters: {'C': 7.16112339350765, 'gamma': 0.7631771981307285, 'kernel': 'poly', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:16,802] Trial 14 finished with value: 0.0 and parameters: {'C': 0.35164935476654235, 'gamma': 0.1168125127233714, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:17,145] Trial 15 finished with value: 0.8668486306868823 and parameters: {'C': 2.567993068573862, 'gamma': 0.41627909380527345, 'kernel': 'linear', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:18,722] Trial 16 finished with value: 0.0 and parameters: {'C': 9.304006758191473, 'gamma': 0.8100391757687728, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:19,173] Trial 17 finished with value: 0.8668486306868823 and parameters: {'C': 5.439488194964942, 'gamma': 0.8093657536124219, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:20,566] Trial 18 finished with value: 0.0 and parameters: {'C': 8.198346182632681, 'gamma': 0.86212327742378, 'kernel': 'poly', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:22,499] Trial 19 finished with value: 0.0 and parameters: {'C': 3.442390196895917, 'gamma': 0.943480606873394, 'kernel': 'rbf', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:22,837] Trial 20 finished with value: 0.8668486306868823 and parameters: {'C': 9.628228219926902, 'gamma': 0.2592644728671105, 'kernel': 'linear', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:24,308] Trial 21 finished with value: 0.0 and parameters: {'C': 5.076522329965728, 'gamma': 0.06096396373748946, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:25,635] Trial 22 finished with value: 0.0 and parameters: {'C': 9.857939495694946, 'gamma': 0.2496347187963854, 'kernel': 'poly', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:27,465] Trial 23 finished with value: 0.0 and parameters: {'C': 6.359827722876437, 'gamma': 0.6371944136532858, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:27,800] Trial 24 finished with value: 0.8668486306868823 and parameters: {'C': 0.5036739013921628, 'gamma': 0.5949840137563595, 'kernel': 'linear', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:28,961] Trial 25 finished with value: 0.0 and parameters: {'C': 1.8262276471494154, 'gamma': 0.6940283607214413, 'kernel': 'poly', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:30,739] Trial 26 finished with value: 0.0 and parameters: {'C': 9.254466820957772, 'gamma': 0.8785659598471712, 'kernel': 'rbf', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:32,241] Trial 27 finished with value: 0.0 and parameters: {'C': 2.4943376799144716, 'gamma': 0.10217174012784021, 'kernel': 'poly', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:32,716] Trial 28 finished with value: 0.8668486306868823 and parameters: {'C': 7.286961220815369, 'gamma': 0.8981391573530513, 'kernel': 'linear', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:34,879] Trial 29 finished with value: 0.0 and parameters: {'C': 8.995686466418084, 'gamma': 0.6103647690629941, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:36,710] Trial 30 finished with value: 0.0 and parameters: {'C': 5.532464514729202, 'gamma': 0.6949762457157663, 'kernel': 'rbf', 'degree': 4}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:37,040] Trial 31 finished with value: 0.8668486306868823 and parameters: {'C': 7.490264910668439, 'gamma': 0.6531365700567425, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:37,378] Trial 32 finished with value: 0.8668486306868823 and parameters: {'C': 2.7255034400490823, 'gamma': 0.25154974694529275, 'kernel': 'linear', 'degree': 9}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:39,206] Trial 33 finished with value: 0.0 and parameters: {'C': 5.076107221741402, 'gamma': 0.5811348457800956, 'kernel': 'rbf', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:39,825] Trial 34 finished with value: 0.26188115883060437 and parameters: {'C': 6.490175729480962, 'gamma': 0.18533957261297845, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:40,153] Trial 35 finished with value: 0.8668486306868823 and parameters: {'C': 9.29035376961848, 'gamma': 0.4339023068341412, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:42,005] Trial 36 finished with value: 0.0 and parameters: {'C': 8.526253048016883, 'gamma': 0.3237527851047149, 'kernel': 'rbf', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:42,346] Trial 37 finished with value: 0.8668486306868823 and parameters: {'C': 1.0620472883306085, 'gamma': 0.618857154432178, 'kernel': 'linear', 'degree': 8}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:42,663] Trial 38 finished with value: 0.12572453409517073 and parameters: {'C': 7.000455835853153, 'gamma': 0.7054592431472382, 'kernel': 'sigmoid', 'degree': 9}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:44,085] Trial 39 finished with value: 0.0 and parameters: {'C': 9.141081470309066, 'gamma': 0.5162289748723284, 'kernel': 'poly', 'degree': 9}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:46,335] Trial 40 finished with value: 0.0 and parameters: {'C': 8.911052883993907, 'gamma': 0.3446152052830205, 'kernel': 'rbf', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:46,763] Trial 41 finished with value: 0.09112543032314517 and parameters: {'C': 5.472181883605009, 'gamma': 0.29367583960700155, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:47,218] Trial 42 finished with value: 0.8668486306868823 and parameters: {'C': 1.3578990752536595, 'gamma': 0.5270208274542564, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:49,136] Trial 43 finished with value: 0.0 and parameters: {'C': 5.360410852524665, 'gamma': 0.5452287703940054, 'kernel': 'rbf', 'degree': 4}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:49,451] Trial 44 finished with value: 0.11307483045187225 and parameters: {'C': 7.972343328210166, 'gamma': 0.27812392874945346, 'kernel': 'sigmoid', 'degree': 9}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:49,774] Trial 45 finished with value: 0.20329185806627265 and parameters: {'C': 6.9901446403276095, 'gamma': 0.4148634149701272, 'kernel': 'sigmoid', 'degree': 8}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:50,104] Trial 46 finished with value: 0.8668486306868823 and parameters: {'C': 6.635954029505539, 'gamma': 0.2871345579764834, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:50,433] Trial 47 finished with value: 0.8668486306868823 and parameters: {'C': 2.552536796061459, 'gamma': 0.362412951864749, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:52,245] Trial 48 finished with value: 0.0 and parameters: {'C': 8.56905978170897, 'gamma': 0.7066212807862234, 'kernel': 'rbf', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:53,680] Trial 49 finished with value: 0.0 and parameters: {'C': 4.395131327455933, 'gamma': 0.4045196870533997, 'kernel': 'poly', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:54,008] Trial 50 finished with value: 0.8668486306868823 and parameters: {'C': 5.081048959942868, 'gamma': 0.857924942776439, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:55,818] Trial 51 finished with value: 0.0 and parameters: {'C': 5.899178254607286, 'gamma': 0.940827939010708, 'kernel': 'rbf', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:56,150] Trial 52 finished with value: 0.8668486306868823 and parameters: {'C': 9.4205016068876, 'gamma': 0.39224161142276653, 'kernel': 'linear', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:56,474] Trial 53 finished with value: 0.2134926016380395 and parameters: {'C': 0.28039607395034233, 'gamma': 0.1034985311483691, 'kernel': 'sigmoid', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:56,779] Trial 54 finished with value: 0.09853802401581964 and parameters: {'C': 8.163237977630464, 'gamma': 0.28903622702566595, 'kernel': 'sigmoid', 'degree': 8}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:57,078] Trial 55 finished with value: 0.09853802401581964 and parameters: {'C': 8.05446121081, 'gamma': 0.28921422684559345, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:58,830] Trial 56 finished with value: 0.0 and parameters: {'C': 3.782979049348554, 'gamma': 0.7786488311345768, 'kernel': 'poly', 'degree': 8}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:59,274] Trial 57 finished with value: 0.8668486306868823 and parameters: {'C': 7.5699744534383555, 'gamma': 0.11209263014757327, 'kernel': 'linear', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:06:59,709] Trial 58 finished with value: 0.16544851586970477 and parameters: {'C': 3.953096619468215, 'gamma': 0.020729274965495377, 'kernel': 'sigmoid', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:00,202] Trial 59 finished with value: 0.13785764229104622 and parameters: {'C': 5.777035092420532, 'gamma': 0.6355188400481013, 'kernel': 'sigmoid', 'degree': 8}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:00,638] Trial 60 finished with value: 0.1881657686907119 and parameters: {'C': 7.9366325328859, 'gamma': 0.7917219613666083, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:02,457] Trial 61 finished with value: 0.0 and parameters: {'C': 8.888271409307167, 'gamma': 0.3574058624265579, 'kernel': 'rbf', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:03,072] Trial 62 finished with value: 0.26188115883060437 and parameters: {'C': 0.9326573805384746, 'gamma': 0.7039594401445288, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:03,389] Trial 63 finished with value: 0.11006053394523882 and parameters: {'C': 9.867731827161636, 'gamma': 0.3805280877985591, 'kernel': 'sigmoid', 'degree': 8}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:03,692] Trial 64 finished with value: 0.13796080110797956 and parameters: {'C': 3.824969896756066, 'gamma': 0.09266570953168207, 'kernel': 'sigmoid', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:04,029] Trial 65 finished with value: 0.8668486306868823 and parameters: {'C': 4.976988532479505, 'gamma': 0.021240108319744877, 'kernel': 'linear', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:04,358] Trial 66 finished with value: 0.8668486306868823 and parameters: {'C': 7.48584430472769, 'gamma': 0.587535077446188, 'kernel': 'linear', 'degree': 4}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:04,677] Trial 67 finished with value: 0.8668486306868823 and parameters: {'C': 9.635903140462052, 'gamma': 0.022032929942918177, 'kernel': 'linear', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:05,008] Trial 68 finished with value: 0.8668486306868823 and parameters: {'C': 0.8305859908804487, 'gamma': 0.5583157415573076, 'kernel': 'linear', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:05,315] Trial 69 finished with value: 0.10256183046319686 and parameters: {'C': 6.312824992832228, 'gamma': 0.5884711688038693, 'kernel': 'sigmoid', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:07,084] Trial 70 finished with value: 0.0 and parameters: {'C': 4.611001852578558, 'gamma': 0.6239312718235214, 'kernel': 'rbf', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:07,408] Trial 71 finished with value: 0.8668486306868823 and parameters: {'C': 0.8695729059533499, 'gamma': 0.9746508595895048, 'kernel': 'linear', 'degree': 9}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:09,190] Trial 72 finished with value: 0.0 and parameters: {'C': 6.878838608283405, 'gamma': 0.17099076995144238, 'kernel': 'rbf', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:09,524] Trial 73 finished with value: 0.8668486306868823 and parameters: {'C': 4.240606059277127, 'gamma': 0.9334011985204731, 'kernel': 'linear', 'degree': 9}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:11,506] Trial 74 finished with value: 0.0 and parameters: {'C': 9.87403368021795, 'gamma': 0.15891272219249292, 'kernel': 'rbf', 'degree': 9}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:13,843] Trial 75 finished with value: 0.0 and parameters: {'C': 4.740062281970205, 'gamma': 0.42067130731428853, 'kernel': 'rbf', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:15,332] Trial 76 finished with value: 0.0 and parameters: {'C': 9.966704687031664, 'gamma': 0.5598773885466012, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:17,114] Trial 77 finished with value: 0.0 and parameters: {'C': 1.3786782099998005, 'gamma': 0.9545105169861352, 'kernel': 'rbf', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:17,436] Trial 78 finished with value: 0.11055773159837487 and parameters: {'C': 1.2242201627763274, 'gamma': 0.6748574636368716, 'kernel': 'sigmoid', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:17,734] Trial 79 finished with value: 0.18637110076160163 and parameters: {'C': 5.653285918200324, 'gamma': 0.8778870666317615, 'kernel': 'sigmoid', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:18,043] Trial 80 finished with value: 0.11506131532088473 and parameters: {'C': 7.070389704182313, 'gamma': 0.22083451989382163, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:19,846] Trial 81 finished with value: 0.0 and parameters: {'C': 4.431001728034918, 'gamma': 0.9051171075488109, 'kernel': 'rbf', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:21,331] Trial 82 finished with value: 0.0 and parameters: {'C': 8.637400716592778, 'gamma': 0.9500254174210657, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:22,448] Trial 83 finished with value: 0.0 and parameters: {'C': 9.802322495326223, 'gamma': 0.4976919130529409, 'kernel': 'poly', 'degree': 3}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:23,935] Trial 84 finished with value: 0.0 and parameters: {'C': 1.3676538056819474, 'gamma': 0.1603836665771714, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:25,662] Trial 85 finished with value: -0.005847928217589523 and parameters: {'C': 4.792220238602436, 'gamma': 0.6708821611358169, 'kernel': 'poly', 'degree': 4}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:27,421] Trial 86 finished with value: 0.0 and parameters: {'C': 1.8524037943397935, 'gamma': 0.09781550841948505, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:27,755] Trial 87 finished with value: 0.16518178910158937 and parameters: {'C': 6.934908803430717, 'gamma': 0.04891901844268795, 'kernel': 'sigmoid', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:28,083] Trial 88 finished with value: 0.8668486306868823 and parameters: {'C': 0.7046718025631511, 'gamma': 0.2841088716657317, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:29,919] Trial 89 finished with value: 0.0 and parameters: {'C': 4.896777553391111, 'gamma': 0.622072223814993, 'kernel': 'rbf', 'degree': 4}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:31,421] Trial 90 finished with value: 0.0 and parameters: {'C': 7.162160900257069, 'gamma': 0.8962547693103273, 'kernel': 'poly', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:31,762] Trial 91 finished with value: 0.8668486306868823 and parameters: {'C': 2.500457985983824, 'gamma': 0.2765507986398872, 'kernel': 'linear', 'degree': 4}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:33,516] Trial 92 finished with value: 0.0 and parameters: {'C': 1.2856451050105873, 'gamma': 0.891622007932496, 'kernel': 'rbf', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:33,838] Trial 93 finished with value: 0.8668486306868823 and parameters: {'C': 5.417354764003623, 'gamma': 0.5909727068406704, 'kernel': 'linear', 'degree': 5}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:34,434] Trial 94 finished with value: 0.26188115883060437 and parameters: {'C': 6.494580689182852, 'gamma': 0.5750705216222227, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:36,231] Trial 95 finished with value: 0.0 and parameters: {'C': 1.6133054779248872, 'gamma': 0.25349815110066304, 'kernel': 'rbf', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:37,876] Trial 96 finished with value: 0.0 and parameters: {'C': 0.8943140820502579, 'gamma': 0.5292662756745521, 'kernel': 'poly', 'degree': 10}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:38,306] Trial 97 finished with value: 0.18430378076261503 and parameters: {'C': 8.668520546350404, 'gamma': 0.8189013502397872, 'kernel': 'sigmoid', 'degree': 7}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:38,754] Trial 98 finished with value: 0.8668486306868823 and parameters: {'C': 5.758965625752008, 'gamma': 0.28717930272368136, 'kernel': 'linear', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 13:07:39,224] Trial 99 finished with value: 0.8668486306868823 and parameters: {'C': 2.4998563509092944, 'gamma': 0.1236884564918115, 'kernel': 'linear', 'degree': 6}. Best is trial 0 with value: 0.8668486306868823.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hs7vQbpIS9ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "s4MsxNNo55NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params #42 random seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782f5859-1541-4da0-d930-e339bc1efb93",
        "id": "fV2ZBe2n55NV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 3.807947176588889,\n",
              " 'gamma': 0.951207163345817,\n",
              " 'kernel': 'linear',\n",
              " 'degree': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "-BlP0-f355NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features]"
      ],
      "metadata": {
        "id": "2Klj9Ids55NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pntd0rgXYAPG",
        "outputId": "f5f3f933-fa09-433e-8d73-05e72d00540c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features]"
      ],
      "metadata": {
        "id": "foQaeIWO55NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOfhlWP4YN5_",
        "outputId": "539d731e-a93b-4de5-dd1b-0f5340e9289d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1141, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best_C = study.best_params['C']\n",
        "#best_gamma = study.best_params['gamma']\n",
        "#best_gamma = study.best_params['gamma']\n",
        "#best_classifier = SVC(C=best_C, gamma=best_gamma)\n",
        "best_classifier_SVC = SVC(**best_params)"
      ],
      "metadata": {
        "id": "FPNOqYVN55NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_SVC.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "fcc74494-3806-4331-e320-b2dafed5e70f",
        "id": "_x7rOdPk55NW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=3.807947176588889, degree=2, gamma=0.951207163345817, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=3.807947176588889, degree=2, gamma=0.951207163345817, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=3.807947176588889, degree=2, gamma=0.951207163345817, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_SVC.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "z4CHWrjt55NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "WWa3X3HQ55NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "m8dWgBDt55NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "oSjrzq4NY1n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "K5FHBb3rY1oA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_feature_selection(X_train_val, y_train_val):\n",
        "    X_train_features, X_hyperparam_opt, y_train_features, y_hyperparam_opt = train_test_split(X_train_val, y_train_val, train_size=0.30, random_state=42)\n",
        "    # Perform feature selection on X_train_val\n",
        "    X_train_val_df = pd.DataFrame(X_train_features)\n",
        "    y_train_val_df = pd.DataFrame(y_train_features)\n",
        "    X_hyperparam_opt = pd.DataFrame(X_hyperparam_opt)\n",
        "    y_hyperparam_opt = pd.DataFrame(y_hyperparam_opt)\n",
        "    selected_features = mrmr_classif(X_train_val_df, y_train_val_df, K=300)\n",
        "    X_train_val_selected = X_hyperparam_opt.loc[:, selected_features] # filter the dataset for hyperparameters tunning according to the selected features\n",
        "\n",
        "    return X_train_val_selected, y_hyperparam_opt,selected_features"
      ],
      "metadata": {
        "id": "TmQymtbdY1oB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_RF(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features):\n",
        "\n",
        "  # Define the hyperparameters to be optimized\n",
        "  n_estimators= trial.suggest_int('n_estimators', 100,1000)\n",
        "  max_depth= trial.suggest_int('max_depth', 5, 31)\n",
        "  min_samples_split= trial.suggest_int('min_samples_split', 2, 100)\n",
        "  min_samples_leaf= trial.suggest_int('min_samples_leaf', 1, 4)\n",
        "  bootstrap=trial.suggest_categorical('bootstrap', [True, False])\n",
        "\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,min_samples_split=min_samples_split,min_samples_leaf=min_samples_leaf,bootstrap=bootstrap)\n",
        "\n",
        "  # Perform cross-validation on the selected features\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "\n",
        "  for train_index, val_index in kf.split(X_hyperparam_opt, y_hyperparam_opt):\n",
        "      X_train, X_val = X_hyperparam_opt.iloc[train_index], X_hyperparam_opt.iloc[val_index]\n",
        "      y_train, y_val = y_hyperparam_opt.iloc[train_index], y_hyperparam_opt.iloc[val_index]\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train, y_train)\n",
        "      y_pred = classifier.predict(X_val)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "bB5_B840Y1oC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature selection\n",
        "X_hyperparam_opt, y_hyperparam_opt,selected_features = perform_feature_selection(X_train_val, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7bcd061-4b81-419e-a98c-1b0ad9cc767c",
        "id": "TBfdzvg2Y1oC"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:01<00:00,  1.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function with selected features\n",
        "def objective(trial):\n",
        "    return objective_RF(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features)"
      ],
      "metadata": {
        "id": "N7NFh8-PY1oD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "Vnu90gdvTjn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "_2e5Mz5YY1oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params #42 random seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b762a15-7621-4f2b-8378-375d23836351",
        "id": "nktoosvMY1oE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 110,\n",
              " 'max_depth': 17,\n",
              " 'min_samples_split': 7,\n",
              " 'min_samples_leaf': 1,\n",
              " 'bootstrap': False}"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "t0EjgtUbY1oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features]"
      ],
      "metadata": {
        "id": "Uw_rM0MGY1oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "569064a9-c54f-4c4e-9499-5b43abd72aed",
        "id": "i0bv6G_jY1oE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features]"
      ],
      "metadata": {
        "id": "QTir4VPAY1oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0198b6-d66b-4124-cae1-e05e8af42c3d",
        "id": "Dm1FSm-aY1oF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1141, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best_C = study.best_params['C']\n",
        "#best_gamma = study.best_params['gamma']\n",
        "#best_gamma = study.best_params['gamma']\n",
        "#best_classifier = SVC(C=best_C, gamma=best_gamma)\n",
        "best_classifier_RF = RandomForestClassifier(**best_params)"
      ],
      "metadata": {
        "id": "3vPk6DWeY1oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_RF.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "be067b2b-1c8a-40ea-c4c6-48e229ebc7c3",
        "id": "sN1zj4s4Y1oF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, max_depth=17, min_samples_split=7,\n",
              "                       n_estimators=110)"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, max_depth=17, min_samples_split=7,\n",
              "                       n_estimators=110)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=17, min_samples_split=7,\n",
              "                       n_estimators=110)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_RF.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "kQq-KrpgY1oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "QbZyogmlY1oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "wNO0TNF355Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "Fxmz_P4xaOEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "NhzbrjDiaOEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_feature_selection(X_train_val, y_train_val):\n",
        "    X_train_features, X_hyperparam_opt, y_train_features, y_hyperparam_opt = train_test_split(X_train_val, y_train_val, train_size=0.30, random_state=42)\n",
        "    # Perform feature selection on X_train_val\n",
        "    X_train_val_df = pd.DataFrame(X_train_features)\n",
        "    y_train_val_df = pd.DataFrame(y_train_features)\n",
        "    X_hyperparam_opt = pd.DataFrame(X_hyperparam_opt)\n",
        "    y_hyperparam_opt = pd.DataFrame(y_hyperparam_opt)\n",
        "    selected_features = mrmr_classif(X_train_val_df, y_train_val_df, K=300)\n",
        "    X_train_val_selected = X_hyperparam_opt.loc[:, selected_features] # filter the dataset for hyperparameters tunning according to the selected features\n",
        "\n",
        "    return X_train_val_selected, y_hyperparam_opt,selected_features"
      ],
      "metadata": {
        "id": "PUCtstaZaOEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_XG(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features):\n",
        "\n",
        "  params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "            'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
        "            'random_state': 42,\n",
        "            'tree_method': 'hist',  # Optional: Use 'hist' method for faster training\n",
        "            'objective': 'multi:softmax',\n",
        "            'num_class': 2  # Replace with the actual number of classes\n",
        "        }\n",
        "\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  classifier = XGBClassifier(**params)\n",
        "\n",
        "  # Perform cross-validation on the selected features\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "\n",
        "  for train_index, val_index in kf.split(X_hyperparam_opt, y_hyperparam_opt):\n",
        "      X_train, X_val = X_hyperparam_opt.iloc[train_index], X_hyperparam_opt.iloc[val_index]\n",
        "      y_train, y_val = y_hyperparam_opt.iloc[train_index], y_hyperparam_opt.iloc[val_index]\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train, y_train)\n",
        "      y_pred = classifier.predict(X_val)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "SzVd-4ljaOEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature selection\n",
        "X_hyperparam_opt, y_hyperparam_opt,selected_features = perform_feature_selection(X_train_val, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355fc8ec-d62b-46f8-be52-b3cad9569467",
        "id": "5sPNbSaJaOEp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:16<00:00,  1.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function with selected features\n",
        "def objective(trial):\n",
        "    return objective_XG(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features)"
      ],
      "metadata": {
        "id": "tmk7ymqLaOEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e93a0d-fb9e-4275-cc7a-8aafd644b4bd",
        "id": "tMzW-W8caOEp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 15:03:05,906] A new study created in memory with name: no-name-48c5052b-3ded-476f-8b38-99c3f1e2cd3a\n",
            "[I 2023-06-23 15:03:46,773] Trial 0 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 106, 'max_depth': 20, 'learning_rate': 0.07587945476302646, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'gamma': 0.7799726016810132, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:04:41,323] Trial 1 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 180, 'max_depth': 14, 'learning_rate': 0.0737265320016441, 'subsample': 0.5102922471479012, 'colsample_bytree': 0.9849549260809971, 'gamma': 4.162213204002109, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:05:15,891] Trial 2 finished with value: 0.9301788222413163 and parameters: {'n_estimators': 77, 'max_depth': 7, 'learning_rate': 0.0373818018663584, 'subsample': 0.762378215816119, 'colsample_bytree': 0.7159725093210578, 'gamma': 1.4561457009902097, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:05:51,885] Trial 3 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 71, 'max_depth': 9, 'learning_rate': 0.04297256589643226, 'subsample': 0.728034992108518, 'colsample_bytree': 0.8925879806965068, 'gamma': 0.9983689107917987, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:06:22,708] Trial 4 finished with value: 0.9285345806485132 and parameters: {'n_estimators': 139, 'max_depth': 5, 'learning_rate': 0.06467903667112945, 'subsample': 0.5852620618436457, 'colsample_bytree': 0.5325257964926398, 'gamma': 4.7444276862666666, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:07:40,721] Trial 5 finished with value: 0.9296699993268674 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.018790490260574548, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007, 'gamma': 0.6101911742238941, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:08:10,999] Trial 6 finished with value: 0.922835115684645 and parameters: {'n_estimators': 55, 'max_depth': 19, 'learning_rate': 0.03329019834400153, 'subsample': 0.831261142176991, 'colsample_bytree': 0.6558555380447055, 'gamma': 2.600340105889054, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:08:40,066] Trial 7 finished with value: 0.9392499125618322 and parameters: {'n_estimators': 77, 'max_depth': 20, 'learning_rate': 0.07976195410250031, 'subsample': 0.9697494707820946, 'colsample_bytree': 0.9474136752138245, 'gamma': 2.9894998940554256, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:09:07,379] Trial 8 finished with value: 0.9120063509948901 and parameters: {'n_estimators': 63, 'max_depth': 8, 'learning_rate': 0.014070456001948426, 'subsample': 0.6626651653816322, 'colsample_bytree': 0.6943386448447411, 'gamma': 1.3567451588694794, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:09:44,009] Trial 9 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 103, 'max_depth': 9, 'learning_rate': 0.058842647484242366, 'subsample': 0.5704621124873813, 'colsample_bytree': 0.9010984903770198, 'gamma': 0.3727532183988541, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:10:55,944] Trial 10 finished with value: 0.9060007382093618 and parameters: {'n_estimators': 166, 'max_depth': 8, 'learning_rate': 0.010496990541124216, 'subsample': 0.9077307142274171, 'colsample_bytree': 0.8534286719238086, 'gamma': 3.6450358402049368, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:11:34,768] Trial 11 finished with value: 0.9057006944637622 and parameters: {'n_estimators': 61, 'max_depth': 10, 'learning_rate': 0.020428215357261678, 'subsample': 0.9315517129377968, 'colsample_bytree': 0.811649063413779, 'gamma': 1.654490124263246, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:12:15,673] Trial 12 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 96, 'max_depth': 10, 'learning_rate': 0.07566455605042577, 'subsample': 0.8187787356776066, 'colsample_bytree': 0.9436063712881633, 'gamma': 2.3610746258097466, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:13:01,783] Trial 13 finished with value: 0.9392499125618322 and parameters: {'n_estimators': 157, 'max_depth': 17, 'learning_rate': 0.06051494778125467, 'subsample': 0.8854835899772805, 'colsample_bytree': 0.7468977981821954, 'gamma': 2.6136641469099704, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:13:23,482] Trial 14 finished with value: 0.9159449250354099 and parameters: {'n_estimators': 53, 'max_depth': 6, 'learning_rate': 0.012828626711806084, 'subsample': 0.8182052056318903, 'colsample_bytree': 0.6571779905381634, 'gamma': 2.542853455823514, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:13:56,476] Trial 15 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 87, 'max_depth': 11, 'learning_rate': 0.07799960246887438, 'subsample': 0.6143990827458112, 'colsample_bytree': 0.5384899549143964, 'gamma': 1.4487572645688402, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:14:47,686] Trial 16 finished with value: 0.9293057257357841 and parameters: {'n_estimators': 190, 'max_depth': 17, 'learning_rate': 0.06700633808593812, 'subsample': 0.9357302950938589, 'colsample_bytree': 0.9018360384495572, 'gamma': 0.9328502944301792, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:15:22,219] Trial 17 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 131, 'max_depth': 17, 'learning_rate': 0.0906482169931144, 'subsample': 0.6590017374859319, 'colsample_bytree': 0.5550259622638384, 'gamma': 1.1396758127097084, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:16:56,653] Trial 18 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 173, 'max_depth': 18, 'learning_rate': 0.010625691747807163, 'subsample': 0.7553736512887829, 'colsample_bytree': 0.7087055015743895, 'gamma': 1.1105390523536514, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:17:41,383] Trial 19 finished with value: 0.9401230090673645 and parameters: {'n_estimators': 100, 'max_depth': 20, 'learning_rate': 0.03908826388186797, 'subsample': 0.7593953108716831, 'colsample_bytree': 0.8515094794475889, 'gamma': 1.81814801189647, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:18:30,647] Trial 20 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 195, 'max_depth': 9, 'learning_rate': 0.0547523655303147, 'subsample': 0.6504391549083848, 'colsample_bytree': 0.6424202471887338, 'gamma': 0.18443473677266398, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:19:24,040] Trial 21 finished with value: 0.9296699993268674 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.035078181781295036, 'subsample': 0.9541329429833268, 'colsample_bytree': 0.6197809453334862, 'gamma': 0.7244743604561155, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:20:13,442] Trial 22 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.07049219926652908, 'subsample': 0.8808098076643588, 'colsample_bytree': 0.6188187719961998, 'gamma': 3.641081743059298, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:21:05,993] Trial 23 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 145, 'max_depth': 15, 'learning_rate': 0.05821972156672827, 'subsample': 0.5451448850272042, 'colsample_bytree': 0.917651247794619, 'gamma': 1.6039003248586792, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:21:27,593] Trial 24 finished with value: 0.9301788222413163 and parameters: {'n_estimators': 56, 'max_depth': 14, 'learning_rate': 0.07098079256580542, 'subsample': 0.508293914463928, 'colsample_bytree': 0.7560465291496405, 'gamma': 1.1324788759896898, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:22:01,366] Trial 25 finished with value: 0.9392499125618322 and parameters: {'n_estimators': 76, 'max_depth': 16, 'learning_rate': 0.044806181167048376, 'subsample': 0.9683649943683672, 'colsample_bytree': 0.5687604720729966, 'gamma': 1.7053317552512925, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:23:11,511] Trial 26 finished with value: 0.9392499125618322 and parameters: {'n_estimators': 189, 'max_depth': 19, 'learning_rate': 0.033214746494364004, 'subsample': 0.8299920230170895, 'colsample_bytree': 0.9086111001006079, 'gamma': 2.7760040579973118, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:23:42,799] Trial 27 finished with value: 0.9296699993268674 and parameters: {'n_estimators': 86, 'max_depth': 6, 'learning_rate': 0.09074941821579942, 'subsample': 0.9502090285816652, 'colsample_bytree': 0.816550728636634, 'gamma': 1.6951489552435035, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:24:42,649] Trial 28 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 159, 'max_depth': 19, 'learning_rate': 0.08983777818386056, 'subsample': 0.8899377729288119, 'colsample_bytree': 0.8210158230771438, 'gamma': 0.42069982497524416, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:26:38,338] Trial 29 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 185, 'max_depth': 14, 'learning_rate': 0.010827734645496669, 'subsample': 0.5507357714330161, 'colsample_bytree': 0.8317508845540279, 'gamma': 0.025307919231093434, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:27:23,827] Trial 30 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 132, 'max_depth': 16, 'learning_rate': 0.06867651335523406, 'subsample': 0.61213465473028, 'colsample_bytree': 0.8560896106737679, 'gamma': 1.1862454374840004, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:28:09,842] Trial 31 finished with value: 0.9392499125618322 and parameters: {'n_estimators': 162, 'max_depth': 15, 'learning_rate': 0.08643010694447602, 'subsample': 0.8288064461501716, 'colsample_bytree': 0.7841543016677358, 'gamma': 0.4683738391404624, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:28:38,416] Trial 32 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.09757094992772011, 'subsample': 0.6965488623333802, 'colsample_bytree': 0.9460232775885566, 'gamma': 3.1556931299863145, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:29:33,544] Trial 33 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 125, 'max_depth': 14, 'learning_rate': 0.05432659244369776, 'subsample': 0.5976214938990223, 'colsample_bytree': 0.8612260576307527, 'gamma': 1.403861812204279, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:30:23,351] Trial 34 finished with value: 0.9392499125618322 and parameters: {'n_estimators': 147, 'max_depth': 7, 'learning_rate': 0.09464127259176229, 'subsample': 0.9769642885012937, 'colsample_bytree': 0.9574321951102243, 'gamma': 1.8507935012772219, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:31:21,187] Trial 35 finished with value: 0.9323562727766734 and parameters: {'n_estimators': 190, 'max_depth': 11, 'learning_rate': 0.09699893371393027, 'subsample': 0.9818099885446264, 'colsample_bytree': 0.92650472773368, 'gamma': 1.4722444603479286, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:32:33,665] Trial 36 finished with value: 0.9305430958323997 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.025254347201748326, 'subsample': 0.7784006312291751, 'colsample_bytree': 0.9680773870803905, 'gamma': 3.480148983374865, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:32:51,538] Trial 37 finished with value: 0.9181835223262776 and parameters: {'n_estimators': 64, 'max_depth': 14, 'learning_rate': 0.0991048465093837, 'subsample': 0.570042007618262, 'colsample_bytree': 0.7591648261818684, 'gamma': 4.386865359639777, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:33:39,692] Trial 38 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 155, 'max_depth': 16, 'learning_rate': 0.04235420360977797, 'subsample': 0.6467959221322467, 'colsample_bytree': 0.9046805777392568, 'gamma': 4.050566973395904, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:34:33,319] Trial 39 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 187, 'max_depth': 13, 'learning_rate': 0.05513646652184797, 'subsample': 0.8991475894833876, 'colsample_bytree': 0.8249819653888826, 'gamma': 3.509834386288517, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:35:35,719] Trial 40 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.04380246573759497, 'subsample': 0.5469909699204345, 'colsample_bytree': 0.789140070498087, 'gamma': 0.17971136898371043, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:36:10,612] Trial 41 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.06317499345121097, 'subsample': 0.5152501249695247, 'colsample_bytree': 0.5186740943746072, 'gamma': 4.113002803298292, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:36:48,969] Trial 42 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 69, 'max_depth': 13, 'learning_rate': 0.07929941977887497, 'subsample': 0.6079105137484215, 'colsample_bytree': 0.8114452379095001, 'gamma': 0.42673732496884, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:37:41,570] Trial 43 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 130, 'max_depth': 13, 'learning_rate': 0.06736869113483859, 'subsample': 0.8630456668613308, 'colsample_bytree': 0.9879260397312672, 'gamma': 2.5815017415059764, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:38:22,777] Trial 44 finished with value: 0.9285345806485132 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.04950742786350726, 'subsample': 0.5392281906711329, 'colsample_bytree': 0.5126753717077288, 'gamma': 4.813242073389626, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:39:18,839] Trial 45 finished with value: 0.9301788222413163 and parameters: {'n_estimators': 155, 'max_depth': 11, 'learning_rate': 0.02559648880637612, 'subsample': 0.5782185213355431, 'colsample_bytree': 0.6251214490822976, 'gamma': 2.7461333235306022, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:40:02,834] Trial 46 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 149, 'max_depth': 9, 'learning_rate': 0.09593787525968747, 'subsample': 0.8689484583478843, 'colsample_bytree': 0.7771770262557003, 'gamma': 3.058603731171761, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:40:42,694] Trial 47 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 87, 'max_depth': 10, 'learning_rate': 0.07820614994179323, 'subsample': 0.5071967443148779, 'colsample_bytree': 0.5580363202534582, 'gamma': 0.23001321010876374, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:41:38,532] Trial 48 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 179, 'max_depth': 16, 'learning_rate': 0.05267564461785927, 'subsample': 0.5489170803255008, 'colsample_bytree': 0.7458079375584161, 'gamma': 2.3673588539028283, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:42:13,157] Trial 49 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 115, 'max_depth': 11, 'learning_rate': 0.06542650882469948, 'subsample': 0.8175468254338218, 'colsample_bytree': 0.5226520048860223, 'gamma': 1.873063073132356, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:42:47,840] Trial 50 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 125, 'max_depth': 18, 'learning_rate': 0.06928242684570506, 'subsample': 0.5814672135407148, 'colsample_bytree': 0.5352843737002149, 'gamma': 3.212096391031578, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:43:29,827] Trial 51 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 138, 'max_depth': 20, 'learning_rate': 0.061792676008829116, 'subsample': 0.694084963103261, 'colsample_bytree': 0.8216441092211766, 'gamma': 2.2912644524575834, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:44:28,019] Trial 52 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 192, 'max_depth': 11, 'learning_rate': 0.09650715074415228, 'subsample': 0.9526753209780319, 'colsample_bytree': 0.5978955673946482, 'gamma': 0.3468065043758273, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:44:49,743] Trial 53 finished with value: 0.9102478506841161 and parameters: {'n_estimators': 52, 'max_depth': 6, 'learning_rate': 0.07147060960747212, 'subsample': 0.5355943242301144, 'colsample_bytree': 0.6594878151468806, 'gamma': 4.2243765548472725, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:46:01,001] Trial 54 finished with value: 0.9205989090063517 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.020634834485949063, 'subsample': 0.8483685826820753, 'colsample_bytree': 0.8144714233899419, 'gamma': 4.387360067635265, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:47:12,363] Trial 55 finished with value: 0.9205989090063517 and parameters: {'n_estimators': 171, 'max_depth': 9, 'learning_rate': 0.025969558940175053, 'subsample': 0.8753073758204292, 'colsample_bytree': 0.9034173696336321, 'gamma': 4.952525710003367, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:48:02,401] Trial 56 finished with value: 0.9296699993268674 and parameters: {'n_estimators': 106, 'max_depth': 17, 'learning_rate': 0.04067231862277161, 'subsample': 0.9653786628017824, 'colsample_bytree': 0.9292063759215059, 'gamma': 2.1449701368750915, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:48:41,762] Trial 57 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 163, 'max_depth': 6, 'learning_rate': 0.091229761601161, 'subsample': 0.7526261862239285, 'colsample_bytree': 0.9132287330538709, 'gamma': 1.6002480051530588, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:49:08,218] Trial 58 finished with value: 0.9285345806485132 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.09148437787773374, 'subsample': 0.5456433383930668, 'colsample_bytree': 0.6596568187952074, 'gamma': 4.750309835254025, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:49:46,192] Trial 59 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 136, 'max_depth': 15, 'learning_rate': 0.05036009697804879, 'subsample': 0.6466053858490323, 'colsample_bytree': 0.664332272684958, 'gamma': 3.362592280385192, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:50:48,617] Trial 60 finished with value: 0.9305430958323997 and parameters: {'n_estimators': 169, 'max_depth': 17, 'learning_rate': 0.018208549274382133, 'subsample': 0.7472101523512907, 'colsample_bytree': 0.5287793800083221, 'gamma': 2.7476444116186776, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:52:14,313] Trial 61 finished with value: 0.9401230090673645 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.02053603147848453, 'subsample': 0.5714958410264179, 'colsample_bytree': 0.8807553158587361, 'gamma': 3.0910903165813055, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:53:03,007] Trial 62 finished with value: 0.9131334876954631 and parameters: {'n_estimators': 62, 'max_depth': 16, 'learning_rate': 0.016548670572777417, 'subsample': 0.9109300296451781, 'colsample_bytree': 0.8531211135782482, 'gamma': 0.4067439032094988, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:54:04,126] Trial 63 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.04335779323602019, 'subsample': 0.9063997836287513, 'colsample_bytree': 0.9736242886919293, 'gamma': 4.930005319114354, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:54:36,332] Trial 64 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.07994322243346931, 'subsample': 0.7792021248679025, 'colsample_bytree': 0.7121110046234882, 'gamma': 4.53177192547368, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:55:13,620] Trial 65 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.05217945777947137, 'subsample': 0.5281516378409187, 'colsample_bytree': 0.559408958134036, 'gamma': 0.5876312338855244, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:55:53,290] Trial 66 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 162, 'max_depth': 14, 'learning_rate': 0.09659552936270878, 'subsample': 0.6874352897618521, 'colsample_bytree': 0.6428560431409304, 'gamma': 4.342995640947302, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:56:32,069] Trial 67 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.09728909440368752, 'subsample': 0.5215799559752881, 'colsample_bytree': 0.9455715568490355, 'gamma': 2.6385055454314994, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:56:54,639] Trial 68 finished with value: 0.9293057257357841 and parameters: {'n_estimators': 61, 'max_depth': 13, 'learning_rate': 0.09723722820571891, 'subsample': 0.7615489220850744, 'colsample_bytree': 0.8146993190676313, 'gamma': 3.4787434449230856, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:57:25,208] Trial 69 finished with value: 0.9181835223262776 and parameters: {'n_estimators': 144, 'max_depth': 14, 'learning_rate': 0.09110422094418902, 'subsample': 0.522723190170729, 'colsample_bytree': 0.6404815947961151, 'gamma': 4.752057420382794, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:58:14,756] Trial 70 finished with value: 0.9401230090673645 and parameters: {'n_estimators': 118, 'max_depth': 14, 'learning_rate': 0.034964306468301946, 'subsample': 0.5940605798618807, 'colsample_bytree': 0.7318492024699911, 'gamma': 1.766761140130264, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:58:37,015] Trial 71 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 61, 'max_depth': 20, 'learning_rate': 0.09875896700316426, 'subsample': 0.8490808570098726, 'colsample_bytree': 0.7680481831720603, 'gamma': 1.5476380814316388, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:59:21,103] Trial 72 finished with value: 0.9392499125618322 and parameters: {'n_estimators': 153, 'max_depth': 7, 'learning_rate': 0.09198344660444582, 'subsample': 0.9112686214615845, 'colsample_bytree': 0.974899956645962, 'gamma': 3.6285975419418, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 15:59:46,148] Trial 73 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 113, 'max_depth': 19, 'learning_rate': 0.08794575005503676, 'subsample': 0.5226093350530947, 'colsample_bytree': 0.5131834872486261, 'gamma': 1.8823168343902479, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:00:44,392] Trial 74 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 199, 'max_depth': 7, 'learning_rate': 0.06347176438169216, 'subsample': 0.6904454283155108, 'colsample_bytree': 0.9849571989073016, 'gamma': 4.210594615678543, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:01:25,375] Trial 75 finished with value: 0.9301788222413163 and parameters: {'n_estimators': 120, 'max_depth': 11, 'learning_rate': 0.034606636473763566, 'subsample': 0.5281877483254636, 'colsample_bytree': 0.9323611881275267, 'gamma': 4.064505045650388, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:02:28,357] Trial 76 finished with value: 0.9296699993268674 and parameters: {'n_estimators': 200, 'max_depth': 13, 'learning_rate': 0.07920886736624595, 'subsample': 0.9723828649412141, 'colsample_bytree': 0.9248236953387057, 'gamma': 1.2367405087159882, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:02:56,764] Trial 77 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 69, 'max_depth': 20, 'learning_rate': 0.06455571710057921, 'subsample': 0.6143214027517314, 'colsample_bytree': 0.8358503422029284, 'gamma': 3.090641202289479, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:03:24,920] Trial 78 finished with value: 0.9205989090063517 and parameters: {'n_estimators': 67, 'max_depth': 15, 'learning_rate': 0.056827693081341404, 'subsample': 0.8861591958678197, 'colsample_bytree': 0.7600817505559967, 'gamma': 4.2609075015927, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:03:59,620] Trial 79 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 134, 'max_depth': 19, 'learning_rate': 0.04631345795911574, 'subsample': 0.5670076142253204, 'colsample_bytree': 0.5143913381566695, 'gamma': 3.775686278368095, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:04:58,324] Trial 80 finished with value: 0.9301788222413163 and parameters: {'n_estimators': 156, 'max_depth': 8, 'learning_rate': 0.02227343280280928, 'subsample': 0.507272332833941, 'colsample_bytree': 0.6752937794032985, 'gamma': 2.9495884342731653, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:05:48,822] Trial 81 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 116, 'max_depth': 19, 'learning_rate': 0.041342992032097035, 'subsample': 0.7569947445799055, 'colsample_bytree': 0.8918265063705715, 'gamma': 1.9827139116063508, 'min_child_weight': 4}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:07:14,572] Trial 82 finished with value: 0.9296699993268674 and parameters: {'n_estimators': 180, 'max_depth': 20, 'learning_rate': 0.023236613283613414, 'subsample': 0.9632938125807472, 'colsample_bytree': 0.7460581465397691, 'gamma': 1.2912219414947916, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:08:37,107] Trial 83 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 197, 'max_depth': 12, 'learning_rate': 0.03958764492587574, 'subsample': 0.8167004271583629, 'colsample_bytree': 0.6200728093890966, 'gamma': 0.3793166405433196, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:09:04,704] Trial 84 finished with value: 0.9324150289196098 and parameters: {'n_estimators': 69, 'max_depth': 7, 'learning_rate': 0.022494445538446914, 'subsample': 0.8204373724016073, 'colsample_bytree': 0.5909400421995724, 'gamma': 1.728336416619316, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:09:54,848] Trial 85 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 121, 'max_depth': 15, 'learning_rate': 0.025508788408146688, 'subsample': 0.5961445094043354, 'colsample_bytree': 0.5204343081332394, 'gamma': 0.8446753153608227, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:10:30,819] Trial 86 finished with value: 0.922835115684645 and parameters: {'n_estimators': 76, 'max_depth': 6, 'learning_rate': 0.020857228399054073, 'subsample': 0.7303893840163629, 'colsample_bytree': 0.6031668592028963, 'gamma': 1.8213493052403773, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:11:10,305] Trial 87 finished with value: 0.9388856389707488 and parameters: {'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.08194693590181384, 'subsample': 0.8139501947454539, 'colsample_bytree': 0.540879515974436, 'gamma': 4.3678931205338865, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:11:35,951] Trial 88 finished with value: 0.9296699993268674 and parameters: {'n_estimators': 59, 'max_depth': 9, 'learning_rate': 0.08255811518137553, 'subsample': 0.8741298451918291, 'colsample_bytree': 0.5922605096781887, 'gamma': 1.0467466166835515, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:12:38,735] Trial 89 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 123, 'max_depth': 14, 'learning_rate': 0.043202227561279526, 'subsample': 0.731267358066574, 'colsample_bytree': 0.8737354690668783, 'gamma': 0.1834160144529895, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:13:23,618] Trial 90 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 157, 'max_depth': 19, 'learning_rate': 0.05605096979040996, 'subsample': 0.7660567426326579, 'colsample_bytree': 0.553586005669888, 'gamma': 2.237061834117273, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:14:01,523] Trial 91 finished with value: 0.9301788222413163 and parameters: {'n_estimators': 86, 'max_depth': 9, 'learning_rate': 0.04395557467941604, 'subsample': 0.5100355988888632, 'colsample_bytree': 0.6610395827915891, 'gamma': 1.0572400349827231, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:14:35,142] Trial 92 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 68, 'max_depth': 19, 'learning_rate': 0.06342332081986439, 'subsample': 0.8395511595722448, 'colsample_bytree': 0.8945856193036692, 'gamma': 2.492210994645286, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:15:14,196] Trial 93 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 131, 'max_depth': 14, 'learning_rate': 0.0770895526765897, 'subsample': 0.7158297731148398, 'colsample_bytree': 0.5637901513977819, 'gamma': 1.4188795289936222, 'min_child_weight': 2}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:16:24,286] Trial 94 finished with value: 0.920650467909433 and parameters: {'n_estimators': 147, 'max_depth': 14, 'learning_rate': 0.042048705330806166, 'subsample': 0.9932576243964899, 'colsample_bytree': 0.8028874096784435, 'gamma': 1.1861339586799724, 'min_child_weight': 1}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:16:52,680] Trial 95 finished with value: 0.9401230090673645 and parameters: {'n_estimators': 73, 'max_depth': 8, 'learning_rate': 0.024461323593360014, 'subsample': 0.5932835120256529, 'colsample_bytree': 0.6425475843469235, 'gamma': 0.8668679764737741, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:17:17,482] Trial 96 finished with value: 0.9392499125618322 and parameters: {'n_estimators': 62, 'max_depth': 13, 'learning_rate': 0.04693571442906954, 'subsample': 0.9911893084543032, 'colsample_bytree': 0.5560194510840262, 'gamma': 1.9892779952287083, 'min_child_weight': 5}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:18:17,101] Trial 97 finished with value: 0.9285345806485132 and parameters: {'n_estimators': 180, 'max_depth': 18, 'learning_rate': 0.03321125443404459, 'subsample': 0.585443793695033, 'colsample_bytree': 0.8343216099622155, 'gamma': 4.646879945637929, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:18:52,353] Trial 98 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 136, 'max_depth': 9, 'learning_rate': 0.07925436398727433, 'subsample': 0.5935218742787617, 'colsample_bytree': 0.6618396182021218, 'gamma': 2.127182193082084, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n",
            "[I 2023-06-23 16:19:27,384] Trial 99 finished with value: 0.9488298257967969 and parameters: {'n_estimators': 86, 'max_depth': 6, 'learning_rate': 0.06495580381974694, 'subsample': 0.6443152766201279, 'colsample_bytree': 0.7906191107113061, 'gamma': 0.7718135763710116, 'min_child_weight': 3}. Best is trial 0 with value: 0.9488298257967969.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "e5s3B_cnaOEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4c5c5c-0921-43d6-e415-ad0589df8974",
        "id": "AYJGZwO3aOEq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 106,\n",
              " 'max_depth': 20,\n",
              " 'learning_rate': 0.07587945476302646,\n",
              " 'subsample': 0.7993292420985183,\n",
              " 'colsample_bytree': 0.5780093202212182,\n",
              " 'gamma': 0.7799726016810132,\n",
              " 'min_child_weight': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "2ZQ3O6GiaOEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features]"
      ],
      "metadata": {
        "id": "TqRM9iqhaOEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f3f933-fa09-433e-8d73-05e72d00540c",
        "id": "g7oLC5h8aOEq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features]"
      ],
      "metadata": {
        "id": "tef0Yt7RaOEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539d731e-a93b-4de5-dd1b-0f5340e9289d",
        "id": "2MdcUO69aOEq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1141, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_XG = XGBClassifier(**best_params)"
      ],
      "metadata": {
        "id": "aNluHqIIaOEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_XG.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "d59af43c-eca7-4850-b032-f7ff125f8d0f",
        "id": "1MxRSL9XaOEr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.5780093202212182, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.7799726016810132, gpu_id=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.07587945476302646, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=106, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.5780093202212182, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.7799726016810132, gpu_id=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.07587945476302646, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=106, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.5780093202212182, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.7799726016810132, gpu_id=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.07587945476302646, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=106, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_XG.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "sM0ugLiaaOEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "HDq01F_WaOEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "3IWlf0dH55Ny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "fQUYqDn3aThs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5\n",
        "#n_folds_features = 2"
      ],
      "metadata": {
        "id": "0TaEpHKZaTht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_feature_selection(X_train_val, y_train_val):\n",
        "    X_train_features, X_hyperparam_opt, y_train_features, y_hyperparam_opt = train_test_split(X_train_val, y_train_val, train_size=0.30, random_state=42)\n",
        "    # Perform feature selection on X_train_val\n",
        "    X_train_val_df = pd.DataFrame(X_train_features)\n",
        "    y_train_val_df = pd.DataFrame(y_train_features)\n",
        "    X_hyperparam_opt = pd.DataFrame(X_hyperparam_opt)\n",
        "    y_hyperparam_opt = pd.DataFrame(y_hyperparam_opt)\n",
        "    selected_features = mrmr_classif(X_train_val_df, y_train_val_df, K=300)\n",
        "    X_train_val_selected = X_hyperparam_opt.loc[:, selected_features] # filter the dataset for hyperparameters tunning according to the selected features\n",
        "\n",
        "    return X_train_val_selected, y_hyperparam_opt,selected_features"
      ],
      "metadata": {
        "id": "1eR7pqIXaTht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_LR(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features):\n",
        "\n",
        "  params = {\n",
        "              'tol' : trial.suggest_float('tol' , 1e-6 , 1e-3),\n",
        "              'C' : trial.suggest_float(\"C\", 1e-5, 100),\n",
        "              \"n_jobs\" : -1,\n",
        "              'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
        "          }\n",
        "\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  #classifier = XGBClassifier(eta=eta,gamma=gamma ,min_child_weight=min_child_weight,max_delta_step=max_delta_step,subsample=subsample)\n",
        "  classifier = LogisticRegression(**params)\n",
        "\n",
        "  # Perform cross-validation on the selected features\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "\n",
        "  for train_index, val_index in kf.split(X_hyperparam_opt, y_hyperparam_opt):\n",
        "      #X_train, X_val = X_hyperparam_opt[train_index], X_hyperparam_opt[val_index]\n",
        "      #y_train, y_val = y_hyperparam_opt[train_index], y_hyperparam_opt[val_index]\n",
        "      X_train, X_val = X_hyperparam_opt.iloc[train_index], X_hyperparam_opt.iloc[val_index]\n",
        "      y_train, y_val = y_hyperparam_opt.iloc[train_index], y_hyperparam_opt.iloc[val_index]\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train, y_train)\n",
        "      y_pred = classifier.predict(X_val)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "2CnNVAhZaTht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature selection\n",
        "X_hyperparam_opt, y_hyperparam_opt,selected_features = perform_feature_selection(X_train_val, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae270a71-fd59-40f9-ebe5-de80958ebf4f",
        "id": "udwQC2_AaTht"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:21<00:00,  1.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function with selected features\n",
        "def objective(trial):\n",
        "    return objective_LR(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features)"
      ],
      "metadata": {
        "id": "n-numCr5aThu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537ab3a6-3c8a-4a3a-d189-a8628917c452",
        "id": "aotM8xj5aThu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 14:45:08,003] A new study created in memory with name: no-name-078e3a57-be4b-4e05-81a4-0622646491e9\n",
            "[I 2023-06-23 14:45:10,723] Trial 0 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0003751655787285152, 'C': 95.07143113384855, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:45:13,481] Trial 1 finished with value: 0.5057760313622911 and parameters: {'tol': 0.0008663099696291604, 'C': 60.11150516317076, 'solver': 'liblinear'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:45:21,986] Trial 2 finished with value: 0.4804327086352961 and parameters: {'tol': 0.00018264314223989352, 'C': 18.340459151298283, 'solver': 'saga'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:45:24,899] Trial 3 finished with value: 0.4983549388463773 and parameters: {'tol': 0.0001403543667913898, 'C': 29.21447193207533, 'solver': 'liblinear'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:45:33,343] Trial 4 finished with value: 0.4807588554225517 and parameters: {'tol': 0.0005928221542931806, 'C': 4.645050807495645, 'solver': 'saga'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:45:39,156] Trial 5 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0008085889507683448, 'C': 30.461383871199377, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:45:45,244] Trial 6 finished with value: 0.8668486306868823 and parameters: {'tol': 3.535413259410318e-05, 'C': 90.93204111467419, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:45:51,137] Trial 7 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00018566960107000154, 'C': 96.95846308060958, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:45:59,582] Trial 8 finished with value: 0.48227494168797963 and parameters: {'tol': 8.940400954986758e-05, 'C': 19.598294282085895, 'solver': 'saga'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:06,721] Trial 9 finished with value: 0.48273108515877566 and parameters: {'tol': 0.00035739657336689574, 'C': 28.093458159392977, 'solver': 'saga'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:12,731] Trial 10 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0007724725245273608, 'C': 19.871576166260425, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:18,617] Trial 11 finished with value: 0.8668486306868823 and parameters: {'tol': 7.497060708235628e-05, 'C': 35.846579269769975, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:22,187] Trial 12 finished with value: 0.4983549388463773 and parameters: {'tol': 0.0003116713393939466, 'C': 32.51833895084149, 'solver': 'liblinear'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:28,105] Trial 13 finished with value: 0.8551377489620082 and parameters: {'tol': 0.0007135315424357721, 'C': 76.07850725383926, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:36,582] Trial 14 finished with value: 0.4803669783770947 and parameters: {'tol': 2.6393707617351097e-05, 'C': 10.789151620416174, 'solver': 'saga'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:39,203] Trial 15 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0002500429369197261, 'C': 41.038298199733745, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:46,319] Trial 16 finished with value: 0.48372529769520617 and parameters: {'tol': 0.0009297679546902306, 'C': 80.8120398752379, 'solver': 'saga'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:49,254] Trial 17 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0005398028996737352, 'C': 80.7440174420047, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.8668486306868823.\n",
            "[I 2023-06-23 14:46:55,140] Trial 18 finished with value: 0.8776843640708254 and parameters: {'tol': 0.0008181967511565707, 'C': 86.07305971832851, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:03,667] Trial 19 finished with value: 0.4818830646425226 and parameters: {'tol': 0.0003382775562322244, 'C': 94.29097096215487, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:10,791] Trial 20 finished with value: 0.48372529769520617 and parameters: {'tol': 0.0009624848476471692, 'C': 25.178237064713457, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:16,772] Trial 21 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0005031763442056327, 'C': 5.147884610211422, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:22,644] Trial 22 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0009856648036564901, 'C': 24.205534730597325, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:25,232] Trial 23 finished with value: 0.503620488801162 and parameters: {'tol': 0.000632673524762986, 'C': 63.35297474079236, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:28,681] Trial 24 finished with value: 0.8668486306868823 and parameters: {'tol': 4.173436641320915e-05, 'C': 59.08929840989475, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:34,606] Trial 25 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00017519206257598648, 'C': 69.09377690086922, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:37,181] Trial 26 finished with value: 0.5030788412250532 and parameters: {'tol': 0.0009247689246602843, 'C': 87.73393656470456, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:43,253] Trial 27 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00024261043860955125, 'C': 9.310285849562243, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:45,596] Trial 28 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0007262297231913692, 'C': 89.71102702415511, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:48,043] Trial 29 finished with value: 0.5057760313622911 and parameters: {'tol': 0.0008986556343385523, 'C': 60.642909901668396, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:50,674] Trial 30 finished with value: 0.503620488801162 and parameters: {'tol': 0.0005491850555772196, 'C': 69.18952285031735, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:53,762] Trial 31 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0007467449137129063, 'C': 64.96329340839247, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:56,900] Trial 32 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00026593716531404376, 'C': 24.398971898011922, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:47:59,336] Trial 33 finished with value: 0.5057760313622911 and parameters: {'tol': 0.000503134456012087, 'C': 57.69039269359707, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:05,177] Trial 34 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0006458268236112607, 'C': 17.711076169598098, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:08,263] Trial 35 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0009283902440251377, 'C': 42.81842054988995, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:11,103] Trial 36 finished with value: 0.5030270637508341 and parameters: {'tol': 0.0008512855348453401, 'C': 31.692207346407713, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:13,831] Trial 37 finished with value: 0.8668486306868823 and parameters: {'tol': 9.807931727699777e-05, 'C': 61.50072651984471, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:22,358] Trial 38 finished with value: 0.4803669783770947 and parameters: {'tol': 0.0006973187252542728, 'C': 70.24841137387008, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:28,188] Trial 39 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0009133273120039149, 'C': 51.134244772669796, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:30,751] Trial 40 finished with value: 0.5030270637508341 and parameters: {'tol': 0.0008901153364757489, 'C': 33.79952230520201, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:38,832] Trial 41 finished with value: 0.4888124495174829 and parameters: {'tol': 0.0005431019900728691, 'C': 28.654132347415917, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:41,467] Trial 42 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0001279334521392329, 'C': 52.22433078304784, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:43,956] Trial 43 finished with value: 0.5057760313622911 and parameters: {'tol': 0.00053182327693658, 'C': 54.06351675465944, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:52,050] Trial 44 finished with value: 0.494898767349639 and parameters: {'tol': 0.0007953910085739351, 'C': 27.083232417884908, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:48:59,751] Trial 45 finished with value: 0.48227494168797963 and parameters: {'tol': 0.0006962782318876043, 'C': 40.895300351897546, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:02,908] Trial 46 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0006605371793410136, 'C': 27.993396895255312, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:05,744] Trial 47 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00024848325851165634, 'C': 35.597274305399374, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:08,284] Trial 48 finished with value: 0.500923298663924 and parameters: {'tol': 0.0008556051234269963, 'C': 70.36578890142377, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:14,316] Trial 49 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0004344177975887351, 'C': 39.85047945469, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:16,938] Trial 50 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0005036331223215077, 'C': 85.64898555393381, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:19,323] Trial 51 finished with value: 0.5048013483183447 and parameters: {'tol': 0.0005861898056921899, 'C': 94.02302474019335, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:21,719] Trial 52 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0009415233439677488, 'C': 38.61026991905105, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:29,868] Trial 53 finished with value: 0.49085804074276745 and parameters: {'tol': 1.920360382589818e-05, 'C': 9.444305131163231, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:36,668] Trial 54 finished with value: 0.49130457624218044 and parameters: {'tol': 0.000814654014106347, 'C': 28.185484658792245, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:44,763] Trial 55 finished with value: 0.488075994647905 and parameters: {'tol': 0.0008036774494544638, 'C': 28.203464436784923, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:50,631] Trial 56 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00037264606770699043, 'C': 77.64129831007008, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:49:53,610] Trial 57 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0007547883312105977, 'C': 10.312395852354571, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:01,148] Trial 58 finished with value: 0.48372529769520617 and parameters: {'tol': 0.00038981247705542903, 'C': 1.0837750396533212, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:09,702] Trial 59 finished with value: 0.48841781784693145 and parameters: {'tol': 0.000573864450235163, 'C': 63.18372489860781, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:16,428] Trial 60 finished with value: 0.49130457624218044 and parameters: {'tol': 0.0007917874646821228, 'C': 78.96181638327396, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:19,197] Trial 61 finished with value: 0.5030270637508341 and parameters: {'tol': 0.0008878164785755415, 'C': 35.091507746057744, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:25,220] Trial 62 finished with value: 0.8668486306868823 and parameters: {'tol': 8.502269930888245e-05, 'C': 70.09691613622068, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:32,680] Trial 63 finished with value: 0.49674100040232255 and parameters: {'tol': 0.0009866529389226744, 'C': 37.427085832904076, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:40,091] Trial 64 finished with value: 0.4856320579517246 and parameters: {'tol': 0.0003768833259453849, 'C': 8.350080834859709, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:48,565] Trial 65 finished with value: 0.4812331709705088 and parameters: {'tol': 0.0004931324791865683, 'C': 1.1353743632054591, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:51,081] Trial 66 finished with value: 0.8668486306868823 and parameters: {'tol': 0.000746298834386158, 'C': 58.336880676028315, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:50:58,351] Trial 67 finished with value: 0.48121499889334773 and parameters: {'tol': 0.0009632593169011708, 'C': 1.2154573474368873, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:01,578] Trial 68 finished with value: 0.8668486306868823 and parameters: {'tol': 7.472276817066347e-05, 'C': 55.38543290158923, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:08,329] Trial 69 finished with value: 0.4913281147905321 and parameters: {'tol': 0.0006279305220039795, 'C': 58.431435349166904, 'solver': 'sag'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:16,821] Trial 70 finished with value: 0.48273108515877566 and parameters: {'tol': 0.0004562010960329273, 'C': 62.0132635788277, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:19,473] Trial 71 finished with value: 0.8668486306868823 and parameters: {'tol': 7.865690232801985e-05, 'C': 97.43948102266857, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:22,162] Trial 72 finished with value: 0.4983549388463773 and parameters: {'tol': 0.0006850464413813255, 'C': 16.261702308319734, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:24,770] Trial 73 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0004188247932543283, 'C': 93.2728490081165, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:28,382] Trial 74 finished with value: 0.5010521289836152 and parameters: {'tol': 0.0009872888531856296, 'C': 15.041697606183906, 'solver': 'liblinear'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:35,510] Trial 75 finished with value: 0.4837071256180452 and parameters: {'tol': 0.0004692244666351754, 'C': 41.4819560855715, 'solver': 'saga'}. Best is trial 18 with value: 0.8776843640708254.\n",
            "[I 2023-06-23 14:51:41,476] Trial 76 finished with value: 0.8782377771941675 and parameters: {'tol': 0.0009966402002368315, 'C': 55.54317500594569, 'solver': 'lbfgs'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:51:44,711] Trial 77 finished with value: 0.5010521289836152 and parameters: {'tol': 0.0001300302557363435, 'C': 95.40510318536197, 'solver': 'liblinear'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:51:51,960] Trial 78 finished with value: 0.4890380236880791 and parameters: {'tol': 0.00011444403460742941, 'C': 67.157322843548, 'solver': 'sag'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:51:59,580] Trial 79 finished with value: 0.49674100040232255 and parameters: {'tol': 0.000561377033563851, 'C': 87.66536149929847, 'solver': 'sag'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:07,534] Trial 80 finished with value: 0.4949209833476342 and parameters: {'tol': 0.0007043756883311244, 'C': 21.296424021249457, 'solver': 'sag'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:10,575] Trial 81 finished with value: 0.5003298736135962 and parameters: {'tol': 0.0004380374471017054, 'C': 90.41587040778789, 'solver': 'liblinear'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:16,402] Trial 82 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0008625013450379985, 'C': 94.95206287055798, 'solver': 'lbfgs'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:22,415] Trial 83 finished with value: 0.8782377771941675 and parameters: {'tol': 0.0009800525427101916, 'C': 49.26181447310602, 'solver': 'lbfgs'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:30,581] Trial 84 finished with value: 0.48372529769520617 and parameters: {'tol': 0.00012891779311881467, 'C': 15.190277832202499, 'solver': 'saga'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:39,558] Trial 85 finished with value: 0.4818830646425226 and parameters: {'tol': 0.00047448767862260955, 'C': 66.75577717652533, 'solver': 'saga'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:47,609] Trial 86 finished with value: 0.4812331709705088 and parameters: {'tol': 0.0001778334737924701, 'C': 8.870262488680224, 'solver': 'saga'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:55,129] Trial 87 finished with value: 0.48220921142977824 and parameters: {'tol': 0.000690704433800736, 'C': 3.931223590988495, 'solver': 'saga'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:52:57,970] Trial 88 finished with value: 0.8668486306868823 and parameters: {'tol': 6.20168818950089e-05, 'C': 27.68777204594389, 'solver': 'newton-cg'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:00,941] Trial 89 finished with value: 0.503620488801162 and parameters: {'tol': 0.0004850384622058304, 'C': 61.825480970481884, 'solver': 'liblinear'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:08,647] Trial 90 finished with value: 0.48679225912888596 and parameters: {'tol': 0.0007136362362986679, 'C': 89.52068481665155, 'solver': 'saga'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:11,250] Trial 91 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00024322803313109496, 'C': 26.924330402505785, 'solver': 'newton-cg'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:15,332] Trial 92 finished with value: 0.5010521289836152 and parameters: {'tol': 0.00012064236968743198, 'C': 89.0527291687167, 'solver': 'liblinear'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:18,177] Trial 93 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0005375694352767293, 'C': 58.684115933676736, 'solver': 'newton-cg'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:23,979] Trial 94 finished with value: 0.8668486306868823 and parameters: {'tol': 0.0006462713240902697, 'C': 57.07783475910814, 'solver': 'lbfgs'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:32,481] Trial 95 finished with value: 0.4808888521060921 and parameters: {'tol': 0.0001537062800451477, 'C': 24.595780378873528, 'solver': 'saga'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:38,392] Trial 96 finished with value: 0.8668486306868823 and parameters: {'tol': 8.115351191598057e-05, 'C': 52.45114371191157, 'solver': 'lbfgs'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:46,444] Trial 97 finished with value: 0.49307875029495063 and parameters: {'tol': 0.0008656416187680864, 'C': 81.70720892420728, 'solver': 'sag'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:49,000] Trial 98 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00057204107678043, 'C': 27.99791656623748, 'solver': 'newton-cg'}. Best is trial 76 with value: 0.8782377771941675.\n",
            "[I 2023-06-23 14:53:51,586] Trial 99 finished with value: 0.8668486306868823 and parameters: {'tol': 0.00024316732268266517, 'C': 11.483691325552105, 'solver': 'newton-cg'}. Best is trial 76 with value: 0.8782377771941675.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqjFVm1PaThu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "G2H4C_VoaThu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params #42 random seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28e66f8-b34f-4b22-8179-1542c16f6011",
        "id": "fxMqxtMaaThu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tol': 0.0009966402002368315, 'C': 55.54317500594569, 'solver': 'lbfgs'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "7yC2_9qgaThu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features]"
      ],
      "metadata": {
        "id": "5EX5BimeaThv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f3f933-fa09-433e-8d73-05e72d00540c",
        "id": "d-OE4kgDaThv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features]"
      ],
      "metadata": {
        "id": "srmaD_7AaThv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539d731e-a93b-4de5-dd1b-0f5340e9289d",
        "id": "uS7bPOP-aThv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1141, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_classifier_LR = LogisticRegression(**best_params)"
      ],
      "metadata": {
        "id": "A_I2hFp7aThv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_LR.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4284ebfb-c8b6-44ec-ede0-97b9287597b0",
        "id": "fMr5jIc7aThv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=55.54317500594569, tol=0.0009966402002368315)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=55.54317500594569, tol=0.0009966402002368315)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=55.54317500594569, tol=0.0009966402002368315)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_LR.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "S5oCv7O9aThw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "y3h21PfJaThw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GaussianNB\n"
      ],
      "metadata": {
        "id": "NBfVfw6I55N4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross val for hyperparameter tunning and feature selection"
      ],
      "metadata": {
        "id": "b01LXgpDaZHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of folds for cross-validation\n",
        "n_folds = 5"
      ],
      "metadata": {
        "id": "o2PFa_i3aZHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_feature_selection(X_train_val, y_train_val):\n",
        "    X_train_features, X_hyperparam_opt, y_train_features, y_hyperparam_opt = train_test_split(X_train_val, y_train_val, train_size=0.30, random_state=42)\n",
        "    # Perform feature selection on X_train_val\n",
        "    X_train_val_df = pd.DataFrame(X_train_features)\n",
        "    y_train_val_df = pd.DataFrame(y_train_features)\n",
        "    X_hyperparam_opt = pd.DataFrame(X_hyperparam_opt)\n",
        "    y_hyperparam_opt = pd.DataFrame(y_hyperparam_opt)\n",
        "    selected_features = mrmr_classif(X_train_val_df, y_train_val_df, K=300)\n",
        "    X_train_val_selected = X_hyperparam_opt.loc[:, selected_features] # filter the dataset for hyperparameters tunning according to the selected features\n",
        "\n",
        "    return X_train_val_selected, y_hyperparam_opt,selected_features"
      ],
      "metadata": {
        "id": "sklN2Nm3aZHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_GNB(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features):\n",
        "\n",
        "  params = {\n",
        "            'var_smoothing': trial.suggest_float('var_smoothing', 1e-10, 1e-3, log=True)\n",
        "          }\n",
        "\n",
        "  # Instantiate the classifier with the current hyperparameters\n",
        "  #classifier = XGBClassifier(eta=eta,gamma=gamma ,min_child_weight=min_child_weight,max_delta_step=max_delta_step,subsample=subsample)\n",
        "  classifier = GaussianNB(**params)\n",
        "\n",
        "  # Perform cross-validation on the selected features\n",
        "  kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "  cv_scores = []\n",
        "\n",
        "  for train_index, val_index in kf.split(X_hyperparam_opt, y_hyperparam_opt):\n",
        "      #X_train, X_val = X_hyperparam_opt[train_index], X_hyperparam_opt[val_index]\n",
        "      #y_train, y_val = y_hyperparam_opt[train_index], y_hyperparam_opt[val_index]\n",
        "      X_train, X_val = X_hyperparam_opt.iloc[train_index], X_hyperparam_opt.iloc[val_index]\n",
        "      y_train, y_val = y_hyperparam_opt.iloc[train_index], y_hyperparam_opt.iloc[val_index]\n",
        "      # Fit the classifier on the selected features and evaluate on the validation set\n",
        "      classifier.fit(X_train, y_train)\n",
        "      y_pred = classifier.predict(X_val)\n",
        "      mcc = matthews_corrcoef(y_val, y_pred)\n",
        "      cv_scores.append(mcc)\n",
        "  # Calculate the average MCC\n",
        "  avg_mcc = np.mean(cv_scores)\n",
        "\n",
        "  return avg_mcc"
      ],
      "metadata": {
        "id": "dPg3nPfvaZHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature selection\n",
        "X_hyperparam_opt, y_hyperparam_opt,selected_features = perform_feature_selection(X_train_val, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f733c1-83a4-40ee-91cc-90ff0e8e7c8d",
        "id": "zWTTvaXiaZHU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:20<00:00,  1.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function with selected features\n",
        "def objective(trial):\n",
        "    return objective_GNB(trial, X_hyperparam_opt, y_hyperparam_opt,selected_features)"
      ],
      "metadata": {
        "id": "J30AIYoUaZHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(seed=42))\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3a165d-6637-49a5-a611-81220eef9330",
        "id": "9lrQ1Q7laZHU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-23 14:58:13,783] A new study created in memory with name: no-name-a5a2727e-7ae5-41bf-9cd2-fbdef4eaea93\n",
            "[I 2023-06-23 14:58:14,001] Trial 0 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 4.185822729546966e-08}. Best is trial 0 with value: 0.48788674353486067.\n",
            "[I 2023-06-23 14:58:14,217] Trial 1 finished with value: 0.5523622794189398 and parameters: {'var_smoothing': 0.0004518560951024107}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:14,433] Trial 2 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.3303245101522907e-05}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:14,652] Trial 3 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.5509913987594307e-06}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:14,863] Trial 4 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.2363188277052218e-09}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:15,078] Trial 5 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.2358382772306896e-09}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:15,300] Trial 6 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.5502648504032847e-10}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:15,536] Trial 7 finished with value: 0.5219086128421979 and parameters: {'var_smoothing': 0.00011567327199145979}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:15,781] Trial 8 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.6136341713591319e-06}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:16,017] Trial 9 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 9.047071957568391e-06}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:16,272] Trial 10 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.3934502251337584e-10}. Best is trial 1 with value: 0.5523622794189398.\n",
            "[I 2023-06-23 14:58:16,497] Trial 11 finished with value: 0.578078563116497 and parameters: {'var_smoothing': 0.00061569973282352}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:16,723] Trial 12 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 6.715811311069945e-05}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:16,939] Trial 13 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 3.064599841241147e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:17,154] Trial 14 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.874022368883631e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:17,374] Trial 15 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.922346047064363e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:17,620] Trial 16 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.3480180290890788e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:17,873] Trial 17 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 4.7129737561107815e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:18,117] Trial 18 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.0558813779064848e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:18,366] Trial 19 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.0929592787219375e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:18,607] Trial 20 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.9185373703841914e-06}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:18,861] Trial 21 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 9.472334467618544e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:19,102] Trial 22 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.1092068418536174e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:19,338] Trial 23 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 3.6688748954991754e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:19,592] Trial 24 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.5577217702693015e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:19,832] Trial 25 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 3.134958021096909e-05}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:20,074] Trial 26 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.4987135684669447e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:20,316] Trial 27 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 3.97778283081119e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:20,558] Trial 28 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.402497132660036e-06}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:20,813] Trial 29 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.1142332035497139e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:21,123] Trial 30 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.7898389848671593e-06}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:21,480] Trial 31 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.5619562520792733e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:21,820] Trial 32 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.853390105240223e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:22,143] Trial 33 finished with value: 0.5380254817386424 and parameters: {'var_smoothing': 0.0004387314432435404}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:22,489] Trial 34 finished with value: 0.578078563116497 and parameters: {'var_smoothing': 0.0005746775499181862}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:22,864] Trial 35 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 4.55807468402733e-05}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:23,240] Trial 36 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.3561145768453489e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:23,617] Trial 37 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 4.827305651975699e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:23,983] Trial 38 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 6.1607159527745434e-06}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:24,340] Trial 39 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.20522312541456e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:24,593] Trial 40 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 7.149367864959178e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:25,154] Trial 41 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.9257577949824413e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:25,423] Trial 42 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.740682839312808e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:25,628] Trial 43 finished with value: 0.5380254817386424 and parameters: {'var_smoothing': 0.0002318690670290197}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:25,833] Trial 44 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 6.478282331897327e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:26,046] Trial 45 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 4.341661800361736e-06}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:26,261] Trial 46 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.520468869219889e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:26,475] Trial 47 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 4.369946783595579e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:26,677] Trial 48 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 6.713854967599219e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:26,884] Trial 49 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.9678010532114953e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:27,111] Trial 50 finished with value: 0.578078563116497 and parameters: {'var_smoothing': 0.0006124806805925976}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:27,320] Trial 51 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.666427400467686e-05}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:27,541] Trial 52 finished with value: 0.5380254817386424 and parameters: {'var_smoothing': 0.00037713131110779903}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:27,752] Trial 53 finished with value: 0.5380254817386424 and parameters: {'var_smoothing': 0.0001835656654435508}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:27,963] Trial 54 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.5321449415450716e-06}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:28,190] Trial 55 finished with value: 0.5380254817386424 and parameters: {'var_smoothing': 0.0002838700963443627}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:28,407] Trial 56 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 4.163394022669372e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:28,620] Trial 57 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.3543988498504872e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:28,832] Trial 58 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.0729604791291157e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:29,051] Trial 59 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.893704954163126e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:29,264] Trial 60 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 5.2570369292136696e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:29,475] Trial 61 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 7.933105363733031e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:29,677] Trial 62 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 6.326486185661583e-05}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:29,886] Trial 63 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 3.142485531883158e-08}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:30,098] Trial 64 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 9.258519973443778e-09}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:30,312] Trial 65 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 6.293215187893864e-07}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:30,520] Trial 66 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 9.693253593230319e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:30,725] Trial 67 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 4.1245717727594184e-05}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:30,943] Trial 68 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 3.325481267274218e-10}. Best is trial 11 with value: 0.578078563116497.\n",
            "[I 2023-06-23 14:58:31,161] Trial 69 finished with value: 0.608532229693239 and parameters: {'var_smoothing': 0.0008094845352286139}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:31,370] Trial 70 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.545150013091292e-05}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:31,580] Trial 71 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.460422958018417e-09}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:31,822] Trial 72 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.0930872279404526e-10}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:32,099] Trial 73 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 5.107754312955834e-05}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:32,361] Trial 74 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 8.871588860587616e-06}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:32,609] Trial 75 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.267798332692875e-05}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:32,819] Trial 76 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.5054885755573557e-05}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:33,028] Trial 77 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 3.298470179752563e-10}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:33,254] Trial 78 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 3.2304282522409615e-08}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:33,462] Trial 79 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 6.472669269538624e-10}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:33,680] Trial 80 finished with value: 0.5219086128421979 and parameters: {'var_smoothing': 0.0001100839441018131}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:33,933] Trial 81 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.3072087378099e-06}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:34,197] Trial 82 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.0715058970816234e-08}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:34,445] Trial 83 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 2.785533924389101e-10}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:34,781] Trial 84 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.5027137214154533e-08}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:35,115] Trial 85 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.889223130553437e-08}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:35,443] Trial 86 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 1.2800980864220754e-05}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:35,758] Trial 87 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.9033694281285623e-06}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:36,097] Trial 88 finished with value: 0.5380254817386424 and parameters: {'var_smoothing': 0.00016236379661338317}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:36,425] Trial 89 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.0207122587167362e-07}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:36,762] Trial 90 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 6.873211713642716e-10}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:37,086] Trial 91 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 9.833622008382918e-06}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:37,414] Trial 92 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.1159009829538346e-05}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:37,734] Trial 93 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 8.490639132761158e-07}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:38,038] Trial 94 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.4932754437140142e-05}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:38,249] Trial 95 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 2.861338079089885e-07}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:38,471] Trial 96 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 4.5617324056306345e-07}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:38,677] Trial 97 finished with value: 0.5068216787033559 and parameters: {'var_smoothing': 9.835289062589968e-08}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:38,880] Trial 98 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 1.5063777323554432e-10}. Best is trial 69 with value: 0.608532229693239.\n",
            "[I 2023-06-23 14:58:39,091] Trial 99 finished with value: 0.48788674353486067 and parameters: {'var_smoothing': 5.691673629899875e-10}. Best is trial 69 with value: 0.608532229693239.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from Optuna\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "V0UXNDMbaZHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params #42 random seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92fe6497-7cdd-48ac-873e-0ae0d3f5b05c",
        "id": "xk1l3iDtaZHV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'var_smoothing': 0.0008094845352286139}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get best parameters and make predictions\n",
        "We suggest executing the notebook \"Papadopoulou_Fillipidou_Vossos_Final_Project_Metrics-Plots(2 class problem).ipynb\" for all the sections of predictions and results from the classifiers"
      ],
      "metadata": {
        "id": "JNPNRrx_aZHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selected_features_indices = [i for i, value in enumerate(best_features) if value]\n",
        "X_test_selected = X_test[:, selected_features]"
      ],
      "metadata": {
        "id": "E7s2z_UpaZHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f3f933-fa09-433e-8d73-05e72d00540c",
        "id": "fxXPLuhBaZHW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features = X_train_val[:, selected_features]"
      ],
      "metadata": {
        "id": "602uNHukaZHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val_selected_final_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539d731e-a93b-4de5-dd1b-0f5340e9289d",
        "id": "U7bwWiIQaZHX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1141, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best_C = study.best_params['C']\n",
        "#best_gamma = study.best_params['gamma']\n",
        "#best_gamma = study.best_params['gamma']\n",
        "#best_classifier = SVC(C=best_C, gamma=best_gamma)\n",
        "best_classifier_GNB = GaussianNB(**best_params)"
      ],
      "metadata": {
        "id": "HUQsjcyiaZHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_GNB.fit(X_train_val_selected_final_features, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "027403da-3b50-4140-a73c-c72476420074",
        "id": "Dq7nI34LaZHX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(var_smoothing=0.0008094845352286139)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=0.0008094845352286139)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=0.0008094845352286139)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_classifier_GNB.predict(X_test_selected)"
      ],
      "metadata": {
        "id": "rCMTdk8WaZHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "uakLSHsaaZHX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}